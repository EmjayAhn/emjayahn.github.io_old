
<!DOCTYPE html>
<html lang="en">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Emjay, 오늘도 새롭게">
    <title>[CS231n]Lecture09-CNN Architectures - Emjay, 오늘도 새롭게</title>
    <meta name="author" content="EmjayAhn">
    
        <meta name="keywords" content="데이터사이언스,머신러닝,딥러닝,개발,machine learning,deep learning,datascience,datascientist,">
    
    
    
        
            <link rel="alternate" type="application/rss+xml" title="RSS" href="/rss2.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"EmjayAhn","sameAs":["https://github.com/emjayahn","https://facebook.com/jjminjae","https://instagram.com/emjay.data_science","mailto:emjay.data@gmail.com"],"image":"https://www.gravatar.com/avatar/92c0fa2eff5c7c916250c5c23a090478"},"articleBody":"Lecture 09: CNN Architectures\n이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.\n\n\n\n이번 강의에서는 최초의 CNN 모델부터, ImageNet 대회에서 역대 좋은 스코어를 기록한 유명한 convnet 구조에 대해 살펴본다. 강의 summary 는 강의 내용 중심과 수업 중 궁금한 사항을 따로 찾아본 내용 위주로 정리한다. 해당 모델의 자세한 내용은 논문을 참조했다.\n1. AlexNetLenet 이후, 가장 처음으로 나온 large scale convnet model 이다. Architecture 는 다음과 같다. 수업시간에는 CONV1 과  Max Pooling layer 에 대해서만 각 layer 의 output volume size 와 parameter 갯수를 확인했으나, 연습과 공부를 위해 전체 layer 에 대해 계산해본다.\n\nArchitecture\n  CONV1\n  MAX POOL1\n  NORM1\n  CONV2\n  MAX POOL2\n  NORM 2\n  CONV3\n  CONV4\n  CONV5\n  MAX POOL3\n  FC6\n  FC7\n  FC8\n\n\n\nInput 이 227 x 227 x 3 image 가 들어갈 때, CONV1 (96 11x11 filter, stride 4)의 output volume size ? \n(227 - 11) / 4 + 1 = 55 이므로, 55 x 55 x 96\n\n\nConv1 의 weight 갯수 ?\nfilter size 11 * 11 * 3 (channel) * 96 (filter 갯수) = 34,849개\n\n\nMAX POOL (3 x 3 filter, stride 2) output volume size?\n(55 - 3) / 2 + 1 = 27\n27 x 27 x 96\n\n\nMAX POOL 의 weight 갯수?\nPooling 은 weight 이 없으니까, 낚이지말자. (낚일 수 없는 낚시지..)\n\n\nNORM Layer 는?\nNormalization 만 해주는 것이므로 output size 는 27 x 27 x 96 으로 동일\n\n\nCONV2 layer (256 5 x 5 filters, stride 1, padding 2) 의 output volume size 와 parameter 갯수?\n(27 - 5 + 4) / 1 + 1 = 27\noutput volume size : 27 x 27 x 256\nparameter 갯수: 5 * 5 * 96 (channel) * 256 (filter 갯수 ) = 614,400\n\n\nMAX POOL2 ( 3 x 3 filters, stride 2) output volume size?\n(27 - 3) / 2 + 1 = 13\noutput volume size: 13 x 13 x 256\n\n\nCONV3 layer ( 384 3 x 3 filters, stride 1, padding 1)의 output volume size 와 parameter 갯수?\n(13-3+2) / 1 + 1 =  13\nouput volume size = 13 x 13 x 384\nparameters: 13 * 13 * 256(channels) * 384 = 16,613,376\n\n\nCONV4 layer (384 3x3 filters stride 1, padding 1)\n(13 - 3 + 2) / 1 + 1 = 13\noutput volume size = 13 x 13 x 384\nparameters: 13 * 13 * 384(channels) * 384 = 24,920,064\n\n\nCONV5 layer (256 3x3 filters stride 1 , padding 1)\n(13 - 3 + 2) / 1 + 1 = 13\noutput volume size = 13 x 13 x 256\nparameters: 13 * 13 * 384 * 256 = 16,613,376\n\n\nMAX POOL3 (3 x 3 filters strides 2)\n(13 - 3) / 2 + 1 = 6\noutput volume size: 6 x 6 x 256\n\n\n\nAlexNet 의 특이점\n당시 GPU 메모리의 부족으로, CONV1 layer 의 경우 depth 가 96이었으나, 48 개씩 (반반) 다른 GPU 에 올려져 계산이 진행되었다. 이는 서로가 데이터를 바라볼수 없다는 것을 의미한다. 마찬가지 의미로, CONV2, CONV4, CONV5의 경우 서로 다른 gpu 상에 올라가 있는 feature map 을 볼수 없다. 반면, CONV3, FC6, FC7, FC8 에서 서로 cross 됨으로써 feature map 을 바라볼수 없는 문제를 완화하였다\n\n2. VGGVGG 는 AlexNet 과 비교하여, 조금더 깊은 convnet 을 가지고 있다. 이는 filter size 를 작게 가져감으로써 얻을 수 있는 이익이었다. \n7x7 conv layer 1개와 3x3 conv layer 가 3개를 비교해본다. 7x7 conv layer 1개의 원본 이미지로부터 얻는 receptive field 는 7x7 영역이다. 3개의 3 x 3 conv layer가 쌓였을 때, 3번째 layer 입장에서, 원본이미지의 7 x 7 만큼의 receptive field, 즉 같은 양의 receptive field 를 얻을 수 있다. 같은 receptive field 영역을 커버하지만, layer 의 수가 증가함으로써, 더 많은 non-linearity feature map을 얻을 수 있다. 또한, 각 layer 의 parameter 수를 살펴 보면, 7x7 conv layer 는 C(이전 layer 의 channel 수)77C = 49 * C^2만큼의 parameter를 가지고 있고, 3 layer 3x3 conv layer 는 333CC = 9 * C^2 만큼의 parameter 를 가지고 있다. 작은 filter size로 layer 수를 늘리는 것이 *parameter 의 갯수** 관점에서도 큰 이득을 가져다 준다.\ncf) 네트워크가 깊어질수록 computation양을 일정하게 유지하기 위해 각 레이어의 입력을 downsampling 한다. &amp; Spatial Area 가 작아질수록 filter 의 depth 를 조금씩 늘려준다.\n3. GoogLeNetGoogLeNet 의 특이점GoogleNet 은 깊은 신경망 모델에 대해, 계산량의 이점을 가져다주기 위해 고안되었다. 이는 Inception Module 을 설계하여, 이를 연속해 쌓는 방식의 구조이다. Inception Module 의 모양은 다음과 같다.\n다음과 같이 구성할 때, conv layer 를 거친 output 을 depth 방향으로 concatenate 한다. spatial dimension 은 stride 등을 조절한다.\n\nfeature map 을 뽑기 위해 각 layer 의 filter 갯수를 조절할텐데, 효과적인 feature map 을 뽑기 위해 filter 갯수를 늘리게되면, 전체 Inception Module 이 쌓이면 쌓일 수록, parameter 수가 지수배 증가하는 단점이 발생한다. 여기서 GoogleNet 의 핵심 idea가 등장하는 듯 하다.\n1x1 convolution layer!\n1x1 convolution layer를 통해 spatial dimension 은 보존하면서, depth 는 줄인다. 즉 이 convolution layer 를 bottle neck 이 되는 conv layer 앞단에 구성하여, 입력을 더 낮은 차원으로 보낸다.\n\n\n또한 google net 은 parameter 가 많이 필요한 fc layer 를 제거하므로써 computational 이득을 취했다. \n\n또한 Inception Module 이 쌓이면서, 깊게 쌓일 수록 loss 의 grdient  전파가 소실 되는 효과를 보완하기 위해 추가적인 classifier 를 곁가지에 닮으로써 gradient 를 추가적으로 update 한다.\n4. ResNetResNet 은 conv layer 를 깊게 추가하는 것이 성능에 이득을 주는지에 대한 의문으로 시작한다. 즉, 답은 깊게 쌓는 것이 성능이 좋아지지 않는다는 것이다. \n\n위 그림의 test error 그래프를 보더라도, 성능면에서 conv layer 의 증가가 좋은 성능을 가져다 주지 않는 것이 아니다. test error 그래프만 본다면, overfitting 된 것이 아닌가? 라는 생각을 할 수 있으나, training error 그래프를 보면, 학습 조차 잘 되지 않았음을 확인 할 수 있다.\n즉, 깊이가 깊은 모델이 어느 순간부터는 얕은 모델보다 성능이 안좋아 질 수 있는 문제가 발생한다. 이 문제를 degradation 문제라고 한다.\nResNet 의 특이점ResNet의 구조적 특이점은 바로 skip connection 이다. skip connection 은 이렇게, layer 의 입력과 출력이 더해져, 다음 layer 에 대한 입력으로 이루어 지는 구조를 의미한다.기존의 Neural Net 의 구조를 remind 해본다. 기존 뉴럴넷은 입력 x 가 들어갈 때, 출력 y 를 얻기 위한 H(x)를 찾아내는 과정이다. H(x)가 y 에 최대한 가깝게 하기 위한 즉, H(x) - y 가 0 이 될 수 있도록 최소화 과정을 거쳐 H(x) 를 찾아낸다. 이에 반해 ResNet 은 layer 를 거친 F(x) 와 x 가 더해진 F(x) + x 를 H(x)로 보고 이를 H(x) - x 를 최소화한다. 이는 residual 로 볼 수 있는 F(x)를 최소화한다는 의미이다. \n\n5. ReferenceLecture 9 | CNN Architectures\nSyllabus | CS 231N\n","dateCreated":"2019-07-26T20:40:18+09:00","dateModified":"2019-07-26T20:42:10+09:00","datePublished":"2019-07-26T20:40:18+09:00","description":"Lecture 09: CNN Architectures\n이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.\n","headline":"[CS231n]Lecture09-CNN Architectures","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/"},"publisher":{"@type":"Organization","name":"EmjayAhn","sameAs":["https://github.com/emjayahn","https://facebook.com/jjminjae","https://instagram.com/emjay.data_science","mailto:emjay.data@gmail.com"],"image":"https://www.gravatar.com/avatar/92c0fa2eff5c7c916250c5c23a090478","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/92c0fa2eff5c7c916250c5c23a090478"}},"url":"https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/","keywords":"summary, CS231n"}</script>
    <meta name="description" content="Lecture 09: CNN Architectures 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.">
<meta name="keywords" content="summary,CS231n">
<meta property="og:type" content="blog">
<meta property="og:title" content="[CS231n]Lecture09-CNN Architectures">
<meta property="og:url" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/index.html">
<meta property="og:site_name" content="Emjay, 오늘도 새롭게">
<meta property="og:description" content="Lecture 09: CNN Architectures 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/Untitled-fc505115-1120-4553-895a-ff1017096753.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/Untitled-455ba9e5-8395-41e4-a9d3-c8543af2883e.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/Untitled-74d7882d-4001-440f-a9b1-a3198f244dfc.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/Untitled-699859d1-387d-4936-8a1d-a191fbb5b6ef.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/Untitled-a0f95736-d7c0-4fc8-a918-f420a76b55c4.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/Untitled-9906cfd9-51eb-4c7f-a3fe-9cd43b5929b7.png">
<meta property="og:updated_time" content="2019-07-26T11:42:10.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[CS231n]Lecture09-CNN Architectures">
<meta name="twitter:description" content="Lecture 09: CNN Architectures 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.">
<meta name="twitter:image" content="https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/Untitled-fc505115-1120-4553-895a-ff1017096753.png">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/all.css">
    <link rel="stylesheet" href="/assets/css/jquery.fancybox.css">
    <link rel="stylesheet" href="/assets/css/thumbs.css">
    <link rel="stylesheet" href="/assets/css/tranquilpeak.css">
    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-128251719-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-128251719-1');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    

    
        
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Emjay, 오늘도 새롭게
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="홈"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">홈</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="Emjay"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Emjay</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="카테고리"
                        >
                        <i class="sidebar-button-icon fa fa-code" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">카테고리</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="아카이브"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">아카이브</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="/all-tags"
                            
                            rel="noopener"
                            title="태그"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">태그</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/emjayahn"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://facebook.com/jjminjae"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Facebook"
                        >
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://instagram.com/emjay.data_science"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Instagram"
                        >
                        <i class="sidebar-button-icon fab fa-instagram" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Instagram</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:emjay.data@gmail.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            [CS231n]Lecture09-CNN Architectures
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2019-07-26T20:40:18+09:00">
	
		    Jul 26, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Lecture/">Lecture</a>, <a class="category-link" href="/categories/Lecture/CS231n/">CS231n</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <h1 id="Lecture-09-CNN-Architectures"><a href="#Lecture-09-CNN-Architectures" class="headerlink" title="Lecture 09: CNN Architectures"></a>Lecture 09: CNN Architectures</h1><ul>
<li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li>
</ul>
<a id="more"></a>

<p>이번 강의에서는 최초의 CNN 모델부터, ImageNet 대회에서 역대 좋은 스코어를 기록한 유명한 convnet 구조에 대해 살펴본다. 강의 summary 는 강의 내용 중심과 수업 중 궁금한 사항을 따로 찾아본 내용 위주로 정리한다. 해당 모델의 자세한 내용은 논문을 참조했다.</p>
<h2 id="1-AlexNet"><a href="#1-AlexNet" class="headerlink" title="1. AlexNet"></a>1. AlexNet</h2><p>Lenet 이후, 가장 처음으로 나온 large scale convnet model 이다. Architecture 는 다음과 같다. 수업시간에는 CONV1 과  Max Pooling layer 에 대해서만 각 layer 의 output volume size 와 parameter 갯수를 확인했으나, 연습과 공부를 위해 전체 layer 에 대해 계산해본다.</p>
<ul>
<li><p>Architecture</p>
<p>  CONV1</p>
<p>  MAX POOL1</p>
<p>  NORM1</p>
<p>  CONV2</p>
<p>  MAX POOL2</p>
<p>  NORM 2</p>
<p>  CONV3</p>
<p>  CONV4</p>
<p>  CONV5</p>
<p>  MAX POOL3</p>
<p>  FC6</p>
<p>  FC7</p>
<p>  FC8</p>
</li>
</ul>
<ol>
<li>Input 이 227 x 227 x 3 image 가 들어갈 때, CONV1 (96 11x11 filter, stride 4)의 output volume size ? <ul>
<li>(227 - 11) / 4 + 1 = 55 이므로, 55 x 55 x 96</li>
</ul>
</li>
<li>Conv1 의 weight 갯수 ?<ul>
<li>filter size 11 * 11 * 3 (channel) * 96 (filter 갯수) = 34,849개</li>
</ul>
</li>
<li>MAX POOL (3 x 3 filter, stride 2) output volume size?<ul>
<li>(55 - 3) / 2 + 1 = 27</li>
<li>27 x 27 x 96</li>
</ul>
</li>
<li>MAX POOL 의 weight 갯수?<ul>
<li>Pooling 은 weight 이 없으니까, 낚이지말자. (낚일 수 없는 낚시지..)</li>
</ul>
</li>
<li>NORM Layer 는?<ul>
<li>Normalization 만 해주는 것이므로 output size 는 27 x 27 x 96 으로 동일</li>
</ul>
</li>
<li>CONV2 layer (256 5 x 5 filters, stride 1, padding 2) 의 output volume size 와 parameter 갯수?<ul>
<li>(27 - 5 + 4) / 1 + 1 = 27</li>
<li>output volume size : 27 x 27 x 256</li>
<li>parameter 갯수: 5 * 5 * 96 (channel) * 256 (filter 갯수 ) = 614,400</li>
</ul>
</li>
<li>MAX POOL2 ( 3 x 3 filters, stride 2) output volume size?<ul>
<li>(27 - 3) / 2 + 1 = 13</li>
<li>output volume size: 13 x 13 x 256</li>
</ul>
</li>
<li>CONV3 layer ( 384 3 x 3 filters, stride 1, padding 1)의 output volume size 와 parameter 갯수?<ul>
<li>(13-3+2) / 1 + 1 =  13</li>
<li>ouput volume size = 13 x 13 x 384</li>
<li>parameters: 13 * 13 * 256(channels) * 384 = 16,613,376</li>
</ul>
</li>
<li>CONV4 layer (384 3x3 filters stride 1, padding 1)<ul>
<li>(13 - 3 + 2) / 1 + 1 = 13</li>
<li>output volume size = 13 x 13 x 384</li>
<li>parameters: 13 * 13 * 384(channels) * 384 = 24,920,064</li>
</ul>
</li>
<li>CONV5 layer (256 3x3 filters stride 1 , padding 1)<ul>
<li>(13 - 3 + 2) / 1 + 1 = 13</li>
<li>output volume size = 13 x 13 x 256</li>
<li>parameters: 13 * 13 * 384 * 256 = 16,613,376</li>
</ul>
</li>
<li>MAX POOL3 (3 x 3 filters strides 2)<ul>
<li>(13 - 3) / 2 + 1 = 6</li>
<li>output volume size: 6 x 6 x 256</li>
</ul>
</li>
</ol>
<h3 id="AlexNet-의-특이점"><a href="#AlexNet-의-특이점" class="headerlink" title="AlexNet 의 특이점"></a>AlexNet 의 특이점</h3><ol>
<li>당시 GPU 메모리의 부족으로, CONV1 layer 의 경우 depth 가 96이었으나, 48 개씩 (반반) 다른 GPU 에 올려져 계산이 진행되었다. 이는 서로가 데이터를 바라볼수 없다는 것을 의미한다. 마찬가지 의미로, CONV2, CONV4, CONV5의 경우 서로 다른 gpu 상에 올라가 있는 feature map 을 볼수 없다. 반면, CONV3, FC6, FC7, FC8 에서 서로 cross 됨으로써 feature map 을 바라볼수 없는 문제를 완화하였다</li>
</ol>
<h2 id="2-VGG"><a href="#2-VGG" class="headerlink" title="2. VGG"></a>2. VGG</h2><p>VGG 는 AlexNet 과 비교하여, 조금더 깊은 convnet 을 가지고 있다. 이는 filter size 를 작게 가져감으로써 얻을 수 있는 이익이었다. </p>
<p>7x7 conv layer 1개와 3x3 conv layer 가 3개를 비교해본다. 7x7 conv layer 1개의 원본 이미지로부터 얻는 receptive field 는 7x7 영역이다. 3개의 3 x 3 conv layer가 쌓였을 때, 3번째 layer 입장에서, 원본이미지의 7 x 7 만큼의 receptive field, 즉 같은 양의 receptive field 를 얻을 수 있다. 같은 receptive field 영역을 커버하지만, layer 의 수가 증가함으로써, 더 많은 <strong>non-linearity feature map</strong>을 얻을 수 있다. 또한, 각 layer 의 parameter 수를 살펴 보면, 7x7 conv layer 는 C(이전 layer 의 channel 수)<em>7</em>7<em>C = 49 * C^2만큼의 parameter를 가지고 있고, 3 layer 3x3 conv layer 는 3</em>3<em>3</em>C<em>C = 9 * C^2 만큼의 parameter 를 가지고 있다. 작은 filter size로 layer 수를 늘리는 것이 *</em>parameter 의 갯수** 관점에서도 큰 이득을 가져다 준다.</p>
<p>cf) 네트워크가 깊어질수록 computation양을 일정하게 유지하기 위해 각 레이어의 입력을 downsampling 한다. &amp; Spatial Area 가 작아질수록 filter 의 depth 를 조금씩 늘려준다.</p>
<h2 id="3-GoogLeNet"><a href="#3-GoogLeNet" class="headerlink" title="3. GoogLeNet"></a>3. GoogLeNet</h2><h3 id="GoogLeNet-의-특이점"><a href="#GoogLeNet-의-특이점" class="headerlink" title="GoogLeNet 의 특이점"></a>GoogLeNet 의 특이점</h3><p>GoogleNet 은 깊은 신경망 모델에 대해, 계산량의 이점을 가져다주기 위해 고안되었다. 이는 Inception Module 을 설계하여, 이를 연속해 쌓는 방식의 구조이다. Inception Module 의 모양은 다음과 같다.</p>
<p>다음과 같이 구성할 때, conv layer 를 거친 output 을 depth 방향으로 concatenate 한다. spatial dimension 은 stride 등을 조절한다.</p>
<p><img src="Untitled-fc505115-1120-4553-895a-ff1017096753.png" alt></p>
<p>feature map 을 뽑기 위해 각 layer 의 filter 갯수를 조절할텐데, 효과적인 feature map 을 뽑기 위해 filter 갯수를 늘리게되면, 전체 Inception Module 이 쌓이면 쌓일 수록, parameter 수가 지수배 증가하는 단점이 발생한다. 여기서 GoogleNet 의 핵심 idea가 등장하는 듯 하다.</p>
<p><strong>1x1 convolution layer!</strong></p>
<p>1x1 convolution layer를 통해 spatial dimension 은 보존하면서, depth 는 줄인다. 즉 이 convolution layer 를 bottle neck 이 되는 conv layer 앞단에 구성하여, 입력을 더 낮은 차원으로 보낸다.</p>
<p><img src="Untitled-455ba9e5-8395-41e4-a9d3-c8543af2883e.png" alt></p>
<p><img src="Untitled-74d7882d-4001-440f-a9b1-a3198f244dfc.png" alt></p>
<p>또한 google net 은 parameter 가 많이 필요한 <strong>fc layer 를 제거</strong>하므로써 computational 이득을 취했다. </p>
<p><img src="Untitled-699859d1-387d-4936-8a1d-a191fbb5b6ef.png" alt></p>
<p>또한 Inception Module 이 쌓이면서, 깊게 쌓일 수록 loss 의 grdient  전파가 소실 되는 효과를 보완하기 위해 추가적인 classifier 를 곁가지에 닮으로써 gradient 를 추가적으로 update 한다.</p>
<h2 id="4-ResNet"><a href="#4-ResNet" class="headerlink" title="4. ResNet"></a>4. ResNet</h2><p>ResNet 은 conv layer 를 깊게 추가하는 것이 성능에 이득을 주는지에 대한 의문으로 시작한다. 즉, 답은 깊게 쌓는 것이 성능이 좋아지지 않는다는 것이다. </p>
<p><img src="Untitled-a0f95736-d7c0-4fc8-a918-f420a76b55c4.png" alt></p>
<p>위 그림의 test error 그래프를 보더라도, 성능면에서 conv layer 의 증가가 좋은 성능을 가져다 주지 않는 것이 아니다. test error 그래프만 본다면, overfitting 된 것이 아닌가? 라는 생각을 할 수 있으나, training error 그래프를 보면, 학습 조차 잘 되지 않았음을 확인 할 수 있다.</p>
<p>즉, 깊이가 깊은 모델이 어느 순간부터는 얕은 모델보다 성능이 안좋아 질 수 있는 문제가 발생한다. 이 문제를 degradation 문제라고 한다.</p>
<h3 id="ResNet-의-특이점"><a href="#ResNet-의-특이점" class="headerlink" title="ResNet 의 특이점"></a>ResNet 의 특이점</h3><p>ResNet의 구조적 특이점은 바로 skip connection 이다. skip connection 은 이렇게, layer 의 입력과 출력이 더해져, 다음 layer 에 대한 입력으로 이루어 지는 구조를 의미한다.기존의 Neural Net 의 구조를 remind 해본다. 기존 뉴럴넷은 입력 x 가 들어갈 때, 출력 y 를 얻기 위한 H(x)를 찾아내는 과정이다. H(x)가 y 에 최대한 가깝게 하기 위한 즉, H(x) - y 가 0 이 될 수 있도록 최소화 과정을 거쳐 H(x) 를 찾아낸다. 이에 반해 ResNet 은 layer 를 거친 F(x) 와 x 가 더해진 F(x) + x 를 H(x)로 보고 이를 H(x) - x 를 최소화한다. 이는 residual 로 볼 수 있는 F(x)를 최소화한다는 의미이다. </p>
<p><img src="Untitled-9906cfd9-51eb-4c7f-a3fe-9cd43b5929b7.png" alt></p>
<h2 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h2><p><a href="https://www.youtube.com/watch?v=DAOcjicFr1Y" target="_blank" rel="noopener">Lecture 9 | CNN Architectures</a></p>
<p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/CS231n/">CS231n</a> <a class="tag tag--primary tag--small t-link" href="/tags/summary/">summary</a>

            </div>
        
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/07/27/decorator/"
                    data-tooltip="[Python] 쉽게 쓰여진 Decorator"
                    aria-label="PREVIOUS: [Python] 쉽게 쓰여진 Decorator"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/07/22/CS231n-Lecture07-Summary/"
                    data-tooltip="[CS231n]Lecture07-Training Neural Networks part2"
                    aria-label="NEXT: [CS231n]Lecture07-Training Neural Networks part2"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Leave a comment"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
    
</article>



                <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6609549176861897"
     crossorigin="anonymous"></script>
<!-- 사각 디스플레이 광고 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6609549176861897"
     data-ad-slot="5287321473"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2021 EmjayAhn. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/07/27/decorator/"
                    data-tooltip="[Python] 쉽게 쓰여진 Decorator"
                    aria-label="PREVIOUS: [Python] 쉽게 쓰여진 Decorator"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/07/22/CS231n-Lecture07-Summary/"
                    data-tooltip="[CS231n]Lecture07-Training Neural Networks part2"
                    aria-label="NEXT: [CS231n]Lecture07-Training Neural Networks part2"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Leave a comment"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="5">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <h4 id="about-card-name">EmjayAhn</h4>
        
            <div id="about-card-bio"><p>NasMedia, Data Science Team</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Data Scientist</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Seoul, Korea
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover_blue.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/jquery.js"></script>
<script src="/assets/js/jquery.fancybox.js"></script>
<script src="/assets/js/thumbs.js"></script>
<script src="/assets/js/tranquilpeak.js"></script>
<!--SCRIPTS END-->


    
        <script>
          var disqus_config = function() {
            this.page.url = 'https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/';
              
            this.page.identifier = '2019/07/26/CS231n-Lecture09-Summary/';
              
          };
          (function() {
            var d = document, s = d.createElement('script');
            var disqus_shortname = 'emjay-blog';
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
    




    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
