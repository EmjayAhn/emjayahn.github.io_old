
<!DOCTYPE html>
<html lang="en">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Emjay, 오늘도 새롭게">
    <title>Linear Regression with Pytorch - Emjay, 오늘도 새롭게</title>
    <meta name="author" content="EmjayAhn">
    
        <meta name="keywords" content="데이터사이언스,머신러닝,딥러닝,개발,machine learning,deep learning,datascience,datascientist,">
    
    
    
        
            <link rel="alternate" type="application/rss+xml" title="RSS" href="/rss2.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"EmjayAhn","sameAs":["https://github.com/emjayahn","https://facebook.com/jjminjae","https://instagram.com/emjay.data_science","mailto:emjay.data@gmail.com"],"image":"https://www.gravatar.com/avatar/92c0fa2eff5c7c916250c5c23a090478"},"articleBody":"Linear Regression through Pytorch\n이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.\n\n\n\nImport Library12345678910import torchimport torch.optim as optimimport matplotlib.pyplot as pltimport numpy as npimport warningswarnings.filterwarnings(\"ignore\")%config InlineBackend.figure_format = 'retina'%matplotlib inline\n\nGenerate Toy Data$ y = \\frac{1}{3} x + 5 $ 와 약간의 noise 를 합쳐 100 개의 toy data를 만들겠습니다.\n12345# Target Functionf = lambda x: 1.0/3.0 * x + 5.0x = np.linspace(-40, 60, 100)fx = f(x)\n\n123plt.plot(x, fx)plt.grid()plt.show()\n\n\n123456# y_train data with little noisey = fx + 10 * np.random.rand(len(x))plt.plot(x, y, 'o')plt.grid()plt.show()\n\n\n1. Gradient Descent\nModel (hypothesis) 를 설정합니다.(여기선, Linear Regression 이므로, $y = Wx + b$ 형태를 사용합니다.)\nLoss Function 을 정의합니다. (여기선, MSE loss 를 사용하겠습니다.)\ngradient 를 계산합니다.(여기선, Gradient Descent 방법으로 optimize 를 할 것이므로, optim.SGD() 를 사용합니다.)\nparameter 를 update 합니다.\n\n1234x_train = torch.FloatTensor(x)y_train = torch.FloatTensor(y)print(\"x_train Tensor shape: \", x_train.shape)print(\"y_train Tensor shape: \", y_train.shape)\n\nx_train Tensor shape:  torch.Size([100])\ny_train Tensor shape:  torch.Size([100])1234567891011121314151617181920212223242526# train code# parameter setting &amp; initializeW = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)# optimizer settingoptimizer = optim.SGD([W, b], lr=0.001)# total epochsepochs = 3000for epoch in range(1, epochs + 1):    # decide model(hypothesis)    model = W * x_train + b        # loss function -&gt; MSE    loss = torch.mean((model - y_train)**2)        optimizer.zero_grad()    loss.backward()    optimizer.step()        # 10 epoch 마다 train loss 를 출력합니다.    if epoch % 500 == 0:        print(\"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;\".format(epoch, W.data, b.data, loss.data))\n\nepoch: 500 -- Parameters: W: tensor([0.3709]) b: tensor([5.6408]) -- loss 22.728315353393555\nepoch: 1000 -- Parameters: W: tensor([0.3467]) b: tensor([7.9427]) -- loss 11.399767875671387\nepoch: 1500 -- Parameters: W: tensor([0.3368]) b: tensor([8.8829]) -- loss 9.51008415222168\nepoch: 2000 -- Parameters: W: tensor([0.3327]) b: tensor([9.2669]) -- loss 9.194862365722656\nepoch: 2500 -- Parameters: W: tensor([0.3311]) b: tensor([9.4237]) -- loss 9.142287254333496\nepoch: 3000 -- Parameters: W: tensor([0.3304]) b: tensor([9.4878]) -- loss 9.13351631164550812345plt.plot(x, y, 'o', label=\"train data\")plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label='fitted')plt.grid()plt.legend()plt.show()\n\n\n2. Stochastic Gradient Descent\nModel (hypothesis) Setting\nLoss Function Setting\n최적화 알고리즘 선택\nshuffle train data\nmini-batch 마다 W, b 업데이트\n\n12345678910111213141516# batch 를 generate 해주는 함수def generate_batch(batch_size, x_train, y_train):    assert len(x_train) == len(y_train)    result_batches = []    x_size = len(x_train)        shuffled_id = np.arange(x_size)    np.random.shuffle(shuffled_id)    shuffled_x_train = x_train[shuffled_id]    shuffled_y_train = y_train[shuffled_id]        for start_idx in range(0, x_size, batch_size):        end_idx = start_idx + batch_size        batch = [shuffled_x_train[start_idx:end_idx], shuffled_y_train[start_idx:end_idx]]        result_batches.append(batch)    return result_batches\n\n12345678910111213141516171819# trainW = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)optimizer = optim.SGD([W, b], lr=0.001)epochs = 10000for epoch in range(1, epochs + 1):    for x_batch, y_batch in generate_batch(10, x_train, y_train):        model = W * x_batch + b        loss = torch.mean((model - y_batch)**2)                optimizer.zero_grad()        loss.backward()        optimizer.step()            if epoch % 500 == 0:        print(\"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;\".format(epoch, W.data, b.data, loss.data))\n\nepoch: 500 -- Parameters: W: tensor([0.0890]) b: tensor([9.5399]) -- loss 162.1055450439453\nepoch: 1000 -- Parameters: W: tensor([0.3672]) b: tensor([9.5366]) -- loss 12.424881935119629\nepoch: 1500 -- Parameters: W: tensor([0.3560]) b: tensor([9.5097]) -- loss 7.826609134674072\nepoch: 2000 -- Parameters: W: tensor([0.3375]) b: tensor([9.5556]) -- loss 13.15934944152832\nepoch: 2500 -- Parameters: W: tensor([0.2462]) b: tensor([9.5157]) -- loss 11.582895278930664\nepoch: 3000 -- Parameters: W: tensor([0.3097]) b: tensor([9.5111]) -- loss 9.991677284240723\nepoch: 3500 -- Parameters: W: tensor([0.2497]) b: tensor([9.5532]) -- loss 20.481367111206055\nepoch: 4000 -- Parameters: W: tensor([0.4388]) b: tensor([9.5390]) -- loss 20.827198028564453\nepoch: 4500 -- Parameters: W: tensor([0.1080]) b: tensor([9.4959]) -- loss 140.0277862548828\nepoch: 5000 -- Parameters: W: tensor([0.3188]) b: tensor([9.4829]) -- loss 6.635367393493652\nepoch: 5500 -- Parameters: W: tensor([0.2553]) b: tensor([9.5017]) -- loss 25.45773696899414\nepoch: 6000 -- Parameters: W: tensor([0.2490]) b: tensor([9.5489]) -- loss 9.580666542053223\nepoch: 6500 -- Parameters: W: tensor([0.3189]) b: tensor([9.5347]) -- loss 12.585128784179688\nepoch: 7000 -- Parameters: W: tensor([0.3026]) b: tensor([9.4874]) -- loss 8.298829078674316\nepoch: 7500 -- Parameters: W: tensor([0.3507]) b: tensor([9.6815]) -- loss 13.348054885864258\nepoch: 8000 -- Parameters: W: tensor([0.1423]) b: tensor([9.5220]) -- loss 32.567440032958984\nepoch: 8500 -- Parameters: W: tensor([0.7147]) b: tensor([9.5182]) -- loss 75.97190856933594\nepoch: 9000 -- Parameters: W: tensor([0.5170]) b: tensor([9.5289]) -- loss 39.07848358154297\nepoch: 9500 -- Parameters: W: tensor([0.3748]) b: tensor([9.5590]) -- loss 10.358983993530273\nepoch: 10000 -- Parameters: W: tensor([0.2958]) b: tensor([9.6088]) -- loss 7.410649299621582\nStochasitic 하게 loss의 gradient 를 계산하여, parameter update를 하므로, loss 가 굉장히 oscilation 이 나타나며 감소하는 것을 볼 수 있다.\n\n12345plt.plot(x, y, 'o', label=\"train data\")plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label='fitted')plt.grid()plt.legend()plt.show()\n\n\n12\n\n","dateCreated":"2019-05-03T18:19:59+09:00","dateModified":"2019-07-17T00:56:04+09:00","datePublished":"2019-05-03T18:19:59+09:00","description":"Linear Regression through Pytorch\n이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.\n","headline":"Linear Regression with Pytorch","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"},"publisher":{"@type":"Organization","name":"EmjayAhn","sameAs":["https://github.com/emjayahn","https://facebook.com/jjminjae","https://instagram.com/emjay.data_science","mailto:emjay.data@gmail.com"],"image":"https://www.gravatar.com/avatar/92c0fa2eff5c7c916250c5c23a090478","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/92c0fa2eff5c7c916250c5c23a090478"}},"url":"https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"}</script>
    <meta name="description" content="Linear Regression through Pytorch 이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.">
<meta name="keywords" content="데이터사이언스,머신러닝,딥러닝,개발,machine learning,deep learning,datascience,datascientist">
<meta property="og:type" content="blog">
<meta property="og:title" content="Linear Regression with Pytorch">
<meta property="og:url" content="https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/index.html">
<meta property="og:site_name" content="Emjay, 오늘도 새롭게">
<meta property="og:description" content="Linear Regression through Pytorch 이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/output_5_0.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/output_6_0.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/output_10_0.png">
<meta property="og:image" content="https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/output_15_0.png">
<meta property="og:updated_time" content="2019-07-16T15:56:04.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Linear Regression with Pytorch">
<meta name="twitter:description" content="Linear Regression through Pytorch 이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.">
<meta name="twitter:image" content="https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/output_5_0.png">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/all.css">
    <link rel="stylesheet" href="/assets/css/jquery.fancybox.css">
    <link rel="stylesheet" href="/assets/css/thumbs.css">
    <link rel="stylesheet" href="/assets/css/tranquilpeak.css">
    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-128251719-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-128251719-1');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    

    
        
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Emjay, 오늘도 새롭게
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="홈"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">홈</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="Emjay"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Emjay</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="카테고리"
                        >
                        <i class="sidebar-button-icon fa fa-code" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">카테고리</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="아카이브"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">아카이브</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="/all-tags"
                            
                            rel="noopener"
                            title="태그"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">태그</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/emjayahn"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://facebook.com/jjminjae"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Facebook"
                        >
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://instagram.com/emjay.data_science"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Instagram"
                        >
                        <i class="sidebar-button-icon fab fa-instagram" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Instagram</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:emjay.data@gmail.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            Linear Regression with Pytorch
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2019-05-03T18:19:59+09:00">
	
		    May 03, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/MachineLearning/">MachineLearning</a>, <a class="category-link" href="/categories/MachineLearning/Pytorch/">Pytorch</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <h1 id="Linear-Regression-through-Pytorch"><a href="#Linear-Regression-through-Pytorch" class="headerlink" title="Linear Regression through Pytorch"></a>Linear Regression through Pytorch</h1><ul>
<li>이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.</li>
</ul>
<a id="more"></a>

<h2 id="Import-Library"><a href="#Import-Library" class="headerlink" title="Import Library"></a>Import Library</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'retina'</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<h2 id="Generate-Toy-Data"><a href="#Generate-Toy-Data" class="headerlink" title="Generate Toy Data"></a>Generate Toy Data</h2><p>$ y = \frac{1}{3} x + 5 $ 와 약간의 noise 를 합쳐 100 개의 toy data를 만들겠습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Target Function</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: <span class="number">1.0</span>/<span class="number">3.0</span> * x + <span class="number">5.0</span></span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-40</span>, <span class="number">60</span>, <span class="number">100</span>)</span><br><span class="line">fx = f(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, fx)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="output_5_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># y_train data with little noise</span></span><br><span class="line">y = fx + <span class="number">10</span> * np.random.rand(len(x))</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="output_6_0.png" alt="png"></p>
<h2 id="1-Gradient-Descent"><a href="#1-Gradient-Descent" class="headerlink" title="1. Gradient Descent"></a>1. Gradient Descent</h2><ol>
<li>Model (hypothesis) 를 설정합니다.<br>(여기선, Linear Regression 이므로, $y = Wx + b$ 형태를 사용합니다.)</li>
<li>Loss Function 을 정의합니다. (여기선, MSE loss 를 사용하겠습니다.)</li>
<li>gradient 를 계산합니다.<br>(여기선, Gradient Descent 방법으로 optimize 를 할 것이므로, optim.SGD() 를 사용합니다.)</li>
<li>parameter 를 update 합니다.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor(x)</span><br><span class="line">y_train = torch.FloatTensor(y)</span><br><span class="line">print(<span class="string">"x_train Tensor shape: "</span>, x_train.shape)</span><br><span class="line">print(<span class="string">"y_train Tensor shape: "</span>, y_train.shape)</span><br></pre></td></tr></table></figure>

<pre><code>x_train Tensor shape:  torch.Size([100])
y_train Tensor shape:  torch.Size([100])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train code</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># parameter setting &amp; initialize</span></span><br><span class="line">W = torch.zeros(<span class="number">1</span>, requires_grad=<span class="keyword">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer setting</span></span><br><span class="line">optimizer = optim.SGD([W, b], lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># total epochs</span></span><br><span class="line">epochs = <span class="number">3000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="comment"># decide model(hypothesis)</span></span><br><span class="line">    model = W * x_train + b</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loss function -&gt; MSE</span></span><br><span class="line">    loss = torch.mean((model - y_train)**<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 10 epoch 마다 train loss 를 출력합니다.</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, b.data, loss.data))</span><br></pre></td></tr></table></figure>

<pre><code>epoch: 500 -- Parameters: W: tensor([0.3709]) b: tensor([5.6408]) -- loss 22.728315353393555
epoch: 1000 -- Parameters: W: tensor([0.3467]) b: tensor([7.9427]) -- loss 11.399767875671387
epoch: 1500 -- Parameters: W: tensor([0.3368]) b: tensor([8.8829]) -- loss 9.51008415222168
epoch: 2000 -- Parameters: W: tensor([0.3327]) b: tensor([9.2669]) -- loss 9.194862365722656
epoch: 2500 -- Parameters: W: tensor([0.3311]) b: tensor([9.4237]) -- loss 9.142287254333496
epoch: 3000 -- Parameters: W: tensor([0.3304]) b: tensor([9.4878]) -- loss 9.133516311645508</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="string">'o'</span>, label=<span class="string">"train data"</span>)</span><br><span class="line">plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label=<span class="string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="output_10_0.png" alt="png"></p>
<h2 id="2-Stochastic-Gradient-Descent"><a href="#2-Stochastic-Gradient-Descent" class="headerlink" title="2. Stochastic Gradient Descent"></a>2. Stochastic Gradient Descent</h2><ol>
<li>Model (hypothesis) Setting</li>
<li>Loss Function Setting</li>
<li>최적화 알고리즘 선택</li>
<li>shuffle train data</li>
<li>mini-batch 마다 W, b 업데이트</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># batch 를 generate 해주는 함수</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_batch</span><span class="params">(batch_size, x_train, y_train)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(x_train) == len(y_train)</span><br><span class="line">    result_batches = []</span><br><span class="line">    x_size = len(x_train)</span><br><span class="line">    </span><br><span class="line">    shuffled_id = np.arange(x_size)</span><br><span class="line">    np.random.shuffle(shuffled_id)</span><br><span class="line">    shuffled_x_train = x_train[shuffled_id]</span><br><span class="line">    shuffled_y_train = y_train[shuffled_id]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> start_idx <span class="keyword">in</span> range(<span class="number">0</span>, x_size, batch_size):</span><br><span class="line">        end_idx = start_idx + batch_size</span><br><span class="line">        batch = [shuffled_x_train[start_idx:end_idx], shuffled_y_train[start_idx:end_idx]]</span><br><span class="line">        result_batches.append(batch)</span><br><span class="line">    <span class="keyword">return</span> result_batches</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train</span></span><br><span class="line">W = torch.zeros(<span class="number">1</span>, requires_grad=<span class="keyword">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([W, b], lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> generate_batch(<span class="number">10</span>, x_train, y_train):</span><br><span class="line">        model = W * x_batch + b</span><br><span class="line">        loss = torch.mean((model - y_batch)**<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, b.data, loss.data))</span><br></pre></td></tr></table></figure>

<pre><code>epoch: 500 -- Parameters: W: tensor([0.0890]) b: tensor([9.5399]) -- loss 162.1055450439453
epoch: 1000 -- Parameters: W: tensor([0.3672]) b: tensor([9.5366]) -- loss 12.424881935119629
epoch: 1500 -- Parameters: W: tensor([0.3560]) b: tensor([9.5097]) -- loss 7.826609134674072
epoch: 2000 -- Parameters: W: tensor([0.3375]) b: tensor([9.5556]) -- loss 13.15934944152832
epoch: 2500 -- Parameters: W: tensor([0.2462]) b: tensor([9.5157]) -- loss 11.582895278930664
epoch: 3000 -- Parameters: W: tensor([0.3097]) b: tensor([9.5111]) -- loss 9.991677284240723
epoch: 3500 -- Parameters: W: tensor([0.2497]) b: tensor([9.5532]) -- loss 20.481367111206055
epoch: 4000 -- Parameters: W: tensor([0.4388]) b: tensor([9.5390]) -- loss 20.827198028564453
epoch: 4500 -- Parameters: W: tensor([0.1080]) b: tensor([9.4959]) -- loss 140.0277862548828
epoch: 5000 -- Parameters: W: tensor([0.3188]) b: tensor([9.4829]) -- loss 6.635367393493652
epoch: 5500 -- Parameters: W: tensor([0.2553]) b: tensor([9.5017]) -- loss 25.45773696899414
epoch: 6000 -- Parameters: W: tensor([0.2490]) b: tensor([9.5489]) -- loss 9.580666542053223
epoch: 6500 -- Parameters: W: tensor([0.3189]) b: tensor([9.5347]) -- loss 12.585128784179688
epoch: 7000 -- Parameters: W: tensor([0.3026]) b: tensor([9.4874]) -- loss 8.298829078674316
epoch: 7500 -- Parameters: W: tensor([0.3507]) b: tensor([9.6815]) -- loss 13.348054885864258
epoch: 8000 -- Parameters: W: tensor([0.1423]) b: tensor([9.5220]) -- loss 32.567440032958984
epoch: 8500 -- Parameters: W: tensor([0.7147]) b: tensor([9.5182]) -- loss 75.97190856933594
epoch: 9000 -- Parameters: W: tensor([0.5170]) b: tensor([9.5289]) -- loss 39.07848358154297
epoch: 9500 -- Parameters: W: tensor([0.3748]) b: tensor([9.5590]) -- loss 10.358983993530273
epoch: 10000 -- Parameters: W: tensor([0.2958]) b: tensor([9.6088]) -- loss 7.410649299621582</code></pre><ul>
<li>Stochasitic 하게 loss의 gradient 를 계산하여, parameter update를 하므로, loss 가 굉장히 oscilation 이 나타나며 감소하는 것을 볼 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="string">'o'</span>, label=<span class="string">"train data"</span>)</span><br><span class="line">plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label=<span class="string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="output_15_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/05/04/Linear-Model-with-Pytorch/"
                    data-tooltip="Linear Model with Pytorch"
                    aria-label="PREVIOUS: Linear Model with Pytorch"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/05/03/Lecture-딥러닝을-이용한-자연어-처리-Section-A-B/"
                    data-tooltip="[Lecture] 딥러닝을 이용한 자연어 처리 Section A, B"
                    aria-label="NEXT: [Lecture] 딥러닝을 이용한 자연어 처리 Section A, B"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Leave a comment"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
    
</article>



                <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6609549176861897"
     crossorigin="anonymous"></script>
<!-- 사각 디스플레이 광고 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6609549176861897"
     data-ad-slot="5287321473"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2021 EmjayAhn. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/05/04/Linear-Model-with-Pytorch/"
                    data-tooltip="Linear Model with Pytorch"
                    aria-label="PREVIOUS: Linear Model with Pytorch"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/05/03/Lecture-딥러닝을-이용한-자연어-처리-Section-A-B/"
                    data-tooltip="[Lecture] 딥러닝을 이용한 자연어 처리 Section A, B"
                    aria-label="NEXT: [Lecture] 딥러닝을 이용한 자연어 처리 Section A, B"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Leave a comment"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="5">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <h4 id="about-card-name">EmjayAhn</h4>
        
            <div id="about-card-bio"><p>NasMedia, Data Science Team</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Data Scientist</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Seoul, Korea
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover_blue.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/jquery.js"></script>
<script src="/assets/js/jquery.fancybox.js"></script>
<script src="/assets/js/thumbs.js"></script>
<script src="/assets/js/tranquilpeak.js"></script>
<!--SCRIPTS END-->


    
        <script>
          var disqus_config = function() {
            this.page.url = 'https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/';
              
            this.page.identifier = '2019/05/03/Linear-Regression-with-Pytorch/';
              
          };
          (function() {
            var d = document, s = d.createElement('script');
            var disqus_shortname = 'emjay-blog';
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
    




    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
