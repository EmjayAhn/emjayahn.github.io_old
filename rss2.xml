<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Emjay, 오늘도 새롭게</title>
    <link>https://emjayahn.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>공부한 것, 알게된 것을 기록하는 블로그입니다.</description>
    <pubDate>Sun, 28 Jul 2019 00:55:28 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>쉽게 쓰여진 Decorator</title>
      <link>https://emjayahn.github.io/2019/07/27/decorator/</link>
      <guid>https://emjayahn.github.io/2019/07/27/decorator/</guid>
      <pubDate>Sat, 27 Jul 2019 09:46:17 GMT</pubDate>
      <description>
      
        &lt;p&gt;오픈소스나, 다른 사람들이 만든 코드를 재수정한 코드, 제가 짠 코드에 대해 다양한 디버깅과 좀 더 다른 기능을 추가하고 싶을 때, 우리는 Decorator 를 자주 접하게 됩니다. Python 실력을 한층 업그레이드 하기 위함과, 코딩의 또 다른 목적이이 &lt;code&gt;귀차니즘의 해결&lt;/code&gt; 이라고 생각할 때 Decorator 에 대한 이해는 그 시작 관문이 됩니다. 이번 글에서는 이 Decorator 에 대한 개념을 쉽게 설명하려고 노력하였습니다.&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>오픈소스나, 다른 사람들이 만든 코드를 재수정한 코드, 제가 짠 코드에 대해 다양한 디버깅과 좀 더 다른 기능을 추가하고 싶을 때, 우리는 Decorator 를 자주 접하게 됩니다. Python 실력을 한층 업그레이드 하기 위함과, 코딩의 또 다른 목적이이 <code>귀차니즘의 해결</code> 이라고 생각할 때 Decorator 에 대한 이해는 그 시작 관문이 됩니다. 이번 글에서는 이 Decorator 에 대한 개념을 쉽게 설명하려고 노력하였습니다.</p><a id="more"></a><p>많은 책들에서 Decorator 의 설명을 본격적으로 들어가기에 앞서, python에서의 변수의 범위와 전역변수, 지역변수, 자유변수 등을 설명하고, 자칫 정신을 혼미하게 만들 수 있는 클로져(closure)를 설명한 뒤에 Decorator 를 만나게 됩니다. 물론 모두 Decorator 에서만아니라 파이썬을 다루고, 컴퓨터 과학을 공부하며, 필수적으로 알아야하는 중요한 개념이긴 하나, 이번 글에서는 예제들을 통해 Decorator 를 짜는 방법과 어떻게 구동이 되는지 실용적인 개념에 대해 요약 정리하려고 합니다.</p><h2 id="1-Decorator란"><a href="#1-Decorator란" class="headerlink" title="1. Decorator란?"></a>1. Decorator란?</h2><blockquote><p>Decorator : <strong>호출 가능한</strong> <strong>객체</strong> 로써, <strong>호출 가능한 객체</strong>를 입력으로 받아, <strong>호출 가능한 객체</strong> 를 반환하는 함수</p></blockquote><p>Decorator 를 만들 때, 가장 첫번째로 성립해야하는 구조가 위처럼, Decorator 기능을 하게 될 함수가 호출 가능해야하고, 입력에 호출 가능한 객체를 받아, 반환하는 객체도 호출 가능한 객체로 반환 해주어야 합니다.<br><br><br>위의 정의를 만족하는 세상에서 가장 간단한 Decorator 를 다음의 예제코드로 만들 수 있습니다.</p><script src="https://gist.github.com/EmjayAhn/f0cd4bafba347e3d046b5a742ffc57db.js"></script><p>위의 코드의 결과는 <code>Hi, Hi</code> 가 출력되는 아무 기능이 없는 본 함수와 decorator 입니다. 위와 같은 기능을 하는, Decorator 문법을 지킨 코드는 다음과 같습니다.</p><script src="https://gist.github.com/EmjayAhn/6fbcfcfa64bd107f0e7875867c28aa37.js"></script><p>두 코드는 같은 기능을 하지만, 앞서 정의된 <code>dumb_decorator</code> 가 첫번째에서는 꾸미려고하는 say_hi 함수를 <code>dumb_decorator</code>에 입력으로 넣어주어 코드를 실행 시켜 주었으며, 두번째에서는 꾸미려고하는 say_hi 함수의 선언시 <code>@dumb_decorator</code> 를 먼저 적어주고, 꾸며진 함수 <code>say_hi()</code> 를 실행하는 점에서 차이가 있습니다.</p><h2 id="2-Decorator를-Decorator-처럼"><a href="#2-Decorator를-Decorator-처럼" class="headerlink" title="2. Decorator를 Decorator 처럼"></a>2. Decorator를 Decorator 처럼</h2><p>1에서 Decorator의 핵심적인 구조를 살펴보았습니다. 이제 본격적인 Decorator를 본격적인 Decorator 로 사용하기 위해선, decorator 내부에 입력함수를 감싸주는 wrapper 함수가 필요합니다. 예제로 살펴보겠습니다. </p><script src="https://gist.github.com/EmjayAhn/bc8e34c19ebb87446aec5c7645c80f55.js"></script><p>첫번째 예제와 다른 점이라곤, 우리가 꾸미려고 하는 decorator 함수 안에 내부 wrapper 함수를 추가해줌으로써, 우리가 꾸미려는 내용을 선언해주었습니다. </p><h2 id="3-Decorator-의-장점"><a href="#3-Decorator-의-장점" class="headerlink" title="3. Decorator 의 장점?"></a>3. Decorator 의 장점?</h2><p>위에 본 예제를 극단적인 case 로 몰고 가보죠. 우리가 꾸며야할 함수가 많다고 상상해 보겠습니다. 기존에 잘 동작하던 프로그램이 있을 때, 프로그램의 로그가 궁금하다던가, 신경망을 학습시키는 코드에 대해 각 layer 의 gradient 나 출력값을 보고 싶을 수 있습니다. 우리가 decorator 를 사용하지 않는다면, 첫번째 코드 예시 처럼 일일히 다 실행시켜주어야 하는 문제가 발생합니다. 우리는 사용하려고 하는 함수를 선언할때 <code>@decorator</code> 를 붙여 줌으로써, 이러한 <code>귀차니즘</code>을 해결할 수 있습니다. 예제를 통해 살펴보겠습니다.<br><br><br>기존에도 잘 돌아가는 프로그램 3개의 log 를 찍어야 하는 순간이 찾아왔다고 가정합니다. generator 를 사용하는 것과 그렇지 않은 것을 비교해봄으로써 generator 의 고마움을 느껴볼 수 있습니다. 이번 예제에서는 간단하게 그 log 를 프로그램 return 형의 글자(character) 수로 생각해보죠.</p><script src="https://gist.github.com/EmjayAhn/c004ae8798e378a07a94c3b0d33e4814.js"></script><p>기존에 존재하던 프로그램이 <code>program_1</code>, <code>program_2</code>, <code>program_3</code> 이라고 생각해보고, 추가적으로 우리가 my_decorator 라는 코드를 통해 각 프로그램의 로그(여기선, charater 수)를 찍어야 하는 task 가 주어졌습니다. 우리가 decorator 를 알기 전이라면, 위와 같이 코드를 작성해 준 후,<br>실행부분에서 각 프로그램을 decorator 에 넣어주어, 꾸며진 결과 객체를 가지고, 이를 다시 실행해주는 행동을 반복해 주어야 합니다. 이제 decorator 의 고마움을 느껴볼 차례입니다.</p><script src="https://gist.github.com/EmjayAhn/1088964a6c8d53a668b45fe6a6f1e9c7.js"></script><h2 id="4-마치며"><a href="#4-마치며" class="headerlink" title="4. 마치며"></a>4. 마치며</h2><p>간단한 예제를 통해 Decorator 가 어떻게 동작하는지, 어떻게 구성해야하는지 핵심적인 부분이 이해됐길 바랍니다. 조금더 공부할 수 있는 키워드는 <code>클로져 (closure)</code>, <code>free variable</code> 등이 있을 수 있습니다. 위 키워드의 공부를 통해 조금더 자유로운 generator 설계를 할 수 있을 것으로 믿습니다.</p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/07/27/decorator/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture09-CNN Architectures</title>
      <link>https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/</link>
      <guid>https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/</guid>
      <pubDate>Fri, 26 Jul 2019 11:40:18 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Lecture-09-CNN-Architectures&quot;&gt;&lt;a href=&quot;#Lecture-09-CNN-Architectures&quot; class=&quot;headerlink&quot; title=&quot;Lecture 09: CNN Architectures&quot;&gt;&lt;/a&gt;Lecture 09: CNN Architectures&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lecture-09-CNN-Architectures"><a href="#Lecture-09-CNN-Architectures" class="headerlink" title="Lecture 09: CNN Architectures"></a>Lecture 09: CNN Architectures</h1><ul><li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li></ul><a id="more"></a><p>이번 강의에서는 최초의 CNN 모델부터, ImageNet 대회에서 역대 좋은 스코어를 기록한 유명한 convnet 구조에 대해 살펴본다. 강의 summary 는 강의 내용 중심과 수업 중 궁금한 사항을 따로 찾아본 내용 위주로 정리한다. 해당 모델의 자세한 내용은 논문을 참조했다.</p><h2 id="1-AlexNet"><a href="#1-AlexNet" class="headerlink" title="1. AlexNet"></a>1. AlexNet</h2><p>Lenet 이후, 가장 처음으로 나온 large scale convnet model 이다. Architecture 는 다음과 같다. 수업시간에는 CONV1 과  Max Pooling layer 에 대해서만 각 layer 의 output volume size 와 parameter 갯수를 확인했으나, 연습과 공부를 위해 전체 layer 에 대해 계산해본다.</p><ul><li><p>Architecture</p><p>  CONV1</p><p>  MAX POOL1</p><p>  NORM1</p><p>  CONV2</p><p>  MAX POOL2</p><p>  NORM 2</p><p>  CONV3</p><p>  CONV4</p><p>  CONV5</p><p>  MAX POOL3</p><p>  FC6</p><p>  FC7</p><p>  FC8</p></li></ul><ol><li>Input 이 227 x 227 x 3 image 가 들어갈 때, CONV1 (96 11x11 filter, stride 4)의 output volume size ? <ul><li>(227 - 11) / 4 + 1 = 55 이므로, 55 x 55 x 96</li></ul></li><li>Conv1 의 weight 갯수 ?<ul><li>filter size 11 * 11 * 3 (channel) * 96 (filter 갯수) = 34,849개</li></ul></li><li>MAX POOL (3 x 3 filter, stride 2) output volume size?<ul><li>(55 - 3) / 2 + 1 = 27</li><li>27 x 27 x 96</li></ul></li><li>MAX POOL 의 weight 갯수?<ul><li>Pooling 은 weight 이 없으니까, 낚이지말자. (낚일 수 없는 낚시지..)</li></ul></li><li>NORM Layer 는?<ul><li>Normalization 만 해주는 것이므로 output size 는 27 x 27 x 96 으로 동일</li></ul></li><li>CONV2 layer (256 5 x 5 filters, stride 1, padding 2) 의 output volume size 와 parameter 갯수?<ul><li>(27 - 5 + 4) / 1 + 1 = 27</li><li>output volume size : 27 x 27 x 256</li><li>parameter 갯수: 5 * 5 * 96 (channel) * 256 (filter 갯수 ) = 614,400</li></ul></li><li>MAX POOL2 ( 3 x 3 filters, stride 2) output volume size?<ul><li>(27 - 3) / 2 + 1 = 13</li><li>output volume size: 13 x 13 x 256</li></ul></li><li>CONV3 layer ( 384 3 x 3 filters, stride 1, padding 1)의 output volume size 와 parameter 갯수?<ul><li>(13-3+2) / 1 + 1 =  13</li><li>ouput volume size = 13 x 13 x 384</li><li>parameters: 13 * 13 * 256(channels) * 384 = 16,613,376</li></ul></li><li>CONV4 layer (384 3x3 filters stride 1, padding 1)<ul><li>(13 - 3 + 2) / 1 + 1 = 13</li><li>output volume size = 13 x 13 x 384</li><li>parameters: 13 * 13 * 384(channels) * 384 = 24,920,064</li></ul></li><li>CONV5 layer (256 3x3 filters stride 1 , padding 1)<ul><li>(13 - 3 + 2) / 1 + 1 = 13</li><li>output volume size = 13 x 13 x 256</li><li>parameters: 13 * 13 * 384 * 256 = 16,613,376</li></ul></li><li>MAX POOL3 (3 x 3 filters strides 2)<ul><li>(13 - 3) / 2 + 1 = 6</li><li>output volume size: 6 x 6 x 256</li></ul></li></ol><h3 id="AlexNet-의-특이점"><a href="#AlexNet-의-특이점" class="headerlink" title="AlexNet 의 특이점"></a>AlexNet 의 특이점</h3><ol><li>당시 GPU 메모리의 부족으로, CONV1 layer 의 경우 depth 가 96이었으나, 48 개씩 (반반) 다른 GPU 에 올려져 계산이 진행되었다. 이는 서로가 데이터를 바라볼수 없다는 것을 의미한다. 마찬가지 의미로, CONV2, CONV4, CONV5의 경우 서로 다른 gpu 상에 올라가 있는 feature map 을 볼수 없다. 반면, CONV3, FC6, FC7, FC8 에서 서로 cross 됨으로써 feature map 을 바라볼수 없는 문제를 완화하였다</li></ol><h2 id="2-VGG"><a href="#2-VGG" class="headerlink" title="2. VGG"></a>2. VGG</h2><p>VGG 는 AlexNet 과 비교하여, 조금더 깊은 convnet 을 가지고 있다. 이는 filter size 를 작게 가져감으로써 얻을 수 있는 이익이었다. </p><p>7x7 conv layer 1개와 3x3 conv layer 가 3개를 비교해본다. 7x7 conv layer 1개의 원본 이미지로부터 얻는 receptive field 는 7x7 영역이다. 3개의 3 x 3 conv layer가 쌓였을 때, 3번째 layer 입장에서, 원본이미지의 7 x 7 만큼의 receptive field, 즉 같은 양의 receptive field 를 얻을 수 있다. 같은 receptive field 영역을 커버하지만, layer 의 수가 증가함으로써, 더 많은 <strong>non-linearity feature map</strong>을 얻을 수 있다. 또한, 각 layer 의 parameter 수를 살펴 보면, 7x7 conv layer 는 C(이전 layer 의 channel 수)<em>7</em>7<em>C = 49 * C^2만큼의 parameter를 가지고 있고, 3 layer 3x3 conv layer 는 3</em>3<em>3</em>C<em>C = 9 * C^2 만큼의 parameter 를 가지고 있다. 작은 filter size로 layer 수를 늘리는 것이 *</em>parameter 의 갯수** 관점에서도 큰 이득을 가져다 준다.</p><p>cf) 네트워크가 깊어질수록 computation양을 일정하게 유지하기 위해 각 레이어의 입력을 downsampling 한다. &amp; Spatial Area 가 작아질수록 filter 의 depth 를 조금씩 늘려준다.</p><h2 id="3-GoogLeNet"><a href="#3-GoogLeNet" class="headerlink" title="3. GoogLeNet"></a>3. GoogLeNet</h2><h3 id="GoogLeNet-의-특이점"><a href="#GoogLeNet-의-특이점" class="headerlink" title="GoogLeNet 의 특이점"></a>GoogLeNet 의 특이점</h3><p>GoogleNet 은 깊은 신경망 모델에 대해, 계산량의 이점을 가져다주기 위해 고안되었다. 이는 Inception Module 을 설계하여, 이를 연속해 쌓는 방식의 구조이다. Inception Module 의 모양은 다음과 같다.</p><p>다음과 같이 구성할 때, conv layer 를 거친 output 을 depth 방향으로 concatenate 한다. spatial dimension 은 stride 등을 조절한다.</p><p><img src="Untitled-fc505115-1120-4553-895a-ff1017096753.png" alt></p><p>feature map 을 뽑기 위해 각 layer 의 filter 갯수를 조절할텐데, 효과적인 feature map 을 뽑기 위해 filter 갯수를 늘리게되면, 전체 Inception Module 이 쌓이면 쌓일 수록, parameter 수가 지수배 증가하는 단점이 발생한다. 여기서 GoogleNet 의 핵심 idea가 등장하는 듯 하다.</p><p><strong>1x1 convolution layer!</strong></p><p>1x1 convolution layer를 통해 spatial dimension 은 보존하면서, depth 는 줄인다. 즉 이 convolution layer 를 bottle neck 이 되는 conv layer 앞단에 구성하여, 입력을 더 낮은 차원으로 보낸다.</p><p><img src="Untitled-455ba9e5-8395-41e4-a9d3-c8543af2883e.png" alt></p><p><img src="Untitled-74d7882d-4001-440f-a9b1-a3198f244dfc.png" alt></p><p>또한 google net 은 parameter 가 많이 필요한 <strong>fc layer 를 제거</strong>하므로써 computational 이득을 취했다. </p><p><img src="Untitled-699859d1-387d-4936-8a1d-a191fbb5b6ef.png" alt></p><p>또한 Inception Module 이 쌓이면서, 깊게 쌓일 수록 loss 의 grdient  전파가 소실 되는 효과를 보완하기 위해 추가적인 classifier 를 곁가지에 닮으로써 gradient 를 추가적으로 update 한다.</p><h2 id="4-ResNet"><a href="#4-ResNet" class="headerlink" title="4. ResNet"></a>4. ResNet</h2><p>ResNet 은 conv layer 를 깊게 추가하는 것이 성능에 이득을 주는지에 대한 의문으로 시작한다. 즉, 답은 깊게 쌓는 것이 성능이 좋아지지 않는다는 것이다. </p><p><img src="Untitled-a0f95736-d7c0-4fc8-a918-f420a76b55c4.png" alt></p><p>위 그림의 test error 그래프를 보더라도, 성능면에서 conv layer 의 증가가 좋은 성능을 가져다 주지 않는 것이 아니다. test error 그래프만 본다면, overfitting 된 것이 아닌가? 라는 생각을 할 수 있으나, training error 그래프를 보면, 학습 조차 잘 되지 않았음을 확인 할 수 있다.</p><p>즉, 깊이가 깊은 모델이 어느 순간부터는 얕은 모델보다 성능이 안좋아 질 수 있는 문제가 발생한다. 이 문제를 degradation 문제라고 한다.</p><h3 id="ResNet-의-특이점"><a href="#ResNet-의-특이점" class="headerlink" title="ResNet 의 특이점"></a>ResNet 의 특이점</h3><p>ResNet의 구조적 특이점은 바로 skip connection 이다. skip connection 은 이렇게, layer 의 입력과 출력이 더해져, 다음 layer 에 대한 입력으로 이루어 지는 구조를 의미한다.기존의 Neural Net 의 구조를 remind 해본다. 기존 뉴럴넷은 입력 x 가 들어갈 때, 출력 y 를 얻기 위한 H(x)를 찾아내는 과정이다. H(x)가 y 에 최대한 가깝게 하기 위한 즉, H(x) - y 가 0 이 될 수 있도록 최소화 과정을 거쳐 H(x) 를 찾아낸다. 이에 반해 ResNet 은 layer 를 거친 F(x) 와 x 가 더해진 F(x) + x 를 H(x)로 보고 이를 H(x) - x 를 최소화한다. 이는 residual 로 볼 수 있는 F(x)를 최소화한다는 의미이다. </p><p><img src="Untitled-9906cfd9-51eb-4c7f-a3fe-9cd43b5929b7.png" alt></p><h2 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h2><p><a href="https://www.youtube.com/watch?v=DAOcjicFr1Y" target="_blank" rel="noopener">Lecture 9 | CNN Architectures</a></p><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/07/26/CS231n-Lecture09-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture07-Training Neural Networks part2</title>
      <link>https://emjayahn.github.io/2019/07/22/CS231n-Lecture07-Summary/</link>
      <guid>https://emjayahn.github.io/2019/07/22/CS231n-Lecture07-Summary/</guid>
      <pubDate>Mon, 22 Jul 2019 04:12:21 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Lecture-07-Training-Neural-Networks-part2&quot;&gt;&lt;a href=&quot;#Lecture-07-Training-Neural-Networks-part2&quot; class=&quot;headerlink&quot; title=&quot;Lecture 07: Training Neural Networks part2&quot;&gt;&lt;/a&gt;Lecture 07: Training Neural Networks part2&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lecture-07-Training-Neural-Networks-part2"><a href="#Lecture-07-Training-Neural-Networks-part2" class="headerlink" title="Lecture 07: Training Neural Networks part2"></a>Lecture 07: Training Neural Networks part2</h1><ul><li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li></ul><a id="more"></a><h2 id="1-Fancier-Optimization"><a href="#1-Fancier-Optimization" class="headerlink" title="1. Fancier Optimization"></a>1. Fancier Optimization</h2><h3 id="1-1-Problems-with-SGD"><a href="#1-1-Problems-with-SGD" class="headerlink" title="1-1. Problems with SGD"></a>1-1. Problems with SGD</h3><ul><li>Loss function 의 gradient 방향이 고르지 못해, 지그재그 형태로 업데이트가 일어나고, 그 업데이트가 느리게 발생된다. 고차원으로 갈수록, 자주 만날 수 있는 문제.</li><li>Local Minima &amp; Saddle point: 높은 차원에서 생각해보면, Local Minima 는 고차원의 모든 gradient 방향에 대해 전부 loss 가 증가하는 방향이므로, 이 경우보다는 Saddle point 문제가 훨씬더 빈번하게 발생한다. Saddle point 의 경우 그 포인트 자체도 문제지만, 그 근처에서 gradient 가 매우 작기 때문에 update 를 해도 매우 느린 문제가 있다.</li><li>SGD 의 S - stochastic! : 미니 배치의 loss 를 가지고 전체 training loss 를 추정하는 것이므로, 노이즈가 포함된 추정일 수 밖에없다.</li></ul><h3 id="1-2-다양한-최적화-알고리즘-기법"><a href="#1-2-다양한-최적화-알고리즘-기법" class="headerlink" title="1-2. 다양한 최적화 알고리즘 기법"></a>1-2. 다양한 최적화 알고리즘 기법</h3><p>최적화 알고리즘은 간단하게 정리한다.</p><ul><li>SGD, SGD + Momentum, Nesterov Momentum : 진행방향과 그 gradient (Momentum) 을 더해 실제로 업데이트 될 방향을 정한다.</li><li>AdaGrad : 이전에 진행했던  gradient 를 제곱하여, 업데이트가 진행 될 수록 학습률을 작게해, 세밀하게 업데이트한다.</li><li>RMSProp : AdaGrad 가 gradient 를 제곱할 때, 학습의 후반부에 갈수록 gradient 가 0 에 가까워 지게 되므로, 제곱하는 term 의 비율을 설정해 0으로 가는 것을 막는다.</li><li>Adam : Momentum 방법과 AdaGrad를 합친 방법으로써, 학습률을 조절하면서, 속도를 조절하는 방법이다.</li></ul><h2 id="2-Regularization"><a href="#2-Regularization" class="headerlink" title="2. Regularization"></a>2. Regularization</h2><h3 id="2-1-Dropout"><a href="#2-1-Dropout" class="headerlink" title="2-1. Dropout"></a>2-1. Dropout</h3><p>앞선 강의에서 다양한 Regularization 방법들을 살펴 보았었다.L2, L1, Elastic Net 등. 이번 강의에서는 신경망에서 자주 사용되는 dropout 방법을 살펴본다. Dropout 이란 forward 진행시, 일부 뉴런을 0으로 만들어 버리는 것을 말한다. dropout layer 는 우리가 그 dropout rate 을 설정하므로써, 어떤 확률로 꺼질지 설정할 수 있다. dropout 은 먼저 각 뉴런이 서로 동화되는 것을 방지함으로써 다양한 표현방식을 지닐 수 있게 한다. 또한, dropout 은 여러 sub model 을 앙상블 하는 효과를 낼 수 있다.</p><p>Dropout Layer 를 사용할 시 주의 할 점은 evaluation, inference 시, 네트워크의 출력에 dropout 확률을 곱해주어야 한다는 점이다. 혹은 test 시에는 기존 출력을 그대로 사용하고, train 할 때 dropout확률로 나눠주는 방법이다. (keras 에는 후자로 구현되어있는 듯 하다.)</p><p>p.s. Batch Normalization 에 regularization 의 효과가 있으므로, 일반적으로 BN 과 dropout 을 같이 사용하지는 않는다. 하지만 dropout 에는 우리가 조절할 수 있는 dropout rate 이 있는 장점이 있다.</p><h3 id="2-2-Data-Augmentation"><a href="#2-2-Data-Augmentation" class="headerlink" title="2-2. Data Augmentation"></a>2-2. Data Augmentation</h3><p>신경망은 기본적으로 데이터가 많으면 많을 수록 학습에 유리한 이점이 있다. 따라서 우리가 가지고 있는 데이터를 조금씩 변형하여, 학습 데이터를 늘려주는 방법을 사용할 수 있다. horizontal flip이나, 사진에 일부분을 자르는 방법, Color jittering(이미지의  contrast, brightness 를 변형해준다)</p><h3 id="2-3-Drop-Connect"><a href="#2-3-Drop-Connect" class="headerlink" title="2-3.  Drop Connect"></a>2-3.  Drop Connect</h3><p>Activation 이 아닌, weight 을 확률적으로 0을 만들어 주는 방법</p><h3 id="2-4-Fractional-Max-Pooling"><a href="#2-4-Fractional-Max-Pooling" class="headerlink" title="2-4. Fractional Max Pooling"></a>2-4. Fractional Max Pooling</h3><p>고정된  Pooling window 를 랜덤으로 정하는 방법. 자주 사용되지는 않는다.</p><h2 id="3-Transfer-Learning"><a href="#3-Transfer-Learning" class="headerlink" title="3. Transfer Learning"></a>3. Transfer Learning</h2><p>유명한 모델과 깊은 네트워크는 대부분 많은량의 데이터와 많은 하드웨어 Resource와 시간이 투입되서 구축된다. 우리가 이 모델구조를 가져와 우리의 목적에 맞게 사용하려고 보면, 우리가 가지고 있는 데이터와 자원의 한계로 학습에 실패하거나 그 시간이 매우 오래 걸리곤 한다. Transfer Learning 은 기존에 학습되어있는 모델 구조와 그 weight 을 가져와, 마지막 Fully Connected Layer 를 우리의 task 에 맞게 수정하고 이 부분만 학습하는 개념을 말한다. </p><p><img src="Untitled-efed7ce8-fb60-4622-ad9c-c01d764a5308.png" alt></p><h2 id="4-Reference"><a href="#4-Reference" class="headerlink" title="4. Reference"></a>4. Reference</h2><p><a href="https://www.youtube.com/watch?v=_JB0AO7QxSA" target="_blank" rel="noopener">Lecture 7 | Training Neural Networks II</a></p><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/07/22/CS231n-Lecture07-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture06-Training Neural Networks part1</title>
      <link>https://emjayahn.github.io/2019/07/18/CS231n-Lecuture06-Summary/</link>
      <guid>https://emjayahn.github.io/2019/07/18/CS231n-Lecuture06-Summary/</guid>
      <pubDate>Thu, 18 Jul 2019 11:38:56 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Lecture-06-Training-Neural-Networks-part1&quot;&gt;&lt;a href=&quot;#Lecture-06-Training-Neural-Networks-part1&quot; class=&quot;headerlink&quot; title=&quot;Lecture 06: Training Neural Networks part1&quot;&gt;&lt;/a&gt;Lecture 06: Training Neural Networks part1&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lecture-06-Training-Neural-Networks-part1"><a href="#Lecture-06-Training-Neural-Networks-part1" class="headerlink" title="Lecture 06: Training Neural Networks part1"></a>Lecture 06: Training Neural Networks part1</h1><ul><li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li></ul><a id="more"></a><h2 id="1-One-time-setup"><a href="#1-One-time-setup" class="headerlink" title="1. One time setup"></a>1. One time setup</h2><h3 id="1-1-Activation-Functions"><a href="#1-1-Activation-Functions" class="headerlink" title="1-1. Activation Functions"></a>1-1. Activation Functions</h3><p>Activation Function 마다 각 특성과 trade off 가 있다. 많이 사용되는 activation function 이 있지만, LU 계열의 activation function 은 모두 실험의 parameter가 될 수 있다.</p><p>(1) Sigmoid</p><p>$$\sigma(x) = \frac{1}{1+e^{-x}}$$</p><p><img src="Untitled-f80c60bd-97fe-4db9-a0a3-3a8a8c38907c.png" alt></p><p>sigmoid function 의 경우, 수식의 특성상 실수 space 에 있는 값들을 [0, 1] 범위 내로 좁혀 주는 기능을 해, 역사적으로 오래된 activation function 이다. 하지만 다음과 같은 단점이 있다.</p><ul><li>단점<ul><li>일정 범위(Saturated 되는 범위)부터 gradient가 0에 가까워진다.</li><li>sigmoid 의 출력 결과가 zero-centered 가 되지 않는다.</li><li>minor 한 단점이지만, exponential 의 계산이 비효율적이다.(비싸다고 표현)</li></ul></li></ul><p>왜 <strong>zero-centered</strong> 가 중요한가?</p><p>$$f(\sum_iw_ix_i+b)$$</p><p>강의에서 설명해준 직관적인 방법이 매우 도움이 되었다.</p><p>Backpropagation 을 생각해 보게 되면, Neuron(Node) 안에서 local gradient 와 loss 에서 부터 오는 upstream gradient 가 곱해지게 된다. 위 식에서 w 에 대해 local gradient 를 구하면 x_i 가 되는 것을 확인 할 수 있다. 만약 xi 가 모두 양수라고 가정한다면, f()의 gradient 는 항상 양수 또는 음수이고, 이는 w 가 모두 같은 방향으로 움직인다는 것을 의미한다. 즉, 비효율적인 gradient update 라고 할 수 있다. </p><p>(2) hyper tangent : Tanh(x)</p><p>$$tanh(x)=\frac{e^{2x}-1}{e^{2x}+1}$$</p><p><img src="Untitled-c1d35d05-3ea2-49a8-9e8a-5c85bbc519a7.png" alt></p><p>위와 같은 zero-centered problem 을 해결하기 위해 tanh(x) 를 사용할 수 도 있다. (추가적으로, 수업시간에 언급은 없었으나, tanh의 등장배경을 설명하는 또다른 한가지는 sigmoid  와 tanh 의 gradient의 최댓값이 4배 차이가 나므로, backpropagation 에서 gradient vanishing 현상을 방지하는 기대효과로 설명하기도 한다.)하지만, 이 역시 sigmoid 처럼 saturate 되는 부분에서 gradient 가 0이 되는 현상이 아직 남아있다.</p><p>(3) ReLU</p><p>$$f(x) = max(0, x)$$</p><p><img src="Untitled-5850722c-4016-4335-b77a-d5237ed6d5b6.png" alt></p><p>ReLU 의 경우, 가장 우리가 많이 볼 수 있는 activation function 이다. 다음과 같은 장점이 있다고 설명한다.</p><ul><li>장점<ul><li>양수인 구간에서는 gradient 가 0이 되지 않고</li><li>계산이 효율적이다.</li><li>sigmoid 와 tanh 에 비해 실제로 6배 빠른 converge 성능을 보여준다.</li></ul></li><li>단점<ul><li>zero-centered output이 아니다.</li><li>0보다 작은 구간에서는 gradient 가 0이 된다.</li></ul></li></ul><p>(4) Leaky ReLU</p><p>$$f(x) = max(0.01x, x)$$</p><p><img src="Untitled-ed8a9855-d2ce-4756-93d5-e042e0a7b823.png" alt></p><p>0보다 작은 구간에서 ReLU 처럼 Saturate 되는 단점을 없애고자, 0보다 작은 구간에서 작은 gradient 를 주는 것이 Leary Relu 이다. </p><ul><li>장점<ul><li>양수 구간 뿐만아니라 음수 구간에서 gradient 를 작게 주어 gradient 가 0 이 되지 않게 한다.</li><li>ReLU function 과 마찬가지로, 계산이 효율적이고</li><li>sigmoid 와 tanh 에 비해 빠르게 수렴한다.</li></ul></li></ul><p>Parametric Rectifier(PReLU) 라는 이름으로, 좀더 generalize 된 형태도 사용한다. $max(\alpha x, x)$ 형태로써, alpha 를 고정시키지 않고 학습시키는 형태이다.</p><p>(5) Exponential Linear Units (ELU)</p><p>$$f(x)=\begin{cases}x \quad\quad\quad\quad if \quad x&gt;0 \<br>\alpha(exp(x) -1) \quad if \quad x\leq 0 \end{cases}$$</p><p><img src="Untitled-b527e985-4c1c-475f-a01a-6f8bdb006ceb.png" alt></p><p>(6) Maxout Neuron</p><p>ReLU function 의 Generalize 된 형태라고 생각할 수 있다.</p><p>$$max(w_1^{T}x + b_1, w_2^Tx + b_2)$$</p><p>하지만, 이 형태는 각 뉴런마다 두 배의 parameter를 가지고 그 output 값 간의 비교를 하므로, 연산량이 두배가 많아지는 단점이 있다.</p><p>(6) Summary</p><ul><li>ReLU 를 사용한다!</li><li>Leaky ReLU, Maxout, ELU 를 실험해볼 수 있다.</li><li>tanh 도 실험할 수 있지만, 큰 효능을 기대하기 힘들다</li><li><strong>Don’t Use sigmoid</strong></li></ul><h3 id="1-2-Data-Preprocessing"><a href="#1-2-Data-Preprocessing" class="headerlink" title="1-2. Data Preprocessing"></a>1-2. Data Preprocessing</h3><p>앞서 살펴 보았던 것 처럼, 입력 데이터에 있어서 zero-centered 가 매우 중요한 preprocessing key 라고 생각 할 수 있다. 머신러닝에서 처럼 다양한 normalized 기법과 whitening 기법들이 있지만, 뉴럴넷, 특히 이미지 데이터에 대해서는 zero-centered 까지만 전처리 해준다. 이는 모든 차원의 데이터가 같은 범위안에 있게 함으로써 각 차원이 equally contribute 하게 하기 위함이다.</p><p><img src="Untitled-417f2e92-c3d6-4bc1-825e-7dfc79a52956.png" alt></p><h3 id="1-3-Weight-Initialization"><a href="#1-3-Weight-Initialization" class="headerlink" title="1-3. Weight Initialization"></a>1-3. Weight Initialization</h3><p>우리가 설정하는 각 layer 의 weight 을 어떻게 초기화 해줄 것인가의 문제도 뉴럴넷의 학습과 성능에 영향이 있을 수 있다. 작은 gaussian random number 로 모든 weight 을 초기화 해 줄 경우, layer 를 지날 수록 activation function 을 거친 작은 output 과 초기화 된  작은 w 가 곱해져, 점차 그 분산이 작아 지는 것을 확인 할 수 있다. </p><p><img src="Untitled-96d3f546-0140-4ccf-b6b1-925eb79dba94.png" alt></p><p>따라서, 이런 가우시안 랜덤으로 초기화 해주는 것이 아닌 다른 초기화 방법이 등장하였다.</p><ul><li>Xavier Initialization &amp; He Initialization</li></ul><p>개인적으로 Xavier Initialization 과 He Initialization 을 간단하게 실험해 본 내용은 나의 github에 올려두었다. 비교군 설정에 있어, 미흡하지만 직관적으로 이해하기 쉽게 실험해 본 내용이다. 간단한 api 를 통해 구현하였기에, 자세한 수식과 개념은 해당 논문을 읽어보고, 정리해봐야겠다.</p><p>github: <a href="https://github.com/EmjayAhn/TIL/blob/master/03_Pytorch/02_xavier%26he.ipynb" target="_blank" rel="noopener">Xavier vs He experiment</a></p><h3 id="1-4-Batch-Normalization"><a href="#1-4-Batch-Normalization" class="headerlink" title="1-4. Batch Normalization"></a>1-4. Batch Normalization</h3><p>결국 우리는 모든 activation 이 unit gaussian form  이길 원한다. 위에서도 살펴 보았듯이, activation function  에 들어가기 전에 모든 fully connected layer 의 출력이 saturate 구간에 있게 하고 싶지 않은 것이다. 따라서, 주로 Batch Normalization 은 <strong>Fully Connected Layer 이후 비선형함수 전</strong> 또는 <strong>Convolution Layer 다음</strong> 에 들어가게 된다.</p><p>이 때, 주의 해야할 점은 Convolution Layer 다음에 들어가는 batch normalize 는 activation map 으로 나온 channel 별로 수행해주게 된다.</p><ol><li>batch mean 과 variance 는 각 차원별로 계산해 준다.</li><li>Normalize </li></ol><p>$$\hat{x}^{(k)} = \frac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$$</p><p>앞서, batch normalization 의 목적은 network의 forward, backward pass 시 saturation 이 일어나지 않게 하기 위함이었습니다. 하지만 반면에, 이렇게 batch normalization 을 해준 이후에도 우리는 network 이 얼마나 해당 activation 을 얼마나 saturate 시킬지까지 학습 할 수 있다면 얼마나 좋을까요? 따라서 우리는 normalize 이후에 scaling factor 와 shifting factor 를 추가시켜, 얼마나 saturate 시킬지까지 학습할 수 있는 parameter 를 추가합니다.</p><p>$$y^{(k)} = \gamma^{(k)}\hat{x}^{(k)} + \beta^{k}$$</p><p>Batch Noramlization 에 대한 pseudo 알고리즘이다.</p><p><img src="Untitled-83e0b3e7-d764-4a19-9c28-9fe815096b28.png" alt></p><p>또한, 우리는 이렇게 학습한 batch mean 과 variance  를 학습 때 사용하며, testing (inference) 시에는 다시 계산하지 않는 것을 유의해야한다. testing 시에는 training 시 running average 등의 방식으로 고정된 mean과 variance 등을 사용할 수 있다.</p><h2 id="2-Training-Dynamics"><a href="#2-Training-Dynamics" class="headerlink" title="2. Training Dynamics"></a>2. Training Dynamics</h2><h3 id="2-1-Babysitting-the-Learning-Process"><a href="#2-1-Babysitting-the-Learning-Process" class="headerlink" title="2-1. Babysitting the Learning Process"></a>2-1. Babysitting the Learning Process</h3><ol><li><p>Preprocess the data</p></li><li><p>Build Model</p></li><li><p>Sanity check for model (e.g. weigh이 작을ㄹ 때, loss가 negative log likelihood 와 비슷한지, regularization term이 추가될때 loss 가 증가하는지 등)</p></li><li><p>(regularization term 을 사용하지 않고) 매우 작은 데이터에 대해서, train  을 돌렸을 때, loss 가 떨어지고, 금방 overfitting 되는지 확인</p><br>여기까지가 sanity check 이라면, 이제 본격적인 training!!<br></li><li><p>간단한 몇가지 실험을 통해 learning rate 을 정한다. 큰 값, 작은 값을 넣어보고, epoch 을 10까지 정도로 주었을 때, loss 가 주는 지 확인하여 대략적인 범위를 정한다.</p></li><li><p>Coarse search: learning rate 과 다른 hyper parameter 를 uniform 등과 같은 distribution 을 통해 random search 한다. 강의에서 말했던, 주의사항 : 범위의 양 끝에 가장 좋은 score 가 뿌려져 있다면, 다시 범위를 설정해야한다. 내가 처음 설정한 범위 끝단에 존재한다면 그 주변에서 다시 최적의 값이 존재 할 수 있기 때문이다.</p></li><li><p>Finer search: 최적의 값을 찾기 위해 세세하게 튜닝한다.</p></li></ol><h3 id="2-2-Hyperparameter-Optimization"><a href="#2-2-Hyperparameter-Optimization" class="headerlink" title="2-2. Hyperparameter Optimization"></a>2-2. Hyperparameter Optimization</h3><ul><li>많은 양의 Cross Validation 을 통해 성능을 비교, 검증하며 최적의 hyper parameter 를 찾아야한다!</li><li>Grid Search &lt;&lt; Random Search<ul><li>Random Sampling 을 통해 좀더 중요한 parameter 의 분포를 찾아 낼 수 있어, Random search 가 효과적</li></ul></li></ul><h2 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3. Reference"></a>3. Reference</h2><p><a href="https://www.youtube.com/watch?v=wEoyxE0GP2M" target="_blank" rel="noopener">Lecture 6 | Training Neural Networks I</a></p><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/07/18/CS231n-Lecuture06-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>볼 때마다 헷갈리는 Iterable, Iterator, Generator 정리하기</title>
      <link>https://emjayahn.github.io/2019/07/15/iterator-generator/</link>
      <guid>https://emjayahn.github.io/2019/07/15/iterator-generator/</guid>
      <pubDate>Mon, 15 Jul 2019 14:03:23 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Iterable-vs-Iterator-vs-Generator&quot;&gt;&lt;a href=&quot;#Iterable-vs-Iterator-vs-Generator&quot; class=&quot;headerlink&quot; title=&quot;Iterable vs Iterator vs Generator&quot;&gt;&lt;/a&gt;Iterable vs Iterator vs Generator&lt;/h1&gt;&lt;hr&gt;
&lt;p&gt;다른 분들의 코드를 읽을 때마다, 내가 사용할 때마다, 헷갈리는 Iterable, Iterator, Generator를 이번 글을 작성해보면서, 마지막으로! (라는 다짐으로) 정리해봅니다. 잘 알고 있는 개념이라고 생각했지만, 다른 사람들로부터의 질문을 받았을 때, 나의 설명이 만족스럽지 못해 ‘아 내가 더 정확히 알아야 한다’ 는 메타인지로부터 출발하는 글입니다.&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Iterable-vs-Iterator-vs-Generator"><a href="#Iterable-vs-Iterator-vs-Generator" class="headerlink" title="Iterable vs Iterator vs Generator"></a>Iterable vs Iterator vs Generator</h1><hr><p>다른 분들의 코드를 읽을 때마다, 내가 사용할 때마다, 헷갈리는 Iterable, Iterator, Generator를 이번 글을 작성해보면서, 마지막으로! (라는 다짐으로) 정리해봅니다. 잘 알고 있는 개념이라고 생각했지만, 다른 사람들로부터의 질문을 받았을 때, 나의 설명이 만족스럽지 못해 ‘아 내가 더 정확히 알아야 한다’ 는 메타인지로부터 출발하는 글입니다.</p><a id="more"></a><br>파이썬의 장점으로 꼽히는, '사용하기 쉬운 데이터 구조'들 덕분에 우리는 루프를 돌아야하는 알고리즘에 대해 손쉽게 코드를 작성 할 수 있습니다. 하지만, 때로는 나만의 객체(class)를 만들고 그 객체가 파이썬에 내장 되어있는 데이터 구조 처럼, 동작하기를 바랍니다.<br>요즘 들어, 제가 짜는 코드에서 이 욕구는 신경망 모델링을 할 때, 신경망 모델 객체에 데이터의 배치를 feeding 하는 객체를 생성하고 싶을 때, 넘쳐나게 됩니다. 이럴 때, 파이썬에 대한 기본 개념이 잘 잡혀있지 않은 상태에서 복잡한 코드를 짜려고 하는 시도를 하니, 신경망 모델 자체의 구조에 대해서도 복잡한데 이런 루프를 돌면서 반복적으로 일정 데이터를 넘겨주기 위한 간단한 기능을 가진 코드에 대해서도 비효율적으로 작성하게 됩니다. 이런 제 자신의 문제를 해결하기 위해 이번 기회에 Iterator 와 Generator 에 대해 확실하게 정리해보려고 합니다. (feat. 예제코드)<hr><h2 id="1-이터러블-Iterable"><a href="#1-이터러블-Iterable" class="headerlink" title="1. 이터러블: Iterable"></a>1. 이터러블: Iterable</h2><blockquote><p>Iterable 객체란? : 객체 안에 있는 원소(element)를 하나씩 반환 가능한 객체</p></blockquote><p><img src="iterable_def.png" alt></p><p>파이썬이 제공하는 대부분의 내장 데이터 구조는 이터러블(Iterable)한 객체 입니다. 뿐만 아니라 우리가 만든 객체(class)도 Iterable 객체가 될 수 있습니다. 이터러블(Iterable)객체는 for 문과 같은 루프 뿐만 아니라, zip이나 map 과 같은 순서대로 처리할 입력이 필요한 곳에서도 사용 될 수 있습니다.<br><br><br><br>이터러블(Iterable) 객체는 <code>iter()</code> 라는 함수의 입력으로 들어갑니다. <code>iter()</code> 라는 함수는 다음에 설명될 이터레이터(Iterator)를 반환합니다.</p><hr><h2 id="2-이터레이터-Iterator"><a href="#2-이터레이터-Iterator" class="headerlink" title="2. 이터레이터: Iterator"></a>2. 이터레이터: Iterator</h2><blockquote><p>Iterator 객체란? : Iterator의 <code>__next__()</code> 나 내장 함수인 <code>next()</code>를 부르면서, 원소(element)를 순차적으로 반환 할 숫 있는 객체</p></blockquote><p><img src="iterator_def.png" alt></p><p>앞서, 설명드린대로 이터레이터(Iterator)는 iter()라는 함수가 <strong>반환</strong>하는 객체입니다. 그리고, 이터레이터(Iterator)는 반복적으로 <code>__next__()</code>나, <code>next()</code> 함수의 입력으로 들어가 호출하여, <code>next()</code>의 return 값인 원소(element)를 최종적으로 반환합니다.<br><br><br>이터레이터(Iterator)가 다음 원소를 계속 반환하다가, 끝에 다달아 반환할 원소가 없을 경우 예외문인 <code>StopIteration</code>이 발생하게 됩니다.<br><br><br>즉, 정리하면, <br><br>Iterable 객체 A → iter(A) → Iterator 객체 B → next(B) → element (data)</p><hr><blockquote><p>Question? 우리는 list 같은 이터러블(Iterable) 객체와 for 문을 쓰면서 한번도 iter() 나 next()를 보지 못했는뎁쇼????<br>파이썬의 for 문은 이터러블(Iterable) 객체를 만나, 내부적으로 <code>iter()</code> 함수를 호출하여, 이터레이터(Iterator)를 생성합니다. 이 생성된 이터레이터(Iterator)가 루프가 실행되면서 <code>next()</code> 를 호출하며 반복적인 데이터를 뽑아 낼 수 있게 되는 것입니다. 그리고 모든 원소가 뽑아지고 난 뒤에는 <code>StopIteration</code> 이 발생하며, for 문이 종료 됩니다.</p></blockquote><hr><p>위 설명을 코드로 풀어쓰면, 다음과 같습니다. 우리가 다음과 같은 for 문을 사용하면,</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> element <span class="hljs-keyword">in</span> iterable_object:</span><br><span class="line">    print(element)</span><br></pre></td></tr></table></figure><p>위 코드는 다음과 같이 파이썬 내부적으로 다음과 같이 동작하게 됩니다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># iter() 함수를 호출해, iterator 를 생성하고,</span></span><br><span class="line">iterator_object = iter(iterable_object)</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">while</span> <span class="hljs-keyword">True</span>:</span><br><span class="line">    <span class="hljs-comment"># next() 함수를 호출해, element 를 받아옵니다.</span></span><br><span class="line">    <span class="hljs-keyword">try</span>:</span><br><span class="line">        element = next(iterator_object)</span><br><span class="line">        print(element)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># element 가 없을 시, StopIteration Exception 발생</span></span><br><span class="line">    <span class="hljs-keyword">except</span>: StopIteration:</span><br><span class="line">        <span class="hljs-keyword">break</span></span><br></pre></td></tr></table></figure><hr><h2 id="3-이터러블-Iterable-이터레이터-Iterator-와-친해지기"><a href="#3-이터러블-Iterable-이터레이터-Iterator-와-친해지기" class="headerlink" title="3. 이터러블(Iterable), 이터레이터(Iterator)와 친해지기"></a>3. 이터러블(Iterable), 이터레이터(Iterator)와 친해지기</h2><h3 id="3-1-간단-버전"><a href="#3-1-간단-버전" class="headerlink" title="3-1. 간단 버전"></a>3-1. 간단 버전</h3><p>파이썬 이터러블(Iterable) 내장 데이터 구조인 list 를 활용하여, 실습해 봅니다. </p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>iterable_object = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>iterator_object = iter(iterable_object)</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>iterator_object</span><br><span class="line">&lt;list_iterator object at <span class="hljs-number">0x104fe2278</span>&gt;</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>next(iterator_object)</span><br><span class="line"><span class="hljs-number">1</span></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>next(iterator_object)</span><br><span class="line"><span class="hljs-number">2</span></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>next(iterator_object)</span><br><span class="line"><span class="hljs-number">3</span></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>next(iterator_object)</span><br><span class="line"><span class="hljs-number">4</span></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>next(iterator_object)</span><br><span class="line"><span class="hljs-number">5</span></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>next(iterator_object)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="hljs-string">"&lt;stdin&gt;"</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure><h3 id="3-2-나만의-iterable-iterator객체"><a href="#3-2-나만의-iterable-iterator객체" class="headerlink" title="3-2. 나만의 iterable, iterator객체"></a>3-2. 나만의 iterable, iterator객체</h3><p>다음의 코드는 이름과 나이를 받는 데이터 객체입니다. 루프를 돌면서 각각 순서에 맞는 (이름, 나이)형태로 데이터를 반환하는 Iterable 객체입니다. 같은 기능을 하는 더욱 효율적인 코드를 짤 수 있겠지만, 공부한 iterable 과 iterator 를 적용해보는 class 입니다.</p><script src="https://gist.github.com/EmjayAhn/70e4232632f340a8f67e0ba1509029c5.js"></script><hr><h2 id="4-제너레이터-Generator"><a href="#4-제너레이터-Generator" class="headerlink" title="4. 제너레이터: Generator"></a>4. 제너레이터: Generator</h2><blockquote><p>제너레이터(Generator)란?: <strong>특이한</strong> (공식 문서에 <del>~</del> iterator) 이터레이터(Iterator)</p></blockquote><p><img src="generator_def.png" alt></p><p>정의에서도 보다시피, 이터레이터(Iterator)입니다. 즉, <code>next()</code> 함수를 만나 동작하는 함수입니다. 이 때, 제너레이터(Generator) 를 일반 함수와 다르게 하는 것이 <code>yield</code> 라는 문법입니다. <code>yield</code> 는 일반 함수의 <code>return</code>과 같이 값을 반환 하지만, <code>return</code>과 다르게 해당 함수(generator)가 종료하지 않고, 그대로 유지됩니다. 다음 순서의 제너레이터(Generator)가 호출되면, 멈추었던 <code>yield</code> 자리에서 다시 함수가 동작하게 됩니다.<br><br></p><p>요약하자면, <br><br>제너레이터(Generator) → next(제너레이터) → 제너레이터 함수 실행 → <code>yield</code>를 만나 next(제너레이터가) 호출된 곳으로 값을 반환 (제너레이터 종료 ❌) → 다시 next(제너레이터) → 멈추었던 <code>yield</code>부터 재실행 </p><hr><blockquote><p>Question? 이런 특이하고, 어렵고, 처음엔 익숙하지 않은 제너레이터(Generator)를 왜 때문에 쓰는 겁죠???<br>제너레이터는 메모리를 아끼기 위해서 사용합니다!!! 다음의 코드에서 메모리 사용량의 비교를 통해 살펴 보겠습니다.</p></blockquote><hr><h2 id="5-제너레이터-Generator-와-친해지기"><a href="#5-제너레이터-Generator-와-친해지기" class="headerlink" title="5. 제너레이터 (Generator)와 친해지기"></a>5. 제너레이터 (Generator)와 친해지기</h2><p>제너레이터를 사용한 코드가 메모리 사용량 측면에서 얼마나 효율적인지 확인해보겠습니다. 다음의 코드는 999999까지의 숫자를 제곱하여 return 해주는 함수입니다. 첫번째, 일반적인 함수는 end 숫자까지 for 문을 돌면서 그 결과를 저장한 뒤에 return 해줍니다. 두번째 generator 는 for 문이 돌 때, yield 에서 해당 데이터만 리턴하게 되므로, 메모리 사용에서 효율적입니다. 다음의 실험에서도 쉽게 비교할 수 있습니다.</p><script src="https://gist.github.com/EmjayAhn/943cde0f7e9794f76272e531c8fffcca.js"></script><p>위 코드 실행결과: <br></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Memory Usage when program start: 8.80859375</span><br><span class="line">Memory Usage when program end: 56.0390625</span><br></pre></td></tr></table></figure><script src="https://gist.github.com/EmjayAhn/8ab50ebfdbf3adabeab8f07f20dd0e01.js"></script><p>위 코드 실행결과: <br></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Memory Usage when program start: 8.78515625</span><br><span class="line">Memory Usage when program end: 8.78515625</span><br></pre></td></tr></table></figure><hr><h2 id="6-마무리"><a href="#6-마무리" class="headerlink" title="6. 마무리"></a>6. 마무리</h2><p>이번 짧은 글에서, Iterable, Iterator, Generator 를 비교해보면서 그 개념과 사용 예제를 간단하게 살펴 보았습니다. 이름에서부터 헷갈릴 수 있는 각 객체에 대한 내용을 이 글을 통해 조금이나마 정리해볼 수 있는 기회가 되셨으면 좋겠으며, 작은 도움이 되셨으면 합니다.</p><hr><h2 id="7-Reference"><a href="#7-Reference" class="headerlink" title="7. Reference"></a>7. Reference</h2><ul><li><a href="https://docs.python.org/3.7/glossary.html#term-generator" target="_blank" rel="noopener">Python documentation: generator</a></li><li><a href="https://docs.python.org/3.7/glossary.html#term-iterable" target="_blank" rel="noopener">Python documentation: iterable</a></li><li><a href="https://docs.python.org/3.7/glossary.html#term-iterator" target="_blank" rel="noopener">Python documentation: iterator</a></li></ul>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/07/15/iterator-generator/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS224n]Lecture01-WordVecs</title>
      <link>https://emjayahn.github.io/2019/07/06/CS224n-Lecture01-Summary/</link>
      <guid>https://emjayahn.github.io/2019/07/06/CS224n-Lecture01-Summary/</guid>
      <pubDate>Sat, 06 Jul 2019 08:38:25 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;CS224n-Lecture-1-Introduction-and-Word-Vectors&quot;&gt;&lt;a href=&quot;#CS224n-Lecture-1-Introduction-and-Word-Vectors&quot; class=&quot;headerlink&quot; title=&quot;[CS224n] Lecture 1: Introduction and Word Vectors&quot;&gt;&lt;/a&gt;[CS224n] Lecture 1: Introduction and Word Vectors&lt;/h1&gt;&lt;p&gt;Standford University 의 CS224n 강의를 듣고 정리하는 글입니다.&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CS224n-Lecture-1-Introduction-and-Word-Vectors"><a href="#CS224n-Lecture-1-Introduction-and-Word-Vectors" class="headerlink" title="[CS224n] Lecture 1: Introduction and Word Vectors"></a>[CS224n] Lecture 1: Introduction and Word Vectors</h1><p>Standford University 의 CS224n 강의를 듣고 정리하는 글입니다.</p><a id="more"></a><h2 id="1-Human-Language-and-Word-Meaning"><a href="#1-Human-Language-and-Word-Meaning" class="headerlink" title="1. Human Language and Word Meaning"></a>1. Human Language and Word Meaning</h2><p><strong>Word meaning</strong> 의 뜻 : symbol → idea or thing : Denotational Semantics</p><p>우리가 ‘의자’라는 단어를 예로 들자면, 말하는 사람과 듣는 사람 모두 의자와 관련된 특정한 이미지와 아이디어 등을 생각해 볼 수 있다. 이렇게 단어에 대해 관념적인 것을 word meaning 이라고 할 수 있다. 그렇다면 컴퓨터에서 사용할 수 있는 <strong>word meaning</strong> 은 어떤 것이 있을까?</p><h3 id="In-Computer-Word-Representations"><a href="#In-Computer-Word-Representations" class="headerlink" title="In Computer Word Representations"></a>In Computer Word Representations</h3><ol><li>WordNet: synonym 과 hypernyms 의 집합으로 표현 (e.g: nltk wordnet)<ul><li>아주 귀한 dataset 이지만,</li><li>단점: Nuance (뉘앙스)를 담아내지 못함, 새로운 단어에 대해 사람이 직접 가공하여 추가해주어야 한다. 단어의 동의어에 대해 계산할 수 없음</li></ul></li><li>Discrete Symbols: One-hot-vectors<ul><li>단점 : 벡터의 차원이 우리가 가지고 있는 단어의 갯수만큼 커지게 된다. Corpus 의 구성 단어가 커질 수록 계산 해야하는 벡터 차원이 매우 커진다. 이는 컴퓨팅 자원의 부족으로 인한 현실적 구현의 어려움을 야기시킨다.</li><li>One-hot-Vector 는 Vector Space 에서 모두 서로 orthogonal (직교)한다. 즉, similarity 가 모두 0으로 단어간의 관계를 알기 힘들다.</li></ul></li><li>By CONTEXT: Word Vecttors<ul><li>“You shall know a word by the company it keeps” (J.R.Firth)</li><li>어떤 특정 단어 w 가 나온다는 것은, 그 주변 단어들(context)이  있기 때문이다.</li><li>Word Vectors == Word Embeddings == Word Representations == Distributed Representation</li></ul></li></ol><h2 id="2-Word2vec-Introduction"><a href="#2-Word2vec-Introduction" class="headerlink" title="2. Word2vec Introduction"></a>2. Word2vec Introduction</h2><p>Word2vec(Mikolov et al. 2013) 은 Word Vectors 를 만들기 위한 알고리즘 중 가장 기초 뼈대를 이루는 알고리즘이다.</p><ol><li>가지고 있는 텍스트 데이터를 구성하는 큰 CORPUS</li><li>Corpus 의 모든 단어는 RandomVector 로 시작한다.</li><li>각 position t 에 대해, 중심단어 c(center) 와 주변단어 o(outside) 를 생각할 수 있다.</li><li>중심단어 c 가 주어질 때, 주변단어 o 의 확률을 구하기 위해(skip-gram)(반대로도 가능(cbow): 주변단어가 주어질 때, 중심단어의 확률을 구하는 방법), 중심단어 c 와 주변단어 o, word 벡터들에 대해 similarity를 구한다.</li><li>위의 확률을 최대화 하기 위해 word vector 를 updating 한다.</li></ol><p><img src="Untitled-cc28ca48-12e4-4a20-a6c4-b0be86d339d8.png" alt></p><h2 id="3-Word2vec-objective-function-gradients"><a href="#3-Word2vec-objective-function-gradients" class="headerlink" title="3. Word2vec objective function gradients"></a>3. Word2vec objective function gradients</h2><p>문장의 특정 위치 t 에 대해 (t = 1, …, T), 중심단어w_j가 주어졌을때, 주변단어를 한정하는 window size m 에 대해  주변단어들을 예측하는 Likelihood 는 다음과 같습니다. likelihood 식을 해석해보면, 중심단어 w_t 에 대해 중심단어를 중심으로 window 사이즈 2m 개의 단어들의 확률을 모두 곱하고, T 개의 단어 갯수에 대해 또 다시 모두 곱합니다.</p><p>$$Likelihood\quad L(\theta)= \prod_{t=1}^{T}\prod_{-m \leq j \leq m}P(w_{t+j}|w_{t};\theta)$$</p><p>목적함수는 likelihood 를 바탕으로 minimize와 average, 계산 편의를 위해 log 를 씌웠다는 것외에 likelihood 와 동일하다.</p><p>$$objective function \quad J(\theta) = - \frac{1}{T}logL(\theta)=-\frac{1}{T}\sum_{t=1}^{T}\sum_{-m \leq j \leq m, j\neq0}logP(w_{t+j} | w_{t};\theta)$$</p><p>단어가 등장할 확률을 구하는 방법은 Softmax Function 을 활용합니다.</p><p><img src="Untitled-99acc04b-91fd-451c-868f-574d995778b3.png" alt></p><h3 id="Objective-Function-의-derivative"><a href="#Objective-Function-의-derivative" class="headerlink" title="Objective Function 의 derivative"></a>Objective Function 의 derivative</h3><p>Objective Function 과 단어 확률 (Softmax) 의 미분을 구하는 과정이다. </p><p><img src="Untitled-d45516b7-8024-457c-bda2-39092a1f6892.png" alt></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/07/06/CS224n-Lecture01-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[GCP] Computing Engine 환경설정</title>
      <link>https://emjayahn.github.io/2019/06/17/gcp-setting/</link>
      <guid>https://emjayahn.github.io/2019/06/17/gcp-setting/</guid>
      <pubDate>Mon, 17 Jun 2019 11:54:01 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Computing-Engine-환경설정&quot;&gt;&lt;a href=&quot;#Computing-Engine-환경설정&quot; class=&quot;headerlink&quot; title=&quot;Computing Engine 환경설정&quot;&gt;&lt;/a&gt;Computing Engine 환경설정&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이번 글은, Google Cloud Platform의 Computing Engine 인스턴스의 기본적인 환경설정 방법을 소개하는 글입니다. 직접 작업환경을 세팅하면서, 정리 하는 목적으로 작성하는 글입니다.&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Computing-Engine-환경설정"><a href="#Computing-Engine-환경설정" class="headerlink" title="Computing Engine 환경설정"></a>Computing Engine 환경설정</h1><ul><li>이번 글은, Google Cloud Platform의 Computing Engine 인스턴스의 기본적인 환경설정 방법을 소개하는 글입니다. 직접 작업환경을 세팅하면서, 정리 하는 목적으로 작성하는 글입니다.<br></li></ul><a id="more"></a><ul><li>다음과 같은 환경을 설정합니다.</li></ul><ol><li>인스턴스 생성 및 네트워크 설정</li><li>접속을 위한 ssh 생성 및 접속</li><li>python3, pip3 설치</li><li>CUDA 설치</li><li>cuDNN 설치</li><li>Pytorch 설치</li><li>Jupyter 설치 및 환경설정</li></ol><h2 id="1-인스턴스-생성-및-네트워크-설정"><a href="#1-인스턴스-생성-및-네트워크-설정" class="headerlink" title="1. 인스턴스 생성 및 네트워크 설정"></a>1. 인스턴스 생성 및 네트워크 설정</h2><p>Compute Engine에서 자신의 목적에 맞는 리소스를 정해, 인스턴스를 생성해줍니다.</p><p><img src="Untitled-aa8ea35c-8d35-4efb-8fda-520336241429.png" alt></p><p>Jupyter  notebook 을 사용하기 위해, VPC 네트워크 → 방화벽 규칙 탭에서 방화벽 규칙을 만들어 줍니다. 후에 Tensorboard 와 다른 기타 환경들을 사용할 때 그에 맞는 포트 규칙을 동일한 방법으로 열어주면 됩니다. 아래의 4가지를 설정해주고 ‘만들기’ 클릭</p><p>이름 : jupyter</p><p>소스 IP 범위: 0.0.0.0/0</p><p>대상 태그: jupyter</p><p>tcp: 8888</p><p>http, https: 체크</p><p><img src="Untitled-e502c0fe-c454-4da1-bf99-5ee9c057bab5.png" alt></p><h2 id="2-접속을-위한-RSA-key-pair-생성-및-ssh-접속"><a href="#2-접속을-위한-RSA-key-pair-생성-및-ssh-접속" class="headerlink" title="2. 접속을 위한 RSA key pair 생성 및 ssh 접속"></a>2. 접속을 위한 RSA key pair 생성 및 ssh 접속</h2><ul><li>gcp 에서 제공하는 gcloud로도 접속 할 수 있습니다.</li></ul><ol><li><p>위에서 생성한 인스턴스에 접속하기 위해, RSA key pair 를 이를 통해 접속 해 봅니다. 아래의 명령어를 이용해 키페어를 생성해 줍니다. 이 때, USERNAME 은 gcp에 등록한 이메일로 설정합니다.</p><p> $ ssh-keygen -t rsa -f ~/.ssh/[KEYFILE_NAME] -C “[USERNAME]”</p><p> example) $ ssh-keygen -t rsa -f ~/.ssh/gcp-key -C “<a href="mailto:myemail@mail.com" target="_blank" rel="noopener">myemail@mail.com</a>“</p></li></ol><p>앞으로 사용할 Password 를 입력하고, </p><p>생성된 키페어는 <code>.ssh</code> 폴더 안에서 확인 할 수 있습니다. <code>.ssh/[KEYFILE_NAME].pub</code> 를 확인해 볼 수 있습니다.</p><ol start="2"><li>생성한 키페어를 gcp 의 메타데이터 탭 → SSH 키에 등록합니다.</li></ol><p><img src="Untitled-ac2cd300-7176-46cc-92d2-aa405a955f85.png" alt></p><ol start="3"><li><p>ssh 접속</p><p> $ ssh -i ~/.ssh/[KEYFILE_NAME] [USERNAME]@[GCP외부IP]</p></li></ol><h2 id="3-Python3-PIP-설치"><a href="#3-Python3-PIP-설치" class="headerlink" title="3. Python3, PIP 설치"></a>3. Python3, PIP 설치</h2><p>위에서 서버에 접속했다면, 서버의 개발환경을 설정해 주기만 하면 됩니다. python3 와 pip 부터 설치해 봅니다.</p><ol><li>locale 설정<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install language-pack-ko</span><br><span class="line">$ sudo locale-gen ko_KR.UTF-8</span><br><span class="line"></span><br><span class="line">$ <span class="hljs-built_in">export</span> LC_ALL=<span class="hljs-string">"en_US.UTF-8"</span></span><br><span class="line">$ <span class="hljs-built_in">export</span> LC_CTYPE=<span class="hljs-string">"en_US.UTF-8"</span></span><br><span class="line">$ sudo dpkg-reconfigure locales</span><br></pre></td></tr></table></figure></li></ol><p>en_US.UTF-8이 [*] 로 체크 되어 있는지까지 확인합니다.</p><ol start="2"><li>Python3, PIP 설치<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install python3-pip</span><br></pre></td></tr></table></figure></li></ol><p>설치 후, <code>python3 --version</code> 으로 python 이 잘 설치 되었는지 확인합니다.</p><h2 id="4-CUDA-설치"><a href="#4-CUDA-설치" class="headerlink" title="4. CUDA 설치"></a>4. CUDA 설치</h2><p>우리가 가장 원하는 리소스인 gpu를 활용한 연산을 위해 CUDA 를 설치 해 줍니다.</p><ol><li>먼저, 설치 파일을 다운로드 해줍니다.</li></ol><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 루트에서</span><br><span class="line">$ wget [http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/](https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64)</span><br></pre></td></tr></table></figure><ol start="2"><li><code>ls</code> 로 cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb 이 잘 다운로드 되었는지 확인 해 줍니다. 다운로드 결과 <code>.deb</code> 확장자가 되어있지 않다면, 파일명에 .deb 를 뒤에 붙여 줍니다.</li></ol><p><code>mv cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64 cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb</code></p><ol start="3"><li>설치<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb</span><br><span class="line">$ sudo apt add /var/cuda-repo-&lt;version&gt;/7fa2af80.pub</span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install cuda</span><br></pre></td></tr></table></figure></li></ol><p>CUDA 가 정상적으로 설치되었다면,  <code>$ nvidia-smi</code> 를 통해 자신의 gpu 상태를 확인 할 수 있습니다. 또한, <code>/usr/local/cuda/version.txt</code> 에 설치한 CUDA, 현재는 10.0의 version 을 확인 할 수 있습니다.</p><h2 id="5-cuDNN-설치"><a href="#5-cuDNN-설치" class="headerlink" title="5. cuDNN 설치"></a>5. cuDNN 설치</h2><p>다음의 명령어를 통해 cuDNN 을 설치 할 수 있습니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sh -c <span class="hljs-string">'echo "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /" &gt;&gt; /etc/apt/sources.list.d/cuda.list'</span></span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install libcudnn7-dev</span><br></pre></td></tr></table></figure><h2 id="6-Pytorch-설치"><a href="#6-Pytorch-설치" class="headerlink" title="6. Pytorch 설치"></a>6. Pytorch 설치</h2><ul><li>우리는 서버가 https 프로토콜을 사용한다고 체크했으므로 -H  flag 를 주어 sudo pip3 를 활용해야합니다.<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo pip3 -H install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl</span><br><span class="line">$ sudo pip3 -H install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl</span><br></pre></td></tr></table></figure></li></ul><h2 id="7-Jupyter-Notebook-설치-및-환경설정"><a href="#7-Jupyter-Notebook-설치-및-환경설정" class="headerlink" title="7. Jupyter Notebook 설치 및 환경설정"></a>7. Jupyter Notebook 설치 및 환경설정</h2><ol><li>Jupyter를 설치합니다.<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo -H pip3 install jupyter</span><br></pre></td></tr></table></figure></li></ol><p>설치 후, <code>$ jupyter notebook</code> 으로 주피터 커널이 켜지는지 확인합니다.</p><ol start="2"><li><p>주피터 config 파일을 생성합니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter notebook --generate-config</span><br></pre></td></tr></table></figure></li><li><p>비밀번호를 생성합니다. 이 비밀번호는 지금 설치한 주피터 환경에 들어가기 위한 비밀번호 입니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ipython</span><br><span class="line">from notebook.auth import passwd</span><br><span class="line">passwd()</span><br><span class="line">Enter Password: 사용할 비밀번호 입력</span><br><span class="line">Verify Password: 사용할 비밀번호 입력</span><br></pre></td></tr></table></figure></li></ol><p>출력된 비밀번호 해쉬  <code>sha1: ~~~</code> 를 복사해 둡니다.</p><ol start="4"><li>우리의 인스턴스는 https 프로토콜을 사용하므로, SSL 키파일을 생성해야 합니다.<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout cert.pem -out cert.pem</span><br></pre></td></tr></table></figure></li></ol><p>위 명령어를 입력하고, 뒤따라 나오는 정보들을 입력하여, <code>.pem</code> 파일을 생성합니다.</p><ol start="5"><li><ol start="2"><li>에서 생성한 config 파일 수정<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi /home/[USERNAME]/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure></li></ol></li></ol><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// config 파일에 다음의 내용을 추가합니다.</span><br><span class="line">c = get_config()</span><br><span class="line">c.NotebookApp.ip = &apos;내부아이피주소&apos;</span><br><span class="line">c.NotebookApp.open_browser=False</span><br><span class="line">c.NotebookApp.password=&apos;3에서 생성한 비밀번호 해쉬 sha1:~&apos;</span><br><span class="line">c.Notebook.certfile=&apos;4에서 생성한 .pem 파일 경로 /home/USERNAME/cert.pem&apos;</span><br></pre></td></tr></table></figure><p>위까지 완료하게 되었으면, 주피터 서버를 열고,  <code>https://외부아이피:8888</code>  로 주피터를 접속 하는 것을 확인하시면 되겠습니다.</p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/06/17/gcp-setting/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Classification Metrics</title>
      <link>https://emjayahn.github.io/2019/06/03/Classification-Metrics/</link>
      <guid>https://emjayahn.github.io/2019/06/03/Classification-Metrics/</guid>
      <pubDate>Mon, 03 Jun 2019 03:18:57 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Classification-Metrics-분류-성능-지표&quot;&gt;&lt;a href=&quot;#Classification-Metrics-분류-성능-지표&quot; class=&quot;headerlink&quot; title=&quot;Classification Metrics: 분류 성능 지표&quot;&gt;&lt;/a&gt;Classification Metrics: 분류 성능 지표&lt;/h1&gt;&lt;p&gt;Kaggle Classification 의 Evaluation 에 자주 사용되는 ROC-AUC를 정리해보면서, 이번 기회에 분류모델에서 자주 사용되는 성능지표(Metric)을 간단하게 정리해봅니다. &lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Classification-Metrics-분류-성능-지표"><a href="#Classification-Metrics-분류-성능-지표" class="headerlink" title="Classification Metrics: 분류 성능 지표"></a>Classification Metrics: 분류 성능 지표</h1><p>Kaggle Classification 의 Evaluation 에 자주 사용되는 ROC-AUC를 정리해보면서, 이번 기회에 분류모델에서 자주 사용되는 성능지표(Metric)을 간단하게 정리해봅니다. </p><a id="more"></a><p>Confusion Matrix 에서 비롯되는 Metric 들은 이를 이미지로 기억하는 것이 효율적입니다.</p><h2 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h2><p>confusion matrix  는 해당 데이터의 정답 클래스(y_true) 와 모델의 예측 클래스(y_pred)의 일치 여부를 갯수로 센 표입니다. 주로, 정답 클래스는 행으로(row), 예측 클래스는 열로(columns) 표현합니다. </p><p><img src="Untitled-170ac3e3-8259-4e1a-80e5-647b5bd326fd.png" alt></p><ul><li>(정의하기에 따라 다르지만) 일반적으로, class 1 을 positive로, class 0 을 negative 로 표기합니다.</li><li>우리가 예측한 클래스를 기준으로 Positive 와 Negative 를 구분합니다.</li><li>그리고 정답과 맞았는지, 틀렸는지를 알려주기 위해 True 와 False 를 각각 붙여줍니다.</li></ul><h2 id="Accuracy-정확도"><a href="#Accuracy-정확도" class="headerlink" title="Accuracy: 정확도"></a>Accuracy: 정확도</h2><ul><li>전체 데이터에 대해 맞게 예측한 비율</li></ul><p>$$<br>\frac{TP+TN}{TP+FN+FP+TN}<br>$$</p><h2 id="Precision-정밀도"><a href="#Precision-정밀도" class="headerlink" title="Precision: 정밀도"></a>Precision: 정밀도</h2><ul><li>class 1 이라고 예측한 데이터 중, 실제로 class 1 인 데이터의 비율</li></ul><p>$$\frac{TP}{TP+FP}$$</p><p>우리의 모델이 기본적인 decision이 class 0 이라고 생각할 때, class 1 은 특별한 경우를 detect 한 경우 일 것입니다. 이 때 class 1 이라고 알람을 울리는 우리의 모델이 얼마나 세밀하게 class를 구분 할 수 있는지의 정도를 수치화 한 것입니다.</p><h2 id="Recall-재현율"><a href="#Recall-재현율" class="headerlink" title="Recall: 재현율"></a>Recall: 재현율</h2><ul><li>실제로 class 1 인 데이터 중에 class 1 이라고 예측한 비율</li><li>= Sensivity = TPR</li></ul><p>$$\frac{TP}{TP+FN}$$</p><p>제가 기억하는 방식은, 자동차에 결함이 발견되서 recall 이 되어야 하는데 (실제 고장 데이터중) 얼마나 recall 됐는지로 생각합니다. </p><h2 id="Fall-out-위양성율"><a href="#Fall-out-위양성율" class="headerlink" title="Fall-out: 위양성율"></a>Fall-out: 위양성율</h2><ul><li>실제로 class 1 이 아닌 데이터 중에 class 1이라고 예측한 비율</li><li>낮을 수록 좋음</li><li>= FPR = 1 - Specificity</li><li>Specificity = 1 - Fall out</li></ul><p>$$\frac{FP}{FP+TN}$$</p><p>실제로 양성데이터가 아닌 데이터에 대해서 우리의 모델이 양성이라고 잘못 예측한 비율을 말합니다. 억울한 데이터의 정도를 측정했다고 생각 할 수 있습니다.</p><h2 id="각-Metric-간의-상관관계"><a href="#각-Metric-간의-상관관계" class="headerlink" title="각 Metric 간의 상관관계"></a>각 Metric 간의 상관관계</h2><p>우리 모델의 decision function 을 f(x) 라 할 때, 우리는 f(x)의 결과와 threshold (decision point)를 기준으로 class를 구분합니다.</p><ul><li><p>Recall vs Fall-out : 양의 상관관계</p><p>  Recall은 위의 정의에 의하듯이, 실제로 positive  인  클래스에 대해 얼마나 positve 라고 예측했는지의 비율입니다. 우리가 Recall 을 높이기 위해서는 고정되어있는 실제 positive 데이터 수에 대해 예측하는 positive 데이터의 갯수 threshold 를 낮춰 늘리면 됩니다. 이에 반해 threshold 를 낮추게 되면, 실제로 positive 가 아닌 데이터에 대해 positive 라고 예측하는 억울한 데이터가 많아지므로 Fall-out 은 커지게 되고 둘은 양의 상관관계를 갖게 됩니다.</p></li><li><p>Recall vs Precision : 대략적인 음의 상관관계</p><p>  위에 설명한 것처럼 threshold 를 낮춰 우리가 예측하는 positive 클래스의 숫자를 늘리게 되면, recall 은 높아지는 반면, 예측한 positive 데이터 중 실제 positive 데이터의 비율은 작아 질 수 있습니다.</p></li></ul><h2 id="F-beta-score"><a href="#F-beta-score" class="headerlink" title="F-beta score"></a>F-beta score</h2><ul><li>precision 과 recall의 가중 조화평균</li></ul><p>$$(\frac{1}{1+\beta^2}\frac{1}{precision} + \frac{\beta^2}{1+\beta^2}\frac{1}{recall})^{-1}$$</p><p>이처럼, 다양한 Metric 에 대해 우리가 초점을 맞추는 것에 따라 모델의 성능은 다르게 바라 볼 수 있습니다. 따라서 모델에 대해 성능을 평가하고 최종 모델을 선택함에 있어, 서로 다른 Metric 을 동시에 비교해야합니다. 이를 위해 precision 과 recall 을 precision 에 beta^2 만큼 가중하여 바라보는 스코어가 F beta score 입니다.</p><p>이 중 beta=1 일 때, score 가 우리가 자주 보는 f1 score 입니다.</p><p>$$F_1=\frac{2<em>precision</em>recall}{precision+recall}$$</p><h2 id="ROC-Curve-Receiver-Operator-Characteristic-Curve"><a href="#ROC-Curve-Receiver-Operator-Characteristic-Curve" class="headerlink" title="ROC Curve: Receiver Operator Characteristic Curve"></a>ROC Curve: Receiver Operator Characteristic Curve</h2><ul><li>Recall vs Fallout 의 plot (TPR vs FPR)</li></ul><p>위의 예시 처럼, 우리가 클래스를 판별하는 기준이 되는 threshold (decision point) 를 올리거나 내리면서, recall 과 fall out 은 바뀌게 됩니다. 이렇게 threshhold 를 변화 해 가면서, recall 과 fall out 을 plotting 한 것이 ROC curve 입니다.</p><ul><li>sklearn.metrics.roc_curve() 의 documentation</li></ul><p><img src="Untitled-1f189e32-c453-43c9-8366-559df3f16464.png" alt></p><h2 id="ROC-AUC-Area-Under-Curve"><a href="#ROC-AUC-Area-Under-Curve" class="headerlink" title="(ROC-)AUC: Area Under Curve"></a>(ROC-)AUC: Area Under Curve</h2><ul><li>위에서 그린 ROC Curve 의 넓이를 점수로써 사용하는 것이 AUC 입니다. AUC 의 유의미한 범위는 class 를 50%의 확률로 random 하게 예측한 넓이인 0.5 보다는 클 것이고, 가장 최대의 AUC 의 넓이는 1 일 것이므로 0.5≤AUC≤1 의 범위를 갖는 score 입니다.</li></ul><p><img src="Untitled-44d5d317-d0ec-4f1a-8aa0-8bdbfe34bd67.png" alt></p><ul><li>ROC 커브와 AUC score 를 보고 모델에 대한 성능을 평가 하기 위해서, ROC 는 같은 Fall out 에 대해 Recall  은 더 높길 바라고, 같은 Recall  에 대해서는, Recall  이 더 작길 바랍니다. 결국, 그래프가 왼쪽 위로 그려지고, AUC 즉 curve  의 넓이는 커지는 것이 더 좋은 성능의 모델이라고 볼 수 있습니다.</li></ul>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/06/03/Classification-Metrics/#disqus_thread</comments>
    </item>
    
    <item>
      <title>SPARK BASIC 1</title>
      <link>https://emjayahn.github.io/2019/05/31/SPARK-BASIC-1/</link>
      <guid>https://emjayahn.github.io/2019/05/31/SPARK-BASIC-1/</guid>
      <pubDate>Fri, 31 May 2019 12:07:52 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Apache-Spark-Basic-1&quot;&gt;&lt;a href=&quot;#Apache-Spark-Basic-1&quot; class=&quot;headerlink&quot; title=&quot;Apache Spark Basic 1&quot;&gt;&lt;/a&gt;Apache Spark Basic 1&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;SPARK 를 공부하면서 실습 과정을 정리해서 남깁니다.&lt;/li&gt;
&lt;li&gt;실습환경&lt;ol&gt;
&lt;li&gt;CentOS&lt;/li&gt;
&lt;li&gt;Spark 2.4.3&lt;/li&gt;
&lt;li&gt;Hadoop 2.7&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Apache-Spark-Basic-1"><a href="#Apache-Spark-Basic-1" class="headerlink" title="Apache Spark Basic 1"></a>Apache Spark Basic 1</h1><ul><li>SPARK 를 공부하면서 실습 과정을 정리해서 남깁니다.</li><li>실습환경<ol><li>CentOS</li><li>Spark 2.4.3</li><li>Hadoop 2.7</li></ol></li></ul><a id="more"></a><h1 id="1-Spark-shell"><a href="#1-Spark-shell" class="headerlink" title="1. Spark-shell"></a>1. Spark-shell</h1><h2 id="1-1-Introduction"><a href="#1-1-Introduction" class="headerlink" title="1-1. Introduction"></a>1-1. Introduction</h2><p>shell의 spark home directory 에서 다음 명령어를 통해 spark shell 을 진입할 수 있습니다.</p><pre><code>$ cd /spark_home_directory/$ ./bin/spark-shell</code></pre><p><img src="Untitled-d3bd9451-d568-49aa-bf5a-0f6b7bf598d9.png" alt></p><ul><li>sc : spark context</li><li>spark : spark session</li></ul><p>spark context 와 spark session 의 경우, spark shell에 띄우면서 내부적으로 선언된 변수명이다. </p><pre><code>$ jps// jps 명령어를 통해 현재 돌고 있는 spark process 를 확인할 수 있다. // spark processor 가 jvm 을 바탕으로 돌기 때문에, jvm 프로세스가 도는 것을 확인하므로써// 확인 할 수 있는 것이다.</code></pre><p><a href="http://localhost:4040" target="_blank" rel="noopener">http://localhost:4040</a>, 즉 해당 서버의 ip:4040 포트를 통해서 드라이버에서 제공되는 웹 UI 를 확인할 수 있다. 이 웹 UI 를 통해 현재 작동하는 프로세서와 클러스터들을 관리 할 수 있다.</p><h2 id="1-2-RDD"><a href="#1-2-RDD" class="headerlink" title="1-2. RDD"></a>1-2. RDD</h2><p>spark는 data를 처리할 때, RDD 와 Spark SQL 을 통해서 data object 를 생성하고 이를 바탕으로 다양한 pipeline 으로 동작 할 수 있다. RDD 를 처음 접해보는 실습.</p><pre><code>//scala shellval data = 1 to 10000val distData = sc.parallelize(data)distData.filter(_ &lt; 10).collect()</code></pre><ul><li><code>data</code> 가 RDD</li><li>sc.parallelize의 return 형 역시 parallelize 된 RDD, 즉 distData 도 RDD</li><li>마지막 command line 은 10보다 작은 data 에 대해 filtering 하고 각 executor 에서 실행된 자료를 collect()</li><li>spark 의 특징은 .collect() 와 같은 action api 가 실행될 때 모든 것이 실행되는 <strong>Lazy Evaluation (RDD)</strong>으로 동작한다.</li></ul><p>드라이버 웹 UI 를 통해 이를 확인 할 수 있다. 이전 command line 에서는 아무 동작도 일어나지 않다가 collect() action api 수행을 통해 실제로 command들이 수행되는 것을 확인 할 수 있다. local 에서 default 로 동작하기 때문에 2개의 partition 으로 동작하며, 어떤 shuffling 도 일어나지 않았기 때문에 1개의 stage 임을 확인 할 수 있다.</p><p><img src="Untitled-a49c2d30-d7d2-43bf-a2d0-7a54ff94d0c6.png" alt></p><pre><code>// scala shell// sc.textFile 을 통해 textfile, md 파일등을 읽어드릴 수 있다.val data = sc.textFile(&quot;file_name&quot;)// rdd 의 .map api 를 통해서 rdd 의 element 마다 val distData = data.map(r =&gt; r + &quot;_experiment!!&quot;)// 앞선 map 이 수행되고, 각 element(data) 갯수를 세개 된다.distData.count</code></pre><p>여기서는 .count 가 action api 이므로, .count 가 수행될 때, 앞선 command 들이 수행되게 된다.</p><p><code>sc.textFile()</code> 의 경우 ‘\n’, newline 을 기준으로 element 를 RDD 에 담게 된다.</p><p><code>RDD.toDebugString</code> 를 통해 해당 RDD 의 Lineage 를 확인 할 수 있다.</p><ul><li>가장 왼쪽에 있는 | 를 통해 stage 정보 역시 확인 할 수 있다. shuffle 이 일어나게 되면, stage가 바뀌므로, 서로 다른 stage  에 있는 command 의 경우, 다른 indent에 있게 된다.</li></ul><p><img src="Untitled-62b02b6f-4150-4dcf-8543-655381c951f7.png" alt></p><p><code>RDD.getNumPartitions</code> 를 통해 해당 RDD의 Partition 갯수 (=Task 의 갯수), 즉 병렬화 수준을 확인 할 수 있다.</p><p><img src="Untitled-a773c2aa-c715-4ccb-8b21-66eaaf1e22b3.png" alt></p><h3 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle!!"></a>Shuffle!!</h3><p>suffle 이 일어나는 경우는 api 마다 다양할 수 있다. 가장 기본적으로, 우리가 default partition 갯수를 변경하므로써 shuffle 이 일어나는 것을 확인 할 수 있다.</p><pre><code>val data = sc.textFile(&quot;file_name&quot;)data.getNumPartitions// Partition 의 숫자를 확인해보면, default 이므로 2 인 것을 확인 할 수 있다.val newData = data.repartition(10)newData.getNumPartitions// Partition 갯수가 10로 변경된 것을 확인 할 수 있다.newData.toDebugString// newData 의 Lineage 를 확인하면, repartition 이 일어나면서 shuffle 이 되고,// shuffle 로 인해 stage 가 2개가 되는 것을 확인 할 수 있다.(indentation)newData.count// action api 를 수행하여 앞선 command 를 모두 수행</code></pre><p><img src="Untitled-95d981bb-62a7-457f-9378-0b41db4d5b42.png" alt></p><p>위 command line 에 대한 DAG 를 웹 UI 를 통해 확인하면, 다음과 같이 stage 가 repartition을 기점으로 나누어 지는 것을 확인 할 수 있다.</p><p><img src="Untitled-ef367f62-d6f5-47da-9086-cdaa914aa5d7.png" alt></p><p>총 Partition의 갯수 (Task의 갯수)를 확인해 보면,  default 로 수행된 partition 2 개와, 우리가 설정해준 Partition 의 갯수인 10개를 합하여 12개인 것을 확인 할 수 있다.</p><p><img src="Untitled-6bf929e7-3f6d-4f2f-8898-04ca7ba404b6.png" alt></p><p>여기서 한 스텝을 더 들어가보면, spark 만의 특이한 특징을 확인 할 수 있다.</p><pre><code>// 위 코드에 이어서, newData 에 대해// newData RDD를 collect 해서 cli에 찍는 command 를 수행해보자.newData.collect.foreach(println)</code></pre><p>collect api 와 RDD의 element를 print 를 하는 action api 를 수행할 때, 지금까지 공부한 것으로 생각해 보면, text를 읽어서, 2개의 Partition 을 나누고, 다시 10개의 Partition 을 나누는 작업으로 이전의 12 개의 Task 와 다를게 없을 것 같은 느낌이다. 하지만 UI 를 통해 확인해보면, 10개의 Partition 으로 2개가 skipped 되었다고 확인할 수 있다. DAG 에서도, skipped 된 stage에 대해서 회색으로 확인된다.</p><p><img src="Untitled-6e461b14-8e34-4edb-91ad-6dd9ba2ba516.png" alt></p><p><img src="Untitled-85afaaf0-58d6-4533-995d-c5ec919da985.png" alt></p><p>이는 spark 에서 이 커맨드라인을 수행할 때, process 간 통신이 file 을 기반으로한 통신을 했기 때문이다. 제일 처음 <code>newData</code> 에 대해서 수행 될 때, 첫 stage 에서 shuffle 이 수행 될 때, 해당 파일을 각 executor 에서 shuffle write 을 하고 저장해두었다가, 두번째 stage 에서 shuffle  이 수행 될때, shuffle read 를 하는 방식으로 file을 기반으로 processor 가 통신하게 된다.</p><p><img src="Untitled-310cc7d4-4e31-4362-bf74-f0e046a27052.png" alt></p><p>따라서, spark 가 같은 command line 을 수행하게 되면 미리 shuffle write  된 file 을 읽기만 함으로써 앞선 stage 의 동일한 반복 작업을 수행하지 않게 되는 것이다. UI 를 확인 해보아도, shuffle read 만 수행 되었다. </p><p><img src="Untitled-e89e6c5f-89f8-475c-af4a-78c1e3ae8377.png" alt></p><h3 id="SaveFile"><a href="#SaveFile" class="headerlink" title="SaveFile!!!"></a>SaveFile!!!</h3><p><code>RDD.saveAsTextFile(&quot;directory_name&quot;)</code> api 를 활용하여, 어떤 처리가 끝난 RDD 를 저장할 수 있다. 이 때 주의 할 점은 parameter 에 들어 가는 것이 directory_name 이라는 것이다. 또한 partition 별로 파일이 저장된다. (e.g. 10개의 partition 이라면, 10개의 file이 저장된다.)</p><h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache!!!"></a>Cache!!!</h3><p>spark가 자랑하는 가장 큰 특징은, data(RDD) 를 memory에 cache  함으로써 처리의 속도가 매우 빠르다는 점이다. <code>RDD.cache</code> api 를 통해 memory 에 캐시할 수 있다. </p><pre><code>// distData RDD 에 이름을 부여distData.name = &quot;myData&quot;// cache!distData.cache// action : 5 개의 data 를 가져옴distData.take(5)// action : collectdistData.collect</code></pre><p><code>distData.take(5)</code> 까지 한 결과를 UI 에서 cache 를 살펴보면, 다음과 같다.</p><p><img src="Untitled-54196c66-b41c-4216-af72-5a70b030b321.png" alt></p><p>우리가 설정 한 것 처럼, RDD 의 이름이 myData 로 들어간것을 확인 할 수 있고 cache  역시 확인 할 수 있다. 하지만, Cached  된 비율을 확인하면 전체 RDD  에서 50% 만 된 것을 확인 할 수 있다. 반면에, <code>distData.collect</code> action 을 취하게 되면, Fraction Cached  가 100% 가 된 것을 확인 할 수 있다.</p><p><img src="Untitled-8f50bedc-ace7-4c09-9450-fb277ee5830b.png" alt></p><p>이는 우리의 action 에 따라 cache 할 용량이 달라 질 수 있기 때문이다. spark 입장에서 take(5) api 는 전체 RDD 중 5개의 element data 만 가져오면되고, 이 때 2개의 Partition 중 하나의 Partition 만 cache 해도 충분하기 때문에 Fraction Cached가 50%라고 나오는 것이다. 반면 collect api 는 collect 자체가 각 executor 에 있는 data 를 driver 로 모두 가져오는 것이므로 100% cache 하게 된다.</p><p><strong>Cache 에서 중요한 것은, 각 executor 의 cache 를 위한 가용 메모리 공간이 해당 Partition의 용량보다 작을 경우, 저장 할 수 있는 용량만큼 저장되는 것이 아니라, 해당 Partition 은 아예 저장이 안되게 된다. 이 점은 Cache를 할 때, Partition 의 용량과 해당 Executor 의 가용 메모리 공간을 미리 파악하여, 설계해야 한다.</strong></p><h3 id="Word-Count-예제"><a href="#Word-Count-예제" class="headerlink" title="Word Count 예제!!!"></a>Word Count 예제!!!</h3><p>우리가 데이터 분석을 할 때, 가장 basic 한 방법은 해당 데이터의 갯수를 세어 보는 것이다. 본 예제에서는 텍스트 파일을 읽어, 띄어쓰기를 바탕으로 word token을 나누고, 이를 세어보자.</p><p>WordCount 예제는 매우 basic 한 코드이므로, 어떤 로직으로 돌아가는지 완벽한 이해와 코드작성이 필수라고 생각한다.</p><pre><code>val originalDataRDD = sc.textFile(&quot;text-file&quot;)val wordcountRDD = originalDataRDD.flatMap(line =&gt; line.split(&quot; &quot;))                                        .map(word =&gt; (word, 1)).reduceByKey(_ + _)wordcountRDD.collect.foreach(println)</code></pre><ol><li>originalDataRDD 에서 text-file을 읽고,</li><li>line 마다 띄어쓰기를 기준으로 split 하고 이를 .flatMap 을 통해, flatten 하게 됩니다.</li><li>그리고 .map 을 통해 (word, 1) tuple 형태로 mapping 합니다.</li><li>.reduceByKey 를 통해 같은 word 에 대해 그 counting 갯수를 더하게 된 것을 RDD 로 return 하게 됩니다.</li></ol>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/31/SPARK-BASIC-1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture05-CNN</title>
      <link>https://emjayahn.github.io/2019/05/20/CS231n-Lecture05-Summary/</link>
      <guid>https://emjayahn.github.io/2019/05/20/CS231n-Lecture05-Summary/</guid>
      <pubDate>Mon, 20 May 2019 08:36:09 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Lecture-05-Convolutonal-Neural-Networks&quot;&gt;&lt;a href=&quot;#Lecture-05-Convolutonal-Neural-Networks&quot; class=&quot;headerlink&quot; title=&quot;Lecture 05: Convolutonal Neural Networks&quot;&gt;&lt;/a&gt;Lecture 05: Convolutonal Neural Networks&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lecture-05-Convolutonal-Neural-Networks"><a href="#Lecture-05-Convolutonal-Neural-Networks" class="headerlink" title="Lecture 05: Convolutonal Neural Networks"></a>Lecture 05: Convolutonal Neural Networks</h1><ul><li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li></ul><a id="more"></a><h2 id="1-Convolution-Layer"><a href="#1-Convolution-Layer" class="headerlink" title="1. Convolution Layer"></a>1. Convolution Layer</h2><h3 id="1-1-Fully-Connected-Layer-와-Convolution-Layer-의-비교"><a href="#1-1-Fully-Connected-Layer-와-Convolution-Layer-의-비교" class="headerlink" title="1-1. Fully Connected Layer 와 Convolution Layer 의 비교"></a>1-1. Fully Connected Layer 와 Convolution Layer 의 비교</h3><p>32 x 32 x 3 image 가 있다고 하자. network 에 주입하기 위해, 1 x 3072 로 핀 data 를 상상해 보자.</p><p>Fully Connected Layer 의 경우, 아래 그림 처럼, Weight 과 dot product 가 수행되어, activation 값이 나오게 된다. 이 때, activation 의 갯수는 W 의 크기에 따른다.</p><p><img src="Untitled-c7b225ec-cc03-4a1b-900f-558beebc21b5.png" alt></p><p>Fully Connected Layer 의 경우, 사진이라는 공간적 구조(Spatial Structure) 가 중요한 data 에 대해, 공간적인 정보를 다 잃어버리는 문제가 발생한다. 공간적 정보를 보존하기 위해 Convolution Layer 를 사용한다. </p><h3 id="1-2-Convolution-Layer-Overview"><a href="#1-2-Convolution-Layer-Overview" class="headerlink" title="1-2. Convolution Layer Overview"></a>1-2. Convolution Layer Overview</h3><p><img src="Untitled-7729c470-9f6b-4d19-9656-cc46c1dfb812.png" alt></p><p>이 때, 실제 convolution 계산은 image 의 filter 크기 만큼의 matrix 를 vectorize 한 후, filter vector 와 dot product 로 수행한다고 한다. 따라서 이 때 헷갈리지 않도록 할 것은, 한번의 Convolution 연산 결과는 <strong>하나의 scalar value</strong> 가 된다. 따라서, 하나의 filter 가 이미지 한 장을 훑어 내려간다면, 원본 이미지보다는 조금 작은 depth 가 1인 <strong>activation map</strong> 이 결과로 나온다.</p><p><img src="Untitled-fce64257-258e-4b3e-93ab-d0543662984f.png" alt></p><p>따라서 activation map 의 깊이(channel 수)는, <strong>filter 의 갯수</strong> 와 동일하다. 여러개의 필터는 이미지의 각기 다른 특징을 추출하려는 의도에서 사용된다.</p><p>그 후, 이 Convolution 의 결과인 activation map 을 비선형 함수(ReLU 등)에 통과 시킨다.</p><p><strong>여러 유명한 ConvNet 들은 이렇게, Convolution Layer 와 비선형함수를 반복적으로 나열 한 Network  라고 볼수 있다</strong></p><h3 id="1-3-Convolution-Layer-의-결과물"><a href="#1-3-Convolution-Layer-의-결과물" class="headerlink" title="1-3. Convolution Layer 의 결과물"></a>1-3. Convolution Layer 의 결과물</h3><p>이렇게 여러 계층의 Convolution Layer를 쌓는 것은, 가장 아래 Layer 부터 높은 Layer 까지 단순한 feature → 복잡한 feature 를 뽑아 내는 것으로 볼 수 있다.</p><p><img src="Untitled-5fec1f58-a947-449b-8d71-772aac9a6f3e.png" alt></p><h3 id="1-4-Convolution-Layer-연산"><a href="#1-4-Convolution-Layer-연산" class="headerlink" title="1-4. Convolution Layer 연산"></a>1-4. Convolution Layer 연산</h3><p><img src="Untitled-2a8adbad-1f2a-4fac-898d-aac944438a1b.png" alt></p><p>filter 가 이미지를 훑고 지나가면서 convolution 연산을 한 후, 나온 결과는 원본 이미지보다 그 크기가 작아지게 된다. 그 정도는 filter 의 크기와 filter 가 훑고 지나가는 간격인 stride 에 따라 바뀌게 된다. </p><p>$$output ;size = (N-F)/stride + 1$$</p><p><strong>문제점:</strong></p><ol><li><p>convolution 연산의 문제는 이미지의 모서리에 있는 정보는 가운데에 있는 이미지의 정보보다 적게 추출 되는 문제가 있다.(filter 가 모서리를 넘어서는 이동 할 수 없으므로)</p></li><li><p>convolution layer 를 반복적으로 지나가다 보면, map의 크기가 매우 빠르게 작아지게 된다. </p></li></ol><p>이를 위해 적용하는 것이 Padding 이다.</p><h3 id="1-5-Padding"><a href="#1-5-Padding" class="headerlink" title="1-5. Padding"></a>1-5. Padding</h3><p>모서리에 정보를 얻기 위해 이미지이 외곽에 숫자를 채워 주는 방법. 이 때, 많이 사용하는 방법은 zero-padding. zero-padding 외에도 다양한 방법이 있다.</p><h2 id="2-Pooling-Layer"><a href="#2-Pooling-Layer" class="headerlink" title="2. Pooling Layer"></a>2. Pooling Layer</h2><p>Parameter 의 갯수를 줄이기 위해, 우리가 ConvLayer 를 통해 뽑아낸 image 를 작게 만드는 Layer  이다. 즉, Downsampling 을 위한 것.</p><p>Maxpooling 의 intuition : 앞선 layer filter 가 각 region  에서 얼마나 활성 되었는지 보는 것이다. </p><h3 id="3-Typical-Architecture"><a href="#3-Typical-Architecture" class="headerlink" title="3. Typical Architecture"></a>3. Typical Architecture</h3><p>[[(Conv → RELU) * N → Pool] * M → (FC → RELU) * K ] → SOFTMAX</p><ul><li>N : ~ 5</li><li>M : Large</li><li>K : 0 ~ 2<ul><li>ResNet, Google net 등은 이 방식을 훨씬더 뛰어넘음</li></ul></li></ul><h2 id="4-Reference"><a href="#4-Reference" class="headerlink" title="4. Reference"></a>4. Reference</h2><p><a href="https://www.youtube.com/watch?v=bNb2fEVKeEo" target="_blank" rel="noopener">Lecture 5 | Convolutinoal Neural Networks</a></p><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/20/CS231n-Lecture05-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture04-Backprop/NeuralNetworks</title>
      <link>https://emjayahn.github.io/2019/05/18/CS231n-Lecture04-Summary/</link>
      <guid>https://emjayahn.github.io/2019/05/18/CS231n-Lecture04-Summary/</guid>
      <pubDate>Sat, 18 May 2019 14:21:08 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Lecture-04-Backpropagation-and-Neural-Networks&quot;&gt;&lt;a href=&quot;#Lecture-04-Backpropagation-and-Neural-Networks&quot; class=&quot;headerlink&quot; title=&quot;Lecture 04: Backpropagation and Neural Networks&quot;&gt;&lt;/a&gt;Lecture 04: Backpropagation and Neural Networks&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lecture-04-Backpropagation-and-Neural-Networks"><a href="#Lecture-04-Backpropagation-and-Neural-Networks" class="headerlink" title="Lecture 04: Backpropagation and Neural Networks"></a>Lecture 04: Backpropagation and Neural Networks</h1><ul><li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li></ul><a id="more"></a><h2 id="1-Backpropagation"><a href="#1-Backpropagation" class="headerlink" title="1. Backpropagation"></a>1. Backpropagation</h2><h3 id="1-1-핵심"><a href="#1-1-핵심" class="headerlink" title="1-1. 핵심"></a>1-1. 핵심</h3><p>Backprop의 한줄요약: 각 parameter 에 대해 Loss Function 의 gradient 를 구하기 위해 사용하는 graphical representation of <strong>ChainRule</strong></p><p>언뜻 보면 어려울 수 도 있지만, just ChainRule</p><p><img src="Untitled-13d44613-a85b-4dcc-a807-8b114b0138c4.png" alt></p><p>위의 그림을 예를 들어 살펴 보면, y 에 대한 f의 gradient 는 q에 대한 f의 gradient * y 에 대한 q 의 gradient 으로 볼 수 있다. 이를 해석하자면, f 에게 미치는 y 의 영향 = f 에게 미치는 q의 영향 * q 에게 미치는 y 의 영향으로 볼 수 있다.</p><p>Backpropagation 의 가장 중요한 특징!!</p><pre><code>gradient 를 구하기 위해 node 를 기준으로 앞과 뒤만 보면 된다.</code></pre><p><img src="Untitled-f2d8c1d9-1a28-4e16-8e35-83ff9f93045f.png" alt></p><p>또한, 위 그림을 보게 되면, Forward passing 과 마찬가지로, Backprop 시에도, 이전 노드에서 전달 되는 Gradient 를 node 에서 local gradient 와의 연산으로 다음 Node 에 gradient 를 전달해 줄 수 있다.</p><h3 id="1-2-Back-prop-시-각-node-의-역할"><a href="#1-2-Back-prop-시-각-node-의-역할" class="headerlink" title="1-2. Back prop 시, 각 node  의 역할"></a>1-2. Back prop 시, 각 node  의 역할</h3><p><img src="Untitled-7a11e194-ea07-4922-a7b5-aa4346476acb.png" alt></p><ol><li><p>Add gate : gradient distributor</p><ul><li>add gate 를 기점으로, 각 입력(forward 방향의 입력)의 gradient로 local gradient 를 구하면 1이므로, 전달 되는 gradient 와 각각 1씩 곱해져 전달 되게 된다. 이 현상을 보게 되면 동등하게 나눠주는 역할을 하므로 gradient distributor 라고 볼 수 있다.</li></ul></li><li><p>Max gate : gradient router</p><ul><li><p>Max gate 는 gradient 를 한쪽에는 전체, 다른 쪽에는 0 을 준다.</p></li><li><p>해석적으로 보자면, max 연산을 통해 forward 방향에서 영향을 준 branch 에게 gradient 를 전달해 주는 것이 합적</p><p>$$max(x, y) = \begin{cases} x \quad\quad if \quad x &gt; y \\ y \quad\quad if \quad x &lt; y \end{cases}$$</p></li><li><p>수식으로 보자면, x 에 대한 gradient, y 에 대한 gradient 가 각각 (1, 0), (0, 1)  로 local gradient 가 계산되기 때문이다.</p></li><li><p>gradient 가 전달될 길을 결정해주는 면에서, 네트워크에서 path 를 설정해 주는 router의 기능과 비슷하다.</p></li></ul></li><li><p>Mul gate : gradient switcher + scaler</p><ul><li>곱셈연산의 gradient 의 경우, x 에 대한 gradient 는 y 가 되므로, 서로 바꿔주는 역할을 한다. 이 때, forward 상에서의 결과 값으로 곱해주므로, scale 역할까지 함께 하게 된다.</li></ul></li></ol><h2 id="2-Neural-Networks"><a href="#2-Neural-Networks" class="headerlink" title="2. Neural Networks"></a>2. Neural Networks</h2><p>강의에서는 Neural Network 에 대한 intuition 을 위해, biological neuron 과 비교하였다. 모델 architecture 로서의 neuron 과 biological neuron 의 공통점은 다음과 같다.</p><ol><li>input impulse</li><li>input axon → dendrite</li><li>(cell body)activation &amp; activation function</li><li>output axon</li></ol><p>이러한 비교는, 나의 개인적인 Neural Network에 대한 공부와 이해에 도움이 되지 않기에 큰 감동은 없다. </p><ul><li>4강에 대한 핵심 사항은, Backpropagation 에 대한 수식적 이해와 그 이해를 통해 Backpropagation 이 gradient를 구함에 있어, 얼마나 편한 representation 인지이다. 공부하며 어려웠던 것은, backprop in <strong>vectorized</strong> 에서, Jacobian Matrix 의 표현이 scalar  backprop 때와는 달리 한번에 머릿속으로 상상되지 않았기에, 손으로 써가며 따라 갔어야만 했다.</li></ul><h2 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3. Reference"></a>3. Reference</h2><p><a href="https://www.youtube.com/watch?v=d14TUNcbn1k" target="_blank" rel="noopener">Lecture 4 | Introduction to Neural Networks</a></p><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/18/CS231n-Lecture04-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture03-LossFunction/Optimization</title>
      <link>https://emjayahn.github.io/2019/05/16/CS231n-Lecture03-Summary/</link>
      <guid>https://emjayahn.github.io/2019/05/16/CS231n-Lecture03-Summary/</guid>
      <pubDate>Thu, 16 May 2019 01:17:11 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Lecture-03-Loss-Function-amp-Optimization&quot;&gt;&lt;a href=&quot;#Lecture-03-Loss-Function-amp-Optimization&quot; class=&quot;headerlink&quot; title=&quot;Lecture 03: Loss Function &amp;amp; Optimization&quot;&gt;&lt;/a&gt;Lecture 03: Loss Function &amp;amp; Optimization&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lecture-03-Loss-Function-amp-Optimization"><a href="#Lecture-03-Loss-Function-amp-Optimization" class="headerlink" title="Lecture 03: Loss Function &amp; Optimization"></a>Lecture 03: Loss Function &amp; Optimization</h1><ul><li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li></ul><a id="more"></a><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><ol><li>Loss Function : 우리가 가지고 있는 W matrix 가 <strong>얼마나 안좋은지 정량화(Quantify)</strong> </li><li>Optimization : 위의 Loss Function 을 minimize 해서 가장 좋은 parameter (W) 를 찾는 과정</li></ol><h2 id="2-Loss-Function"><a href="#2-Loss-Function" class="headerlink" title="2. Loss Function"></a>2. Loss Function</h2><p>주어진 data 가 다음과 같을 때, </p><p>$${(x_i, y_i)}_{i=1}^{N}$$</p><p> Loss 는 “Average of over examples” 즉, </p><p>$$L = \frac{1}{N}\sum_{i}L_i(f(x_i, W), y_i)$$</p><ul><li>딥러닝 알고리즘의 General Setup<ul><li>W 가 얼마나 좋고, 나쁜지를 정량화하는 손실함수 만들기</li><li>W 공간을 탐색하면서  이 loss를 minimize 하는 W 를 찾기</li></ul></li></ul><h3 id="2-1-Loss-Example-Multiclass-SVM-Loss"><a href="#2-1-Loss-Example-Multiclass-SVM-Loss" class="headerlink" title="2-1. Loss Example: Multiclass SVM Loss"></a>2-1. Loss Example: Multiclass SVM Loss</h3><p>SVM Loss 는 다음과 같다. 주어진 data example (x_i, y_i) 에 대해서, score vector <strong>s</strong> 는 다음과 같다. </p><p>$$s = f(x_i, W)$$</p><p>이 때, SVM loss는 </p><p>$$L_i = \sum_{j\neq y_i}\begin{cases} 0 \quad\quad\quad\quad\quad\quad\quad if ;s_{y_i} \geq s_j +1 \ s_j - s_{y_i} + 1 \quad\quad otherwise \end{cases} \ = \sum_{j\neq y_i}max(0, s_j-s_{y_i}+ 1)$$</p><p>x_i 의 정답이 아닌 클래스의 score (s_j) + 1 (safety margin) 과 정답 클래스 score s_yi 를 비교하여, Loss 를 계산한다.</p><p><img src="Untitled-d804129d-082d-4cfc-819c-4fd3e14ddf17.png" alt></p><ol><li>SVM Loss 의 최대, 최솟값은 ? min : 0, max :  infinite</li><li>W 를 작게 초기화 하면, s 가 거의 0에 가까워 진다. 이 때, SVM Loss 는 어떻게 예상되는가?<ul><li>정답이 아닌 class, 즉 class - 1 개의 score 원소들을 순회하면서 모두 더할 때, score 는 0에 가깝고, 이를 average 취하면 <strong>class 갯수 - 1</strong> 만큼의 Loss 값이 나온다.</li><li>이 특징은 debugging strategy 로 사용할 수 있다. 초기 loss 가 C-1 에 가깝지 않으면 bug 가 있는 것으로 의심해볼 수 있다.</li></ul></li><li>만약 include j = y_i 이면, SVM Loss 는 어떻게 되는가? <ul><li>Loss Funtion 이 바뀌는 것은 아니다. 단지 전체 loss의 minimum 이 1이 될 뿐이므로 해석의 관점에서 관례상 맞지 않아 정답 class 는 빼고 계산한다.</li></ul></li><li>우리가 average 를 취하지 않으면?<ul><li>이 역시 바뀌는 것이 없다. 전체 class 수는 정해져 있고, 이를 나누는 average 는 scaling 만 할 뿐이다.</li></ul></li><li>Loss 를 max(0, s_j - s_yi + 1) ^2 를 사용하면?<ul><li>이는 squared hinge function 으로 때에 따라서 사용할 수 있는 loss function 이다. 다른 Loss function 이며, 이는 위의 loss 와 다르게 해석 할 수 있다. 기존의 SVM loss 는 class score 가 각각 얼마나 차이가 나는지에 대해서는 고려하지 않는 것이라고 한다면, squared 가 들어감으로써, 차이가 많이 나는 score class 에 대해서는 좀더 가중하여 고려하겠다는 의미로 해석 할 수 있다.</li></ul></li></ol><h3 id="2-2-Regularization"><a href="#2-2-Regularization" class="headerlink" title="2-2. Regularization"></a>2-2. Regularization</h3><p>만약 위 Loss Function 에 대해서, L = 0 으로 만드는 W 를 찾았다고 할때, 과연 이 W 는 유일한가? 그렇지 않다. W 일 때, L=0  이라면, 2W 역시 L=0 이다. 또한 L을 0으로 만드는 다양한 W 중에서 단지  training  data 에만 fit 하는 classifier 를 원하는 것이 아니라, test data에서 좋은 성능을 발휘하는 classifier 를 찾기를 원한다. 이런 Overfitting 을 막기 위해서는 모델의 W 를 다른 의미에서 조절해줄 수 있는 <strong>Regularization</strong> term 을 추가할 수 있다.</p><p><strong>즉, Model이 training set 에 완벽하게  fit 하지 못하도록 Model 의 복잡도에 penalty 를 부여하는 것을 말한다.</strong></p><p><img src="Untitled-253fa150-bbe6-473f-bd43-e3fd6fe0009d.png" alt></p><p>Regularization 의 종류들:</p><ul><li>L2 Regularization</li><li>L1 Regularization</li><li>Elastic net(L1 + L2)</li><li>Max norm Regularization</li><li>Dropout</li><li>Batch normalization, stochastic depth</li></ul><h3 id="2-3-Loss-example-Softmax-Classifier-Multinomial-Logistic-Regression"><a href="#2-3-Loss-example-Softmax-Classifier-Multinomial-Logistic-Regression" class="headerlink" title="2-3 Loss example: Softmax Classifier (Multinomial Logistic Regression)"></a>2-3 Loss example: Softmax Classifier (Multinomial Logistic Regression)</h3><p>deeplearning 에서 훨씬 더 자주 보게 되는 loss 의 종류 중 하나이다.  위에서 살펴본 SVM loss 의 단점은 그 값 자체에 어떤 의미를 부여하기는 힘들다는 점이다. 반면에, Softmax Classifier 는 그 값 자체를 확률적 해석이 가능하기 때문이다. (cf. 콜모고로프의 공리를 통해 softmax 의 layer 의 output 이 확률로 해석 될 수 있다.)</p><p>Softmax Function 은 다음과 같다.</p><p>$$P(Y=k|X=x_i) = \frac{e^{s_k}}{\sum_j e^{s_j}},\quad where \quad s = f(x_i;W)$$</p><h2 id="3-Opitmization"><a href="#3-Opitmization" class="headerlink" title="3. Opitmization"></a>3. Opitmization</h2><p>Optimization 을 한마디로 요약하자면, <strong>우리의  loss 를 최소화 하는 W 를 찾기</strong> 가 되겠다. 그 방법에는,</p><ul><li>(바보 같은 접근인: 강의표현) Random Search</li><li>Gradient 를 구하는 방법<ul><li>Numerical Gradient 수치적 접근 : 이 방법은 근사치를 구하는 것이며, 매우 느린 단점이 있다. 하지만, 쉽게 작성할 수 있다는 장점이 있다.</li><li>Analytic Gradient 해석적 접근 : 미분식을 구해야하는 단점이 있다. 하지만 빠르고 정확하다.</li></ul></li></ul><p>실제로는, Analytic Gradient 방법을 사용한다. 하지만 debugging 을 위해 numerical gradient 를 사용한다. 이를 <strong>gradient check</strong>이라 한다.</p><h3 id="3-1-Gradient-Descent-amp-Stochastic-Gradient-Descent"><a href="#3-1-Gradient-Descent-amp-Stochastic-Gradient-Descent" class="headerlink" title="3-1. Gradient Descent &amp; Stochastic Gradient Descent"></a>3-1. Gradient Descent &amp; Stochastic Gradient Descent</h3><p>Gradient Descent 를 방법을 이용해서 optimization 을 진행할 수 있다. 하지만 데이터의 숫자와 차원이 매우 큰 경우, parameter (W) 를 update 하는데 그 연산량이 매우 큰 단점과 위험이 있다. 이를 해결하기 위해 minibatch 를 사용하여 확률적 접근을 사용한다.</p><h2 id="4-Image-Feature-Extraction"><a href="#4-Image-Feature-Extraction" class="headerlink" title="4. Image Feature Extraction"></a>4. Image Feature Extraction</h2><p>CNN 등이 등장하기 전에 Image 에서  Feature 를 뽑아내는 방법에 대해 소개한다. Feature를 뽑아내는 개념으로 생각할 수 도 있지만, Feature Transform 이라는 표현을 사용한다. </p><ol><li>Color Histogram :  이미지의 color distribution 을 사용하여 해당 이미지의 feature 로 사용할 수 있다. (출처: <a href="https://en.wikipedia.org/wiki/Color_histogram" target="_blank" rel="noopener">wikipedia</a> ) For digital images, a color histogram represents the number of pixels that have colors in each of a fixed list of color ranges, that span the image’s color space, the set of all possible colors.</li><li>Histogram of Oriented Gradients (HoG) : CNN 이 등장하기 전, 매우 인기있는 Image Feature 중 하나라고 알고 있다. Edge 를 검출하는 방법이다. pixel 사이에, 값의 gradient 가 가장 큰 neighbor 가 edge 일 것이다라는 개념을 사용하여 edge 를 검출한다. 사진을 8 x 8 patch 를 만들어, 각 patch 마다 9 directional oriented gradients 를 계산하여, 이를 feature 로 사용하는 방법이다.</li><li>Bag of Words : NLP 에서도 자주 사용되는 개념인 BoW 에서 차용한 개념으로, 이미지 데이터들에서 일정 크기의 patch 를 모아 clustering 을 통해 visual words (codebook)  을 만든다. 그리고 feature 뽑아내고 싶은 image 를 patch 형태로 바꾸고, codebook 에서 찾아 histogram 을 만들어 이를 feature 로 사용한다.</li></ol><h2 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h2><p><a href="https://www.youtube.com/watch?v=h7iBpEHGVNc" target="_blank" rel="noopener">Lecture 3 | Loss Functions and Optimization</a></p><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/16/CS231n-Lecture03-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture02-Image Classification Pipeline</title>
      <link>https://emjayahn.github.io/2019/05/13/CS231n-Lecture02-Summary/</link>
      <guid>https://emjayahn.github.io/2019/05/13/CS231n-Lecture02-Summary/</guid>
      <pubDate>Mon, 13 May 2019 03:46:04 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Lecture-02-Image-Classification-Pipeline&quot;&gt;&lt;a href=&quot;#Lecture-02-Image-Classification-Pipeline&quot; class=&quot;headerlink&quot; title=&quot;Lecture 02: Image Classification Pipeline&quot;&gt;&lt;/a&gt;Lecture 02: Image Classification Pipeline&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lecture-02-Image-Classification-Pipeline"><a href="#Lecture-02-Image-Classification-Pipeline" class="headerlink" title="Lecture 02: Image Classification Pipeline"></a>Lecture 02: Image Classification Pipeline</h1><ul><li>이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다.</li></ul><a id="more"></a><h2 id="1-Image-Classification-의-기본-TASK"><a href="#1-Image-Classification-의-기본-TASK" class="headerlink" title="1. Image Classification 의 기본 TASK"></a>1. Image Classification 의 기본 TASK</h2><p><img src="Untitled-dfb244ee-00d4-4801-9db3-2247269d65db.png" alt></p><ul><li>위 사진을 보고, → ‘CAT’ 혹은 ‘고양이’ 라고 classification</li><li>자연스럽게 따라오는 문제는 <strong>“Sementic Gap”</strong> : 우리가 준 data (pixel 값  [0, 255]) 와 Label 간의  gap</li><li>또한, 이 과정에서 극복해야 하는 Challenges<ul><li>Viewpoint Variation ( 같은 객체에 대해 시점이 이동해도 robust)</li><li>Illumination ( 빛, 밝기, 명암 등에도 robust)</li><li>Deformation ( 다양한 Position, 형태의 변형에도 robust)</li><li>Occlusion ( 다른 물체나 환경에 의해 가려지는 data 에도 robust)</li><li>Background Clutter ( 배경과 비슷하게 보이는 객체에도 robust)</li><li>Intraclass Variation ( 한 종류의 클랫스에도 다양한 색과 모습의 객체가 있을 수 있다.)</li></ul></li></ul><h2 id="2-기존의-시도와-New-Era"><a href="#2-기존의-시도와-New-Era" class="headerlink" title="2. 기존의 시도와 New Era"></a>2. 기존의 시도와 New Era</h2><ul><li>Hard Coded Algorithm 과 여러 규칙 (rule-based로 해석된다) 들을 통해서 Image를 Classify 하는 노력들이 있어왔다. 이들의 문제는, (1) 위에 언급한 문제들이 Robust  하지 않다. (2) 객체가 달라지면, (고양이, 호랑이, 비행기 등) 객체마다 다 다른 규칙을 성립해줘야 한다. 즉 한마디로 요약하자면, Algorithm의 확장성이 없다.</li><li>이런 문제에 좀더 강한 방법이 지금 우리가 공부하고 있는, <strong>Data-Driven Approach</strong><ol><li>Image 와 Label pair 의 dataset 을 모은다.</li><li>Machine Learning 알고리즘을 이용해 classifier 를 학습시킨다.</li><li>Classifier 를 new images 에 테스트에 평가한다.</li></ol></li></ul><h2 id="3-First-Classifier-Nearest-Neighbor"><a href="#3-First-Classifier-Nearest-Neighbor" class="headerlink" title="3. First Classifier : Nearest Neighbor"></a>3. First Classifier : Nearest Neighbor</h2><h3 id="3-1-Nearest-Neighbor-의-기본-알고리즘"><a href="#3-1-Nearest-Neighbor-의-기본-알고리즘" class="headerlink" title="3-1. Nearest Neighbor 의 기본 알고리즘"></a>3-1. Nearest Neighbor 의 기본 알고리즘</h3><ol><li>train set 에서의 모든 data 와 label 을 기억한다.</li><li>test Image 와 <strong>가장 가까운</strong> train Image 의 label로 test image를 predict 한다.<ul><li>이 때 ‘<strong>가장 가까운’</strong> 을 계산 할 때<strong>, L1 distance</strong> 와 <strong>L2 distance</strong> 가 쓰일 수 있다. 이 외에도, 다양한 distance 지표가 쓰일 수 있다.</li></ul></li></ol><h3 id="3-2-Nearest-Neighbor-Classifier-의-문제"><a href="#3-2-Nearest-Neighbor-Classifier-의-문제" class="headerlink" title="3-2. Nearest Neighbor Classifier 의 문제"></a>3-2. Nearest Neighbor Classifier 의 문제</h3><ul><li>이미지 classification 에는 잘 사용되지 않는다.</li><li>train 보다 predict 하는데 훨씬 오래 걸린다.<ul><li>train 은 train data set 의 기억만 하면 되지만, predict 할 때는 전체 train data 에 대해 거리를 측정해야하고, sorting 해야하는 문제가 발생한다.</li><li>Time Complexity - train O(1), predict O(N) (N은 train data 수)</li></ul></li></ul><p><img src="Untitled-2fdb78f0-11b7-49cf-99f8-164d6b79fc2c.png" alt></p><p>위 그림을 보면, 연두색 공간에 노란색  class 가 포함 되어 있는 것을 볼 수 있다. 이는 generalize 면에서 부족한 모델이라고 볼 수 있다. 같은 알고리즘 이지만, 이를 해결 하는 방법은 K 개의 가까운 neighbor 로 부터 majority voting 을 받은 것으로 classify 를 하는 것이다.</p><h3 id="3-3-K-Nearest-Neightbors"><a href="#3-3-K-Nearest-Neightbors" class="headerlink" title="3-3. K-Nearest Neightbors"></a>3-3. K-Nearest Neightbors</h3><p>Single Nearest 만 보는 것이 아니라, K 개의 가까운 point 의 투표를 통해 해당 test data  의 label 을 예측한다.</p><ul><li>이 때, Voting 하는 방법에는 majority voting ( 다수결 ) 과 weighted voting ( 가중치를 주어 투표: distance 가 가까운 것에 가중치를 준다.)</li><li>가중치를 주는 방법에는 distance 가 커지면 곱해지는 weight 을 줄이는 방법으로 1 / (1+distance) 등을 weight 을 곱해준다.</li></ul><p><img src="Untitled-469c81dd-01a3-4934-8fec-429c34285d0e.png" alt></p><h3 id="3-4-k-Nearest-Neighbor-on-images-NEVER-USED"><a href="#3-4-k-Nearest-Neighbor-on-images-NEVER-USED" class="headerlink" title="3-4. k-Nearest Neighbor on images NEVER USED"></a>3-4. k-Nearest Neighbor on images NEVER USED</h3><ul><li>차원의 저주 문제</li><li>knn 이 잘 동작하기 위해서는 dataset 공간을 조밀하게 커버할 만큼의 충분한 training space 가 필요하다. 하지만, data 의 차원이 늘어날 수록 그 충분한 data 의 수가 exponential 하게 늘어난다.</li></ul><h2 id="4-Setting-Hyperparameters"><a href="#4-Setting-Hyperparameters" class="headerlink" title="4. Setting Hyperparameters"></a>4. Setting Hyperparameters</h2><p>Model 최적의 hyperparameter 를 찾기 위해서는 data set 을 구분하여, unseened data 를 사용하여 성능 검증을 하고, model selection 을 해야한다. 이는 단순이 hyperparameter 를 찾는 용도 뿐만 아니라 우리가 세운 가설을 서로 비교 할 때는 data set 을 정확히 구분하고, test set 을 통해 비교하고, 선택해야한다. 그 방법에는 train, validation, test set 으로 dataset 을 나누는 방법과 cross validation 방법이 있다.</p><ul><li>첫 번째 방법으로는, Validation set 을 통해 hyperparameter(가설)를 검증하고 선택하여, Test set 을 사용하여 Evaluate 과 Reporting 등을 한다. 딥러닝 모델링에서는 이 방법으로 많이 사용한다.</li></ul><p><img src="Untitled-7d99fc52-7613-4bbf-8cfc-5e036f905602.png" alt></p><ul><li>두 번째 방법은, data set 의 크기가 크지 않을 때, Train set 안에서 folds 들을 나누어 각 fold 가 돌아가며 validation set 이 되며, 이들의 평균값으로 가설을 비교한다. 이는 딥러닝 모델에서는 적합하지 않은 형태이다. 모델 자체의 연산이 많은데다가, 같은 모델에 대해 많은 validation 이 효율적이지 않기 때문이다. 또한 data가 많지 않은 상태에서 딥러닝 모델을 선택하는 것은 옳지 않다.</li></ul><p><img src="Untitled-1e7d1cc8-fcee-4215-a721-345c8f25e8f5.png" alt></p><h2 id="5-Second-Classifier-Linear-Classifier"><a href="#5-Second-Classifier-Linear-Classifier" class="headerlink" title="5. Second Classifier : Linear Classifier"></a>5. Second Classifier : Linear Classifier</h2><p>Linear Classifier 는 Neural Network 의 기본 골격이다. (1) image data 와 W (parameters or weights) 을 통해 연산을 해주고, (2) function 을 통과해 Classification 을 해준다.</p><p>특히 Linear Classifier 의 경우 아래 와 같이, (1) image data 와 W 를 dot product 를 해주고 (2) linear function f 를 통과한다.</p><p>$$f(x, W) = Wx$$</p><p><img src="Untitled-c15a20fd-b906-44ce-af25-6810bc57751a.png" alt></p><h2 id="6-Reference"><a href="#6-Reference" class="headerlink" title="6. Reference"></a>6. Reference</h2><p><a href="https://www.youtube.com/watch?v=OoUX-nOEjG0&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=2" target="_blank" rel="noopener">Lecture 2 | Image Classification</a></p><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">Syllabus | CS 231N</a></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/13/CS231n-Lecture02-Summary/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Basic Classification with Pytorch</title>
      <link>https://emjayahn.github.io/2019/05/06/Basic-Classification-with-Pytorch/</link>
      <guid>https://emjayahn.github.io/2019/05/06/Basic-Classification-with-Pytorch/</guid>
      <pubDate>Mon, 06 May 2019 03:39:33 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Basic-Classification-with-Pytorch&quot;&gt;&lt;a href=&quot;#Basic-Classification-with-Pytorch&quot; class=&quot;headerlink&quot; title=&quot;Basic Classification with Pytorch&quot;&gt;&lt;/a&gt;Basic Classification with Pytorch&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이번 post 는 pytorch 를 활용해 기초적인 분류 모델링을 해보면서, pytorch에 익숙함을 높이는 것이 목적입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Basic-Classification-with-Pytorch"><a href="#Basic-Classification-with-Pytorch" class="headerlink" title="Basic Classification with Pytorch"></a>Basic Classification with Pytorch</h1><ul><li>이번 post 는 pytorch 를 활용해 기초적인 분류 모델링을 해보면서, pytorch에 익숙함을 높이는 것이 목적입니다.</li></ul><a id="more"></a><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</span><br><span class="line"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="hljs-string">'retina'</span></span><br></pre></td></tr></table></figure><h2 id="1-Binary-Classification"><a href="#1-Binary-Classification" class="headerlink" title="1. Binary Classification"></a>1. Binary Classification</h2><ol><li>Modeling</li><li>Sigmoid</li><li>Loss : Binary Cross Entropy</li></ol><h3 id="1-1-Generate-Data"><a href="#1-1-Generate-Data" class="headerlink" title="1.1 Generate Data"></a>1.1 Generate Data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># plotting function</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_scatter</span><span class="hljs-params">(W_, xy, labels)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">for</span> k, color <span class="hljs-keyword">in</span> [(<span class="hljs-number">0</span>, <span class="hljs-string">'b'</span>), (<span class="hljs-number">1</span>, <span class="hljs-string">'r'</span>)]:</span><br><span class="line">        idx = labels.flatten() == k</span><br><span class="line">        plt.scatter(xy[idx, <span class="hljs-number">0</span>], xy[idx, <span class="hljs-number">1</span>], c=color)</span><br><span class="line">        </span><br><span class="line">    x1 = np.linspace(<span class="hljs-number">-0.1</span>, <span class="hljs-number">1.1</span>)</span><br><span class="line">    x2 = -W_[<span class="hljs-number">1</span>] / W_[<span class="hljs-number">2</span>] * x1 - W_[<span class="hljs-number">0</span>] / W_[<span class="hljs-number">2</span>]</span><br><span class="line">    plt.plot(x1, x2, <span class="hljs-string">'--k'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Generate data</span></span><br><span class="line"></span><br><span class="line">W = np.array([<span class="hljs-number">-4.</span>/<span class="hljs-number">5</span>, <span class="hljs-number">3.</span>/<span class="hljs-number">4.</span>, <span class="hljs-number">1.0</span>])</span><br><span class="line"></span><br><span class="line">xy = np.random.rand(<span class="hljs-number">30</span>, <span class="hljs-number">2</span>)</span><br><span class="line">labels = np.zeros(len(xy))</span><br><span class="line">labels[W[<span class="hljs-number">0</span>] + W[<span class="hljs-number">1</span>] * xy[:, <span class="hljs-number">0</span>] + W[<span class="hljs-number">2</span>] * xy[:, <span class="hljs-number">1</span>] &gt; <span class="hljs-number">0</span>] = <span class="hljs-number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_scatter(W, xy, labels)</span><br></pre></td></tr></table></figure><p><img src="output_6_0.png" alt="png"></p><h3 id="1-2-Train-data"><a href="#1-2-Train-data" class="headerlink" title="1.2 Train data"></a>1.2 Train data</h3><ul><li>Generate 한 data 로 부터, x 축 값, y 축 값, augmented term 으로 3가지 column 을 만들어 train data 로 만들어 줍니다.</li><li>또한 대응 되는 label 도 model 에 적합한 모양으로 바꾸어 줍니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[<span class="hljs-number">1.0</span>, xval, yval] <span class="hljs-keyword">for</span> xval, yval <span class="hljs-keyword">in</span> xy])</span><br><span class="line">y_train = torch.FloatTensor(labels).view(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">print(x_train[:<span class="hljs-number">5</span>])</span><br><span class="line">print(y_train[:<span class="hljs-number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>tensor([[1.0000, 0.0192, 0.6049],        [1.0000, 0.0485, 0.2529],        [1.0000, 0.2412, 0.9115],        [1.0000, 0.9764, 0.1665],        [1.0000, 0.9021, 0.5825]])tensor([[0.],        [0.],        [1.],        [1.],        [1.]])</code></pre><h3 id="1-3-Modeling"><a href="#1-3-Modeling" class="headerlink" title="1.3 Modeling"></a>1.3 Modeling</h3><ul><li>Linear Model 형태와 Sigmoid 함수, Loss function 은 cross entropy 를 활용해 모델링을 합니다.</li><li>여기선, 내장되어있는 함수들을 되도록 사용하지 않고, Low level 로 코드를 작성해 보겠습니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Low level modeling</span></span><br><span class="line">parameter_W = torch.FloatTensor([[<span class="hljs-number">-0.5</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">1.8</span>]]).view(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">parameter_W.requires_grad_(<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([parameter_W], lr=<span class="hljs-number">0.01</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    <span class="hljs-comment"># Prediction</span></span><br><span class="line">    y_hat = F.sigmoid(torch.matmul(x_train, parameter_W))</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># Loss function</span></span><br><span class="line">    loss = (-y_train * torch.log(y_hat) - (<span class="hljs-number">1</span> - y_train) * torch.log((<span class="hljs-number">1</span> - y_hat))).sum().mean()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># Backprop &amp; update</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch 1000 -- loss 6.368619441986084epoch 2000 -- loss 4.5249152183532715epoch 3000 -- loss 3.654862403869629epoch 4000 -- loss 3.122910261154175epoch 5000 -- loss 2.7545464038848877epoch 6000 -- loss 2.4800000190734863epoch 7000 -- loss 2.2651939392089844epoch 8000 -- loss 2.091233253479004epoch 9000 -- loss 1.9466761350631714epoch 10000 -- loss 1.8241318464279175</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameter_W.data.numpy()</span><br></pre></td></tr></table></figure><pre><code>array([[-16.748823],       [ 16.618748],       [ 17.622692]], dtype=float32)</code></pre><ul><li>아래 그림을 보면, Train이 잘 된 것을 알 수 있습니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_scatter(parameter_W.data.numpy(), xy, labels)</span><br></pre></td></tr></table></figure><p><img src="output_13_0.png" alt="png"></p><h2 id="2-Multiclass-Classification"><a href="#2-Multiclass-Classification" class="headerlink" title="2. Multiclass Classification"></a>2. Multiclass Classification</h2><h3 id="2-1-Generate-Data"><a href="#2-1-Generate-Data" class="headerlink" title="2.1 Generate Data"></a>2.1 Generate Data</h3><ul><li>이번에는 3개의 label 을 가지고 있는 classification 을 Modeling 해 보겠습니다.</li><li>또한, High Level 로 pytorch 의 추상 클래스를 이용해 모델링 해보겠습니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_scatter</span><span class="hljs-params">(W1, W2, xy, labels)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">for</span> k, color <span class="hljs-keyword">in</span> [(<span class="hljs-number">0</span>, <span class="hljs-string">'b'</span>), (<span class="hljs-number">1</span>, <span class="hljs-string">'r'</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">'y'</span>)]:</span><br><span class="line">        idx = labels.flatten() == k</span><br><span class="line">        plt.scatter(xy[idx, <span class="hljs-number">0</span>], xy[idx, <span class="hljs-number">1</span>], c=color)</span><br><span class="line">        </span><br><span class="line">    x1 = np.linspace(<span class="hljs-number">-0.6</span>, <span class="hljs-number">1.6</span>)</span><br><span class="line">    x2 = -W1[<span class="hljs-number">1</span>] / W1[<span class="hljs-number">2</span>] * x1 - W1[<span class="hljs-number">0</span>] / W1[<span class="hljs-number">2</span>]</span><br><span class="line">    x3 = -W2[<span class="hljs-number">1</span>] / W2[<span class="hljs-number">2</span>] * x1 - W2[<span class="hljs-number">0</span>] / W2[<span class="hljs-number">2</span>]</span><br><span class="line">    plt.plot(x1, x2, <span class="hljs-string">'--k'</span>)</span><br><span class="line">    plt.plot(x1, x3, <span class="hljs-string">'--k'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Generate data</span></span><br><span class="line"></span><br><span class="line">W1 = np.array([<span class="hljs-number">-1</span>, <span class="hljs-number">3.</span>/<span class="hljs-number">4.</span>, <span class="hljs-number">1.0</span>])</span><br><span class="line">W2 = np.array([<span class="hljs-number">-1.</span>/<span class="hljs-number">5</span>, <span class="hljs-number">3.</span>/<span class="hljs-number">4.</span>, <span class="hljs-number">1.0</span>])</span><br><span class="line"></span><br><span class="line">xy = <span class="hljs-number">2</span> * np.random.rand(<span class="hljs-number">100</span>, <span class="hljs-number">2</span>) - <span class="hljs-number">0.5</span></span><br><span class="line">labels = np.zeros(len(xy))</span><br><span class="line">labels[(W1[<span class="hljs-number">0</span>] + W1[<span class="hljs-number">1</span>] * xy[:, <span class="hljs-number">0</span>] + W1[<span class="hljs-number">2</span>] * xy[:, <span class="hljs-number">1</span>] &gt; <span class="hljs-number">0</span>)] = <span class="hljs-number">1</span></span><br><span class="line">labels[(W2[<span class="hljs-number">0</span>] + W2[<span class="hljs-number">1</span>] * xy[:, <span class="hljs-number">0</span>] + W2[<span class="hljs-number">2</span>] * xy[:, <span class="hljs-number">1</span>] &lt; <span class="hljs-number">0</span>)] = <span class="hljs-number">2</span></span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_scatter(W1, W2, xy, labels)</span><br></pre></td></tr></table></figure><p><img src="output_18_0.png" alt="png"></p><h3 id="2-2-Train-data"><a href="#2-2-Train-data" class="headerlink" title="2.2 Train data"></a>2.2 Train data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[<span class="hljs-number">1.0</span>, xval, yval] <span class="hljs-keyword">for</span> xval, yval <span class="hljs-keyword">in</span> xy])</span><br><span class="line">y_train = torch.LongTensor(labels)</span><br><span class="line">print(x_train[<span class="hljs-number">-5</span>:])</span><br><span class="line">print(y_train[<span class="hljs-number">-5</span>:])</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 1.0000,  0.9641,  1.3851],        [ 1.0000, -0.4445,  1.0595],        [ 1.0000,  1.0854, -0.1216],        [ 1.0000,  0.8707,  0.1640],        [ 1.0000,  0.7043,  1.3483]])tensor([1, 0, 0, 0, 1])</code></pre><h3 id="2-3-Modeling"><a href="#2-3-Modeling" class="headerlink" title="2.3 Modeling"></a>2.3 Modeling</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MultiModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = MultiModel()</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    y_hat = model(x_train)</span><br><span class="line">    </span><br><span class="line">    loss = F.cross_entropy(y_hat, y_train)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch 1000 -- loss 0.6635385155677795epoch 2000 -- loss 0.5513403415679932epoch 3000 -- loss 0.4890784025192261epoch 4000 -- loss 0.44675758481025696epoch 5000 -- loss 0.4151267111301422epoch 6000 -- loss 0.39017024636268616epoch 7000 -- loss 0.369760125875473epoch 8000 -- loss 0.35262930393218994epoch 9000 -- loss 0.3379631042480469epoch 10000 -- loss 0.3252090811729431</code></pre><h3 id="2-4-Accuracy-계산"><a href="#2-4-Accuracy-계산" class="headerlink" title="2.4 Accuracy 계산"></a>2.4 Accuracy 계산</h3><ul><li>Accuracy 가 96 % 로 비교적 잘 분류 된 것을 확인 할 수 있습니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">accuracy = (torch.ByteTensor(model(x_train).max(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == y_train)).sum().item() / len(y_train)</span><br><span class="line">print(<span class="hljs-string">"Accuracy: &#123;&#125;"</span>.format(accuracy))</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.96</code></pre>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/06/Basic-Classification-with-Pytorch/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Linear Model with Pytorch</title>
      <link>https://emjayahn.github.io/2019/05/04/Linear-Model-with-Pytorch/</link>
      <guid>https://emjayahn.github.io/2019/05/04/Linear-Model-with-Pytorch/</guid>
      <pubDate>Sat, 04 May 2019 14:54:06 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Linear-Model-with-Pytorch&quot;&gt;&lt;a href=&quot;#Linear-Model-with-Pytorch&quot; class=&quot;headerlink&quot; title=&quot;Linear Model with Pytorch&quot;&gt;&lt;/a&gt;Linear Model with Pytorch&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이 글의 목적은, 지난 Linear Regression 에서 좀더 나아가서, 다양한 Regression 예제들을 Linear Model (WX) 형태로 pytorch 를 이용해 풀어 보는 것입니다.&lt;/li&gt;
&lt;li&gt;Pytorch 를 사용하여 Modeling 과 loss function 등을 class 형태, 내장 loss 함수등을 사용해보겠습니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Linear-Model-with-Pytorch"><a href="#Linear-Model-with-Pytorch" class="headerlink" title="Linear Model with Pytorch"></a>Linear Model with Pytorch</h1><ul><li>이 글의 목적은, 지난 Linear Regression 에서 좀더 나아가서, 다양한 Regression 예제들을 Linear Model (WX) 형태로 pytorch 를 이용해 풀어 보는 것입니다.</li><li>Pytorch 를 사용하여 Modeling 과 loss function 등을 class 형태, 내장 loss 함수등을 사용해보겠습니다.</li></ul><a id="more"></a><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn</span><br><span class="line"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"><span class="hljs-keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="hljs-string">'retina'</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="1-Quadratic-Regression-Model"><a href="#1-Quadratic-Regression-Model" class="headerlink" title="1. Quadratic Regression Model"></a>1. Quadratic Regression Model</h2><p>$$<br>f(x) = w_0 + w_1x + w_2x^2<br>$$</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="hljs-number">-10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>)</span><br><span class="line">y = x**<span class="hljs-number">2</span> + <span class="hljs-number">0.7</span> * x + <span class="hljs-number">3.0</span> + <span class="hljs-number">20</span> * np.random.rand(len(x))</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_4_0.png" alt="png"></p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[each_x**<span class="hljs-number">2</span>, each_x, <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> each_x <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor(y)</span><br><span class="line"></span><br><span class="line">print(<span class="hljs-string">"x_train shape: "</span>, x_train.shape)</span><br><span class="line">print(<span class="hljs-string">"y_train shape: "</span>, y_train.shape)</span><br></pre></td></tr></table></figure><pre><code>x_train shape:  torch.Size([100, 3])y_train shape:  torch.Size([100])</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">W = torch.zeros(<span class="hljs-number">3</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([W], lr=<span class="hljs-number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = x_train.matmul(W)</span><br><span class="line">    </span><br><span class="line">    loss = torch.mean((hypothesis - y_train) ** <span class="hljs-number">2</span>)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch: 1000 -- Parameters: W: tensor([1.1738, 0.4943, 1.0699]) -- loss 85.30189514160156epoch: 2000 -- Parameters: W: tensor([1.1581, 0.4949, 2.0311]) -- loss 76.05414581298828epoch: 3000 -- Parameters: W: tensor([1.1437, 0.4949, 2.9105]) -- loss 68.31205749511719epoch: 4000 -- Parameters: W: tensor([1.1305, 0.4949, 3.7151]) -- loss 61.83049011230469epoch: 5000 -- Parameters: W: tensor([1.1185, 0.4949, 4.4514]) -- loss 56.4041862487793epoch: 6000 -- Parameters: W: tensor([1.1075, 0.4949, 5.1250]) -- loss 51.86140060424805epoch: 7000 -- Parameters: W: tensor([1.0974, 0.4949, 5.7414]) -- loss 48.058231353759766epoch: 8000 -- Parameters: W: tensor([1.0882, 0.4949, 6.3054]) -- loss 44.8742790222168epoch: 9000 -- Parameters: W: tensor([1.0798, 0.4949, 6.8214]) -- loss 42.20869445800781epoch: 10000 -- Parameters: W: tensor([1.0721, 0.4949, 7.2935]) -- loss 39.97709655761719</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, (x_train.data.matmul(W.data).numpy()), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_7_0.png" alt="png"></p><h2 id="2-Cubic-Regression-Model"><a href="#2-Cubic-Regression-Model" class="headerlink" title="2. Cubic Regression Model"></a>2. Cubic Regression Model</h2><p>$$<br>f(x) = w_0 + w_1x + w_2x^2 + w_3x^3<br>$$</p><h3 id="2-1-Generate-Toy-data"><a href="#2-1-Generate-Toy-data" class="headerlink" title="2.1 Generate Toy data"></a>2.1 Generate Toy data</h3><ul><li>100개의 data 를 생성합니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">100</span>)</span><br><span class="line">y = <span class="hljs-number">3</span>*x**<span class="hljs-number">3</span> - <span class="hljs-number">0.2</span> * x ** <span class="hljs-number">2</span> + <span class="hljs-number">0.7</span> * x + <span class="hljs-number">3</span> + <span class="hljs-number">0.5</span> * np.random.rand(len(x))</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_11_0.png" alt="png"></p><h3 id="2-2-Define-Model"><a href="#2-2-Define-Model" class="headerlink" title="2.2 Define Model"></a>2.2 Define Model</h3><ul><li>x_train과 y_train 을 만들어줍니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[xval**<span class="hljs-number">3</span>, xval**<span class="hljs-number">2</span>, xval, <span class="hljs-number">1</span>]<span class="hljs-keyword">for</span> xval <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor([y]).view(<span class="hljs-number">100</span>, <span class="hljs-number">-1</span>)</span><br><span class="line">y_train.shape</span><br></pre></td></tr></table></figure><pre><code>torch.Size([100, 1])</code></pre><ul><li>이번에 Model을 nn.Module 추상 클래스를 상속 받아, class 형태로 모델링 해보겠습니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CubicModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = CubicModel()</span><br></pre></td></tr></table></figure><ul><li>train 시킬 때, loss 역시 nn.functional 에 있는 내장 mse loss 를 사용하여 보겠습니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">15000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = model(x_train)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># define loss</span></span><br><span class="line">    loss  = F.mse_loss(hypothesis, y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># Backprop &amp; update parameters</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1500</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch: 1500 -- loss 0.22306101024150848epoch: 3000 -- loss 0.11560291796922684epoch: 4500 -- loss 0.09848319739103317epoch: 6000 -- loss 0.08879078179597855epoch: 7500 -- loss 0.08104882389307022epoch: 9000 -- loss 0.07452096790075302epoch: 10500 -- loss 0.06889640539884567epoch: 12000 -- loss 0.06398065388202667epoch: 13500 -- loss 0.05964164435863495epoch: 15000 -- loss 0.055785566568374634</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, model(x_train).data.numpy(), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_19_0.png" alt="png"></p><h2 id="3-Exponential-Regression-Model"><a href="#3-Exponential-Regression-Model" class="headerlink" title="3. Exponential Regression Model"></a>3. Exponential Regression Model</h2><p>$$<br>f(x) = e^{w_0x}<br>$$</p><p>$$<br>g(x) = \ln f(x) = w_0x<br>$$</p><ul><li>Exponential 의 경우, Linear Model 형태를 만들어 주기 위해, log 를 씌워 주워 train 을 시킨후, 다시 exponential 을 양변에 취해주는 형태로 modeling 을 하여야 한다.</li></ul><h3 id="3-1-Generate-Toy-data"><a href="#3-1-Generate-Toy-data" class="headerlink" title="3.1 Generate Toy data"></a>3.1 Generate Toy data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="hljs-number">20190505</span>)</span><br><span class="line">x = np.linspace(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">50</span>)</span><br><span class="line">y = np.exp(<span class="hljs-number">2</span> * x) + <span class="hljs-number">0.2</span> * (<span class="hljs-number">2</span> * np.random.rand(len(x)) - <span class="hljs-number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_23_0.png" alt="png"></p><h3 id="3-2-Define-Model"><a href="#3-2-Define-Model" class="headerlink" title="3.2 Define Model"></a>3.2 Define Model</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[xval, <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> xval <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor([np.log(y)]).view(<span class="hljs-number">50</span>, <span class="hljs-number">-1</span>)</span><br><span class="line">y_train.shape</span><br></pre></td></tr></table></figure><pre><code>torch.Size([50, 1])</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ExpModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure><ul><li>이번에는 optimize algorithm 중 Adam 을 사용해 보겠습니다.</li><li>Adam 은 adaptive 하게 learning rate 를 조정해 주는 algorithm 입니다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = ExpModel()</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">15000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = model(x_train)</span><br><span class="line">    </span><br><span class="line">    loss = F.mse_loss(hypothesis, y_train)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch: 1000 -- loss 1.4807509183883667epoch: 2000 -- loss 0.6568859815597534epoch: 3000 -- loss 0.2930431365966797epoch: 4000 -- loss 0.1839657723903656epoch: 5000 -- loss 0.1683545857667923epoch: 6000 -- loss 0.16775406897068024epoch: 7000 -- loss 0.16775156557559967epoch: 8000 -- loss 0.16775153577327728epoch: 9000 -- loss 0.16775155067443848epoch: 10000 -- loss 0.16775155067443848epoch: 11000 -- loss 0.16775155067443848epoch: 12000 -- loss 0.16775155067443848epoch: 13000 -- loss 0.16775153577327728epoch: 14000 -- loss 0.1677515208721161epoch: 15000 -- loss 0.1677515208721161</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, np.exp(model(x_train).data.numpy()), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_29_0.png" alt="png"></p><h2 id="4-Sine-amp-Cosine-Regression"><a href="#4-Sine-amp-Cosine-Regression" class="headerlink" title="4. Sine &amp; Cosine Regression"></a>4. Sine &amp; Cosine Regression</h2><p>$$<br>f(x) = w_0\cos(\pi x) + w_1\sin(\pi  x)<br>$$</p><h3 id="4-1-Generate-Toy-data"><a href="#4-1-Generate-Toy-data" class="headerlink" title="4.1 Generate Toy data"></a>4.1 Generate Toy data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">100</span>)</span><br><span class="line">y = <span class="hljs-number">2</span> * np.cos(np.pi * x) + <span class="hljs-number">1.5</span> * np.sin(np.pi * x) + <span class="hljs-number">2</span> * np.random.rand(len(x)) - <span class="hljs-number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_33_0.png" alt="png"></p><h3 id="4-2-Modeling"><a href="#4-2-Modeling" class="headerlink" title="4.2 Modeling"></a>4.2 Modeling</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[np.cos(np.pi*xval), np.sin(np.pi*xval), <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> xval <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor(y).view(<span class="hljs-number">100</span>, <span class="hljs-number">-1</span>)</span><br><span class="line">y_train.shape</span><br></pre></td></tr></table></figure><pre><code>torch.Size([100, 1])</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SinCosModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = SinCosModel()</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = model(x_train)</span><br><span class="line">    </span><br><span class="line">    loss = F.mse_loss(hypothesis, y_train)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch: 1000 -- loss 1.1333037614822388epoch: 2000 -- loss 0.45972707867622375epoch: 3000 -- loss 0.36056602001190186epoch: 4000 -- loss 0.3566252291202545epoch: 5000 -- loss 0.3566077649593353epoch: 6000 -- loss 0.3566077947616577epoch: 7000 -- loss 0.3566077649593353epoch: 8000 -- loss 0.3566077947616577epoch: 9000 -- loss 0.3566077947616577epoch: 10000 -- loss 0.3566077649593353</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, model(x_train).data.numpy(), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_38_0.png" alt="png"></p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/04/Linear-Model-with-Pytorch/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Linear Regression with Pytorch</title>
      <link>https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/</link>
      <guid>https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/</guid>
      <pubDate>Fri, 03 May 2019 09:19:59 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Linear-Regression-through-Pytorch&quot;&gt;&lt;a href=&quot;#Linear-Regression-through-Pytorch&quot; class=&quot;headerlink&quot; title=&quot;Linear Regression through Pytorch&quot;&gt;&lt;/a&gt;Linear Regression through Pytorch&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Linear-Regression-through-Pytorch"><a href="#Linear-Regression-through-Pytorch" class="headerlink" title="Linear Regression through Pytorch"></a>Linear Regression through Pytorch</h1><ul><li>이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.</li></ul><a id="more"></a><h2 id="Import-Library"><a href="#Import-Library" class="headerlink" title="Import Library"></a>Import Library</h2><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="hljs-string">'retina'</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="Generate-Toy-Data"><a href="#Generate-Toy-Data" class="headerlink" title="Generate Toy Data"></a>Generate Toy Data</h2><p>$ y = \frac{1}{3} x + 5 $ 와 약간의 noise 를 합쳐 100 개의 toy data를 만들겠습니다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Target Function</span></span><br><span class="line">f = <span class="hljs-keyword">lambda</span> x: <span class="hljs-number">1.0</span>/<span class="hljs-number">3.0</span> * x + <span class="hljs-number">5.0</span></span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="hljs-number">-40</span>, <span class="hljs-number">60</span>, <span class="hljs-number">100</span>)</span><br><span class="line">fx = f(x)</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, fx)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_5_0.png" alt="png"></p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># y_train data with little noise</span></span><br><span class="line">y = fx + <span class="hljs-number">10</span> * np.random.rand(len(x))</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_6_0.png" alt="png"></p><h2 id="1-Gradient-Descent"><a href="#1-Gradient-Descent" class="headerlink" title="1. Gradient Descent"></a>1. Gradient Descent</h2><ol><li>Model (hypothesis) 를 설정합니다.<br>(여기선, Linear Regression 이므로, $y = Wx + b$ 형태를 사용합니다.)</li><li>Loss Function 을 정의합니다. (여기선, MSE loss 를 사용하겠습니다.)</li><li>gradient 를 계산합니다.<br>(여기선, Gradient Descent 방법으로 optimize 를 할 것이므로, optim.SGD() 를 사용합니다.)</li><li>parameter 를 update 합니다.</li></ol><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor(x)</span><br><span class="line">y_train = torch.FloatTensor(y)</span><br><span class="line">print(<span class="hljs-string">"x_train Tensor shape: "</span>, x_train.shape)</span><br><span class="line">print(<span class="hljs-string">"y_train Tensor shape: "</span>, y_train.shape)</span><br></pre></td></tr></table></figure><pre><code>x_train Tensor shape:  torch.Size([100])y_train Tensor shape:  torch.Size([100])</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># train code</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># parameter setting &amp; initialize</span></span><br><span class="line">W = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line">b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># optimizer setting</span></span><br><span class="line">optimizer = optim.SGD([W, b], lr=<span class="hljs-number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># total epochs</span></span><br><span class="line">epochs = <span class="hljs-number">3000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    <span class="hljs-comment"># decide model(hypothesis)</span></span><br><span class="line">    model = W * x_train + b</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># loss function -&gt; MSE</span></span><br><span class="line">    loss = torch.mean((model - y_train)**<span class="hljs-number">2</span>)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 10 epoch 마다 train loss 를 출력합니다.</span></span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">500</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, b.data, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch: 500 -- Parameters: W: tensor([0.3709]) b: tensor([5.6408]) -- loss 22.728315353393555epoch: 1000 -- Parameters: W: tensor([0.3467]) b: tensor([7.9427]) -- loss 11.399767875671387epoch: 1500 -- Parameters: W: tensor([0.3368]) b: tensor([8.8829]) -- loss 9.51008415222168epoch: 2000 -- Parameters: W: tensor([0.3327]) b: tensor([9.2669]) -- loss 9.194862365722656epoch: 2500 -- Parameters: W: tensor([0.3311]) b: tensor([9.4237]) -- loss 9.142287254333496epoch: 3000 -- Parameters: W: tensor([0.3304]) b: tensor([9.4878]) -- loss 9.133516311645508</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">"train data"</span>)</span><br><span class="line">plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_10_0.png" alt="png"></p><h2 id="2-Stochastic-Gradient-Descent"><a href="#2-Stochastic-Gradient-Descent" class="headerlink" title="2. Stochastic Gradient Descent"></a>2. Stochastic Gradient Descent</h2><ol><li>Model (hypothesis) Setting</li><li>Loss Function Setting</li><li>최적화 알고리즘 선택</li><li>shuffle train data</li><li>mini-batch 마다 W, b 업데이트</li></ol><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># batch 를 generate 해주는 함수</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_batch</span><span class="hljs-params">(batch_size, x_train, y_train)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">assert</span> len(x_train) == len(y_train)</span><br><span class="line">    result_batches = []</span><br><span class="line">    x_size = len(x_train)</span><br><span class="line">    </span><br><span class="line">    shuffled_id = np.arange(x_size)</span><br><span class="line">    np.random.shuffle(shuffled_id)</span><br><span class="line">    shuffled_x_train = x_train[shuffled_id]</span><br><span class="line">    shuffled_y_train = y_train[shuffled_id]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">for</span> start_idx <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, x_size, batch_size):</span><br><span class="line">        end_idx = start_idx + batch_size</span><br><span class="line">        batch = [shuffled_x_train[start_idx:end_idx], shuffled_y_train[start_idx:end_idx]]</span><br><span class="line">        result_batches.append(batch)</span><br><span class="line">    <span class="hljs-keyword">return</span> result_batches</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># train</span></span><br><span class="line">W = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line">b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([W, b], lr=<span class="hljs-number">0.001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    <span class="hljs-keyword">for</span> x_batch, y_batch <span class="hljs-keyword">in</span> generate_batch(<span class="hljs-number">10</span>, x_train, y_train):</span><br><span class="line">        model = W * x_batch + b</span><br><span class="line">        loss = torch.mean((model - y_batch)**<span class="hljs-number">2</span>)</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">500</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, b.data, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch: 500 -- Parameters: W: tensor([0.0890]) b: tensor([9.5399]) -- loss 162.1055450439453epoch: 1000 -- Parameters: W: tensor([0.3672]) b: tensor([9.5366]) -- loss 12.424881935119629epoch: 1500 -- Parameters: W: tensor([0.3560]) b: tensor([9.5097]) -- loss 7.826609134674072epoch: 2000 -- Parameters: W: tensor([0.3375]) b: tensor([9.5556]) -- loss 13.15934944152832epoch: 2500 -- Parameters: W: tensor([0.2462]) b: tensor([9.5157]) -- loss 11.582895278930664epoch: 3000 -- Parameters: W: tensor([0.3097]) b: tensor([9.5111]) -- loss 9.991677284240723epoch: 3500 -- Parameters: W: tensor([0.2497]) b: tensor([9.5532]) -- loss 20.481367111206055epoch: 4000 -- Parameters: W: tensor([0.4388]) b: tensor([9.5390]) -- loss 20.827198028564453epoch: 4500 -- Parameters: W: tensor([0.1080]) b: tensor([9.4959]) -- loss 140.0277862548828epoch: 5000 -- Parameters: W: tensor([0.3188]) b: tensor([9.4829]) -- loss 6.635367393493652epoch: 5500 -- Parameters: W: tensor([0.2553]) b: tensor([9.5017]) -- loss 25.45773696899414epoch: 6000 -- Parameters: W: tensor([0.2490]) b: tensor([9.5489]) -- loss 9.580666542053223epoch: 6500 -- Parameters: W: tensor([0.3189]) b: tensor([9.5347]) -- loss 12.585128784179688epoch: 7000 -- Parameters: W: tensor([0.3026]) b: tensor([9.4874]) -- loss 8.298829078674316epoch: 7500 -- Parameters: W: tensor([0.3507]) b: tensor([9.6815]) -- loss 13.348054885864258epoch: 8000 -- Parameters: W: tensor([0.1423]) b: tensor([9.5220]) -- loss 32.567440032958984epoch: 8500 -- Parameters: W: tensor([0.7147]) b: tensor([9.5182]) -- loss 75.97190856933594epoch: 9000 -- Parameters: W: tensor([0.5170]) b: tensor([9.5289]) -- loss 39.07848358154297epoch: 9500 -- Parameters: W: tensor([0.3748]) b: tensor([9.5590]) -- loss 10.358983993530273epoch: 10000 -- Parameters: W: tensor([0.2958]) b: tensor([9.6088]) -- loss 7.410649299621582</code></pre><ul><li>Stochasitic 하게 loss의 gradient 를 계산하여, parameter update를 하므로, loss 가 굉장히 oscilation 이 나타나며 감소하는 것을 볼 수 있다.</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">"train data"</span>)</span><br><span class="line">plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_15_0.png" alt="png"></p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/03/Linear-Regression-with-Pytorch/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Lecture] 딥러닝을 이용한 자연어 처리 Section A, B</title>
      <link>https://emjayahn.github.io/2019/05/03/Lecture-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-Section-A-B/</link>
      <guid>https://emjayahn.github.io/2019/05/03/Lecture-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-Section-A-B/</guid>
      <pubDate>Fri, 03 May 2019 04:24:28 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Section-A-B-Summary&quot;&gt;&lt;a href=&quot;#Section-A-B-Summary&quot; class=&quot;headerlink&quot; title=&quot;Section A, B - Summary&quot;&gt;&lt;/a&gt;Section A, B - Summary&lt;/h1&gt;&lt;p&gt;이 글은 edwith(&lt;a href=&quot;https://www.edwith.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.edwith.org/&lt;/a&gt;)의 조경현 교수님의 딥러닝을 이용한 자연어 처리 (&lt;a href=&quot;https://www.edwith.org/deepnlp/joinLectures/17363&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.edwith.org/deepnlp/joinLectures/17363&lt;/a&gt;)강의를 듣고 정리한 글입니다.&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Section-A-B-Summary"><a href="#Section-A-B-Summary" class="headerlink" title="Section A, B - Summary"></a>Section A, B - Summary</h1><p>이 글은 edwith(<a href="https://www.edwith.org/" target="_blank" rel="noopener">https://www.edwith.org/</a>)의 조경현 교수님의 딥러닝을 이용한 자연어 처리 (<a href="https://www.edwith.org/deepnlp/joinLectures/17363" target="_blank" rel="noopener">https://www.edwith.org/deepnlp/joinLectures/17363</a>)강의를 듣고 정리한 글입니다.</p><a id="more"></a><h2 id="Section-A-Introduction"><a href="#Section-A-Introduction" class="headerlink" title="Section A. Introduction"></a>Section A. Introduction</h2><ul><li><p>알고리즘의 정의 : 문제를 해결하기 위한 instruction 의 sequence</p></li><li><p>Machine Learning Algorithm</p><ol><li><p>문제 정의 (optional) : 문제를 specific 하게 정의 하는 것 자체가 쉽지 않다.</p><p> ex) 얼굴을 detection 할 때, 어떤 범위까지 얼굴이라고 정의할 것인지</p></li><li><p>Example들이 주어진다 → 데이터들</p></li><li><p>문제를 해결 할 수 있는 Train된 Machine Learning Model</p></li></ol></li></ul><h2 id="Section-B-Basic-Machine-Learning-Supervised-Learning"><a href="#Section-B-Basic-Machine-Learning-Supervised-Learning" class="headerlink" title="Section B. Basic Machine Learning: Supervised Learning"></a>Section B. Basic Machine Learning: Supervised Learning</h2><h3 id="0-Supervised-Learning"><a href="#0-Supervised-Learning" class="headerlink" title="0. Supervised Learning"></a>0. Supervised Learning</h3><ul><li><p>제공되는 것들:</p><ol><li><p>N 개의 pair 로 된 training set</p><p> $$D = {(x_1, y_1), …, (x_N, y_N)}$$</p></li><li><p>Data 별 loss function</p><ul><li>Loss function 은 필요에 따라서 우리가 디자인 해야 할 때도 있다.</li></ul><p>$$l(M(x), y) \geq 0$$</p></li><li><p>Evaluation sets: Validation set과 test set</p></li></ol><ul><li>기존에 보지 못한 dataset 에도 trained model 이 잘 작동 하는지 확인하는 것이 필수</li></ul></li><li><p>우리가 결정해야 하는 것들:</p><ol><li>Hypothesis sets: H1, H2 … :<ul><li>모델, hyper parameter들이 다른 모델, 여러가지 실험 해보고 싶은 것들이 될 수 있다.</li><li>가설을 잘 설정하는 것이 최종의 모델을 결정하는데 중요한 기초 작업</li></ul></li><li>Optimization Algorithm<ul><li>어떤 방법론으로 최적화를 진행 할지 역시 매우 중요한 문제</li></ul></li></ol></li><li><p>결국, 우리가 해야 하는 것은</p><ol><li>주어진 Training set 에서, hypothesis set 안의 각 Hm 마다 가장 좋은 모델을 찾는다.</li><li>Trained Hm 중에서, Validation set 에서 가장 좋은 한 가지 모델을 결정한다.</li><li>Reporting 을 위해 test set 에서 얼마나 좋은 성능을 나타내는지 확인한다.</li></ol></li></ul><h3 id="Three-points-to-Consider-both-in-research-and-in-practice"><a href="#Three-points-to-Consider-both-in-research-and-in-practice" class="headerlink" title="[Three points to Consider both in research and in practice]"></a>[Three points to Consider both in research and in practice]</h3><h3 id="1-어떻게-Hypothesis-set-을-설정하는가"><a href="#1-어떻게-Hypothesis-set-을-설정하는가" class="headerlink" title="1. 어떻게 Hypothesis set 을 설정하는가?"></a>1. 어떻게 Hypothesis set 을 설정하는가?</h3><ul><li><p>Hypothesis Set 자체가 infinite 하다는 문제</p><ul><li>Neural Network 에서 국한되서 보자면, 어떤 Network Architecture 를 사용하여 모델을 구성할 것인지,  각 모델마다 hyper parameter 를 어떻게 설정할 것인지 등 hypothesis set 이 매우 다양하다.</li><li>이 중, 좋은 한가지 모델을 한가지 찾는 방법이 어렵다.</li><li>강의 표현 중 이를 찾는 것은 Science ——— Magic 사이에 어느 한 점인, 거의 Art 에 가깝다고 하셔서 매우 웃겼다. 개인적으로 이 부분이 가장 공부하면서도 어렵고, 그 모델을 찾는 것이 매우 추상적인 느낌이다. 그리고 개인적으로 진행하는 프로젝트에서 과연 내가 찾은 모델보다 더 좋은 성능을 가지는 모델혹은 파라미터는 없을까(무조건 있을 것인데..라고 생각하는 경우가 훨씬 많지만..)라고 생각하며 분석과 모델링의 열정을 높이곤한다.</li></ul></li><li><p>Network Architectures</p><ul><li>Neural Network 는 Directed Acyclic Graph이다!!</li><li>Inference : Forward Computaion 만으로, 쉽게 trained neural network를 사용할 수 있다.</li><li>이를 구성하는데 있어, high-level 로 abstraction 된 라이브러리를 oop , functional programming 을 활용해 쉽게 구현할 수 있다. (pytorch, tensorflow…)</li></ul></li></ul><h3 id="2-Loss-Function"><a href="#2-Loss-Function" class="headerlink" title="2.  Loss Function"></a>2.  Loss Function</h3><ul><li><p>관점의 이동:</p><ul><li><p>어떤 주어진 data x 에 대하여 y 는 무엇일까? 를 생각하는 모델이 아니라,</p><p>$$f_\theta(x) = ? $$</p></li><li><p>주어진 x 에 대해 y가 어떤 case 혹은 값일 확률로 생각한다.</p><p>$$p(y=y’|x) = ?$$</p></li></ul></li><li><p>Distribution based loss functions</p><ul><li>Binary Classification : Bernoulli distribution → Sigmoid</li><li>Multiclass Classification : Categorical distribution → Softmax</li><li>Linear Regression : Gaussian distribution</li><li>Multimodal linear Regression : Mixture of Gaussians</li></ul></li><li><p>결국 Loss Function 은 다음과 같이 표현될 수 있다. Maximize logp</p></li></ul><p>$$argmax_\theta \sum_{n=1}^{N} logp_\theta(y_n|x_n)$$</p><ul><li>= minimize L(theta):</li></ul><p>$$L(\theta) = \sum_{n=1}^{N} l(M_\theta(x_n), y_n)=  -\sum_{n=1}^{N} logp_\theta(y_n|x_n)$$</p><h3 id="3-Optimization"><a href="#3-Optimization" class="headerlink" title="3. Optimization"></a>3. Optimization</h3><ul><li>Optimization 방법<ul><li>Optimization 방법에는 GD, SGD, Newton Method 등 다양한 방법이 있지만, Nerual Network 에서는 Gradient Descent 방법을 위주로 사용한다. 이 강의에서는 다루지 않았지만, Gradient Descent  방법 외의 다른 알고리즘들은 전제되는 가정들이 많고, Nerual Network 의 고차원에서는 그 가정을 만족하기가 쉽지 않다. (예를 들어, Newton Method 에서의 Hessian 행렬이 구해지기 위한 가정, computation 양 또한 매우 많다.) 이런 이유에서 Gradient Descent 방법을 사용한다.</li></ul></li><li>Backward Computation : Backpropagation<ul><li>Loss function 의 gradient 를 구하는 방법은 쉽지 않다.</li><li>Neural Network는 Automatic differentiation (Autograd) 를 사용하여, weight 과 bias term 에 대해 쉽게(?) gradient 값을 구할 수 있다. library 덕분에 우리가 loss function 의 gradient 를 직접 구하지 않아도 된다.</li></ul></li></ul>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/05/03/Lecture-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-Section-A-B/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Provision</title>
      <link>https://emjayahn.github.io/2019/01/10/Provision/</link>
      <guid>https://emjayahn.github.io/2019/01/10/Provision/</guid>
      <pubDate>Thu, 10 Jan 2019 14:34:05 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Server-Provisioning-amp-Terraform&quot;&gt;&lt;a href=&quot;#Server-Provisioning-amp-Terraform&quot; class=&quot;headerlink&quot; title=&quot;Server Provisioning &amp;amp; Terraform&quot;&gt;&lt;/a&gt;Server Provisioning &amp;amp; Terraform&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Provisioning 이란,  한정된 자원을 최적의 효율을 위해 제공하는 기술적 개념을 말한다. 유저의 요청에 맞게 자원을 미리 세팅해두고, 유저의 요청에 따라 준비된 자원들을 목적과 효율에 맞게 제공하는 개념이다. 특정 분야에서 한정되어 사용하는 개념이 아니라 다양한 분야에서 응용되어지는 주제이다.  (IT 분야만으로 한정되지도 않는다) IT 분야의 Provisioning의 예시로는, Server Provisioning, Storage Provisioning, Telecommunication Provisioning 등이 있다.&lt;/li&gt;
&lt;li&gt;여기서는 &lt;strong&gt;Terraform&lt;/strong&gt; 을 활용한 AWS 서버 프로비져닝에 관해 다룬다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Server-Provisioning-amp-Terraform"><a href="#Server-Provisioning-amp-Terraform" class="headerlink" title="Server Provisioning &amp; Terraform"></a>Server Provisioning &amp; Terraform</h1><ul><li>Provisioning 이란,  한정된 자원을 최적의 효율을 위해 제공하는 기술적 개념을 말한다. 유저의 요청에 맞게 자원을 미리 세팅해두고, 유저의 요청에 따라 준비된 자원들을 목적과 효율에 맞게 제공하는 개념이다. 특정 분야에서 한정되어 사용하는 개념이 아니라 다양한 분야에서 응용되어지는 주제이다.  (IT 분야만으로 한정되지도 않는다) IT 분야의 Provisioning의 예시로는, Server Provisioning, Storage Provisioning, Telecommunication Provisioning 등이 있다.</li><li>여기서는 <strong>Terraform</strong> 을 활용한 AWS 서버 프로비져닝에 관해 다룬다.</li></ul><a id="more"></a><h2 id="AWS-EC2"><a href="#AWS-EC2" class="headerlink" title="## AWS EC2"></a>## AWS EC2</h2><ul><li>AWS EC2를 활용하기 위해서는 3가지의 기본적인 세팅이 필요하다.<ol><li>키페어 (Key pair)</li><li>보안그룹 (Security Group)</li><li>인스턴스 (Instance)</li></ol></li><li>이 세가지를 Terraform 을 활용해 생성하는 코드를 정리한다.</li></ul><h3 id="1-키페어-생성-Key-pair"><a href="#1-키페어-생성-Key-pair" class="headerlink" title="1. 키페어 생성 (Key pair)"></a>1. 키페어 생성 (Key pair)</h3><h4 id="1-1-Key-만들기"><a href="#1-1-Key-만들기" class="headerlink" title="1-1. Key 만들기"></a>1-1. Key 만들기</h4><pre><code>- 자신의 email로 ssh key 를 생성하여, key_name 이름으로 .ssh 폴더에 저장</code></pre><p><code>ssh-keygen -t rsa -b 4096 -C “email” -f “$HOME/.ssh/key_name” -N “”</code><br>    - 이렇게 생성된 key 는 /key_name/ 과 /key_name.pub/로 private key 와 public key가 생성된다.</p><h4 id="1-2-Key-pair-생성"><a href="#1-2-Key-pair-생성" class="headerlink" title="1-2. Key pair 생성"></a>1-2. Key pair 생성</h4><pre><code>- `main.tf`  파일 생성</code></pre><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">`provider “aws” &#123;</span><br><span class="line"># 이 region 은 seoul 을 의미한다</span><br><span class="line">region = “ap-northeast-2”</span><br><span class="line">&#125;</span><br><span class="line">Resource “aws_key_pair” “resource_name” &#123;</span><br><span class="line"># keygen 으로 생성한 key_name</span><br><span class="line">key_name = &quot;key_name&quot;</span><br><span class="line">public_key = &quot;$&#123;file(&quot;~/.ssh/key_name.pub&quot;)&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><pre><code>- apply 를 실행해, aws 키페어를 생성</code></pre><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ terraform init</span><br><span class="line">$ terraform plan</span><br><span class="line">$ terraform apply</span><br></pre></td></tr></table></figure><pre><code>- destroy 를 실행해, aws 키페어를 삭제</code></pre><p><code>$ terraform destroy</code></p><h3 id="2-보안그룹-생성-Security-Group"><a href="#2-보안그룹-생성-Security-Group" class="headerlink" title="2. 보안그룹 생성 (Security Group)"></a>2. 보안그룹 생성 (Security Group)</h3><pre><code>- 보안그룹은 생성될 인스턴스의 정책을 설정하는 부분이다. 가장 대표적인 기능은 인바운드와 아웃바운드 port 를 설정할 수 있다.- 필요에 따라 port number 를 열어주면 된다.- `ingress` 는 인바운드, `egress` 는 아웃바운드 태그이다.- `from_port` 와 `to_port` 는 말 그대로 from 부터 to 까지의 번호를 지정한다.- 대표적인 포트번호에 관한 설명    - 22 : ssh 접속을 위한 포트    - 80 : http의 기본포트    - 8888 : Jupiter notebook 사용을 위한  포트    - 27017 : MongoDB 사용을 위한 포트    - 3306 : MySQL 사용을 위한 포트( /여기서는 DB의 경우, 다른 서버를 두고 사용하고 있으므로, 열어주지 않는다/ )- `main.tf`  파일 생성</code></pre><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">provider &quot;aws&quot; &#123;</span><br><span class="line">    region = &quot;ap-northeast-2&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource &quot;aws_security_group&quot; &quot;resource_name&quot; &#123;</span><br><span class="line">name = &quot;보안그룹 이름&quot;</span><br><span class="line">description = &quot;보안그룹의 설명&quot;</span><br><span class="line">ingress &#123;</span><br><span class="line">from_port = 22</span><br><span class="line">to_port = 22</span><br><span class="line">protocol = &quot;tcp&quot;</span><br><span class="line">cidr_blocks = [&quot;0.0.0.0/0&quot;]</span><br><span class="line">&#125;</span><br><span class="line">ingress &#123;</span><br><span class="line">from_port = 80</span><br><span class="line">to_port = 80</span><br><span class="line">protocol = &quot;tcp&quot;</span><br><span class="line">cidr_blocks = [&quot;0.0.0.0/0&quot;]</span><br><span class="line">&#125;</span><br><span class="line">ingress &#123;</span><br><span class="line">from_port = 8888</span><br><span class="line">to_port = 8888</span><br><span class="line">protocol = &quot;tcp&quot;</span><br><span class="line">cidr_blocks = [&quot;0.0.0.0/0&quot;]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>마찬가지로, <code>init</code>, <code>plan</code>, <code>apply</code> 를 활용하여 보안그룹을 생성하고, <code>destroy</code> 로 제거한다.</li></ul><h3 id="3-인스턴스-생성"><a href="#3-인스턴스-생성" class="headerlink" title="3. 인스턴스 생성"></a>3. 인스턴스 생성</h3><pre><code>- 대망의 인스턴스 생성!- 여기선, EC2 중, linux ubuntu 18.04 버젼 을 활용한다. AWS 내에서 다른 종류의 인스턴스를 사용할 경우, ami 를 다른 값으로 사용하면 된다.- 또한, 다양한 인스턴스 유형중, t2.nano를 사용한다. 인스턴스 유형도 필요에 따라 다르게 설정하면 된다.- `main.tf`  파일 생성</code></pre><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">provider &quot;aws&quot; &#123;</span><br><span class="line">region = &quot;ap-northeast-2&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data &quot;aws_security_group&quot; &quot;resource1&quot; &#123;</span><br><span class="line">     name = &quot;security_group_name&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource &quot;aws_instance&quot; &quot;resource2&quot; &#123;</span><br><span class="line">ami = &quot;ami-06e7b9c5e0c4dd014&quot;</span><br><span class="line">instance_type = &quot;t2.nano&quot;</span><br><span class="line">key_name = &quot;key_name&quot;</span><br><span class="line">vpc_security_group_ids = [</span><br><span class="line"> &quot;$&#123;data.aws_security_group.resource1.id&#125;&quot;</span><br><span class="line">]</span><br><span class="line">tags &#123;</span><br><span class="line">Name = &quot;dss_instance&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><pre><code>- `init`, `plan`, `apply` 를 활용하여  인스턴스를 생성하고, `destroy` 로 제거한다.</code></pre><h3 id="4-생성된-인스턴스-확인"><a href="#4-생성된-인스턴스-확인" class="headerlink" title="4. 생성된 인스턴스 확인"></a>4. 생성된 인스턴스 확인</h3><p><code>ssh -I ~/.ssh/key_name ubuntu@외부ip</code> 로 생성된 인스턴스를 확인하고, 활용할 수 있다.</p>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/01/10/Provision/#disqus_thread</comments>
    </item>
    
    <item>
      <title>190109-TodayWhatILearned</title>
      <link>https://emjayahn.github.io/2019/01/09/190109-TodayWhatILearned/</link>
      <guid>https://emjayahn.github.io/2019/01/09/190109-TodayWhatILearned/</guid>
      <pubDate>Wed, 09 Jan 2019 14:58:09 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;190109-TWIL&quot;&gt;&lt;a href=&quot;#190109-TWIL&quot; class=&quot;headerlink&quot; title=&quot;190109 TWIL&quot;&gt;&lt;/a&gt;190109 TWIL&lt;/h1&gt;&lt;hr&gt;
&lt;h2 id=&quot;오늘-한-일은-무엇인가&quot;&gt;&lt;a href=&quot;#
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="190109-TWIL"><a href="#190109-TWIL" class="headerlink" title="190109 TWIL"></a>190109 TWIL</h1><hr><h2 id="오늘-한-일은-무엇인가"><a href="#오늘-한-일은-무엇인가" class="headerlink" title="오늘 한 일은 무엇인가"></a>오늘 한 일은 무엇인가</h2><ol><li>BLOG RENEWAL</li></ol><hr><h2 id="내일-할-일은-무엇인가"><a href="#내일-할-일은-무엇인가" class="headerlink" title="내일 할 일은 무엇인가"></a>내일 할 일은 무엇인가</h2><ol><li>Graph모형 공부</li><li>LinearAlgebra 1강, 2강<br></li></ol><hr><h2 id="무엇을-느꼈는가"><a href="#무엇을-느꼈는가" class="headerlink" title="무엇을 느꼈는가"></a>무엇을 느꼈는가</h2><ul><li>새해를 맞아 블로그를 새 테마로 바꾸었다. 기존에 hueman theme 에 익숙해져 있어서, 새로운 테마의 기능을<br>수정하고, 전처럼 편해지려면 또 적응의 시간이 필요할 것 같다. 블로그의 테마는 작년부터 글의 양이 늘어나면 늘어날수록<br>그 욕구가 더 심해 졌다. 특정 카테고리에서 글이 누적되가면서, 어떤 글들이 담겨있는지 제목을 통해 직관적으로<br>보고싶었다. hueman 은 글마다 썸네일들이 있고, 글의 순서가 조금 불편하게 배치되어 있다. 시리즈성 글들을 올린다거나,<br>주제가 1, 2, 3 등으로 나뉘는 글들이 있을 때, 글 제목으로 연속성을 보기가 힘들었다.</li><li>위의 이유로 선택한 이번 테마는 내가 중점적으로 생각한 부분을 조금이나마 개선할 수 있는 것 같다. 틈틈히<br>새로운 테마의 세팅도 마쳐야겠다.</li></ul><hr>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/01/09/190109-TodayWhatILearned/#disqus_thread</comments>
    </item>
    
    <item>
      <title>REBOOT</title>
      <link>https://emjayahn.github.io/2019/01/08/190108-TodayWhatILearned/</link>
      <guid>https://emjayahn.github.io/2019/01/08/190108-TodayWhatILearned/</guid>
      <pubDate>Tue, 08 Jan 2019 02:35:35 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;** REBOOT **&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Text Classification Project 를 한다는 핑계로 그간 TodayWhatILearned의 작성을 하지 못했다.&lt;br&gt;프로젝트를 하는 동안은 매일 어떤 것을 공부할 계획이고, 어떤 공
        
      
      </description>
      
      <content:encoded><![CDATA[<p>** REBOOT **</p><ul><li>Text Classification Project 를 한다는 핑계로 그간 TodayWhatILearned의 작성을 하지 못했다.<br>프로젝트를 하는 동안은 매일 어떤 것을 공부할 계획이고, 어떤 공부를 했는지 남길 만한 내용이 없었던 것도 사실이다.<br>프로젝트 동안 미뤄뒀던 공부들, 보고싶었던 주제들을 이제 다시 새로운 마음가짐을 가지고 시작할 것이다.<br>새해가 밝은 만큼 블로그를 만들기 시작하면서 다짐했던 초심을 상기하자.</li></ul><h2 id="To-Do-List"><a href="#To-Do-List" class="headerlink" title="To-Do-List"></a>To-Do-List</h2><ol><li>Graph모형, 네트워크 추론 공부 (수식) - 새로운 패키지, 코드 정리하면서 공부</li><li>LinearAlgebra 1강, 2강 다시 시작</li></ol><hr><h2 id="오늘-한-일은-무엇인가"><a href="#오늘-한-일은-무엇인가" class="headerlink" title="오늘 한 일은 무엇인가"></a>오늘 한 일은 무엇인가</h2><ol><li>Graph모형 공부</li><li>LinearAlgebra 1강, 2강<br></li></ol><hr><h2 id="내일-할-일은-무엇인가"><a href="#내일-할-일은-무엇인가" class="headerlink" title="내일 할 일은 무엇인가"></a>내일 할 일은 무엇인가</h2><ol><li>네트워크 추론 공부(수식 위주로 공부)</li></ol><hr>]]></content:encoded>
      
      <comments>https://emjayahn.github.io/2019/01/08/190108-TodayWhatILearned/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
